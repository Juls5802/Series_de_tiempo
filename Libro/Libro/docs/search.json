[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Análisis de series de tiempo",
    "section": "",
    "text": "Introducción"
  },
  {
    "objectID": "index.html#esquina",
    "href": "index.html#esquina",
    "title": "Análisis de series de tiempo",
    "section": "Esquina",
    "text": "Esquina\nEste trabajo realiza un análisis de dos bases de datos: Recaudo de impuestos internos por la DIAN para los años 2000 a 2023 y consumo de energía por horas de la organización regional de transmisión PJM Interconnection para los años 2004 a 2018. El análisis se desarrolla de forma estadística, realizando la parte descriptiva con su correspondiente interpretación."
  },
  {
    "objectID": "index.html#análisis-del-recaudo-de-impuestos-internos-por-la-dian",
    "href": "index.html#análisis-del-recaudo-de-impuestos-internos-por-la-dian",
    "title": "Análisis de series de tiempo",
    "section": "Análisis del recaudo de impuestos internos por la DIAN",
    "text": "Análisis del recaudo de impuestos internos por la DIAN\nLa DIAN es la entidad encargada de administrar y recaudar los impuestos internos y aduaneros en el país. El recaudo de impuestos internos que realiza la DIAN cada mes se refiere a la suma total de los impuestos nacionales recaudados dentro del territorio colombiano durante ese período mensual. Los impuestos internos son aquellos que se aplican a las actividades económicas y transacciones que ocurren dentro del país, los cuales pueden incluir: IVA, impuesto de renta y complementarios, impuesto de timbre, impuesto de consumo, impuesto a la riqueza, impuesto predial, ICA, entre otros.\nCon el proyecto se busca estudiar esta serie de tiempo para ver como es el comportamiento de los impuestos internos de Colombia a lo largo de los años, por ejemplo, encontrar patrones y observar qué tanto han aumentado dichos impuestos.\nA continuación se presenta la manera en que se realiza la carga de los datos y un vistazo preliminar de la serie de tiempo en la Figura 1 .\n\n# Carga de la base de datos\ndian&lt;-read_excel(\"dian.xlsx\", range=\"A7:C313\", sheet = \"Rec mensual a junio 2023\" )\naños&lt;-2000:2023\ndian&lt;-dplyr::filter(dian,Año %in% años)\ncolnames(dian)&lt;-c(\"Año\",\"Mes\",\"Impuestos\")\ndian$fecha&lt;-as.Date(paste(dian$Año, dian$Mes, \"1\", sep = \"-\"), format = \"%Y-%B-%d\")\ndian&lt;-dian[,3:4]\n\n# Gráfico de la serie de tiempo\ndian2&lt;-ts(dian$Impuestos,start=c(2000,01),frequency=12)\nplot(dian2, main=\"Serie de tiempo del recaudo mensual interno\",\n     cex.main=1.3,\n     xlab=\"Tiempo\",\n     ylab=\"Recaudo interno\",\n     cex.lab=0.4)\n\n\n\n\nFigura 1: Gráfico de la serie de tiempo de la DIAN."
  },
  {
    "objectID": "Descriptivo Dian.html",
    "href": "Descriptivo Dian.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. «Literate Programming». Comput. J. 27 (2): 97-111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "Descriptivo Energia.html",
    "href": "Descriptivo Energia.html",
    "title": "2  Análisis descriptivo Energía",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "Descriptivo Dian.html#estabilización-de-la-varianza-marginal",
    "href": "Descriptivo Dian.html#estabilización-de-la-varianza-marginal",
    "title": "2  Análisis descriptivo del recaudo de impuestos internos por la DIAN",
    "section": "2.1 Estabilización de la varianza marginal",
    "text": "2.1 Estabilización de la varianza marginal\nTeniendo en cuenta lo observado utilizando el gráfico de la serie de tiempo, se puede evidenciar una heterocedasticidad marginal la cual debemos corregir, para esto utilizaremos la transformación de Box-cox, esto teniendo en cuenta que no se tienen valors negativos, de este modo se tiene que\n\nMASS::boxcox(lm(dian2 ~ 1),seq(-5, 5, length = 50)) ##Notese que no acputra al 1\n\n\n\nforecast::BoxCox.lambda(dian2, method =\"loglik\",\n                        lower = -1, upper = 3)#Entrega el valor de lambda (0.1).\n\n[1] 0.1\n\n\nCon el anterior gráfico y salida podemos observar que el valor que maximiza la log-verosimilitud es 0.1, pero este valor es bastante cercano a 0, por lo tanto lo aproximaremos para asi poder utilizar la transformación logaritmo, notese que el intervalo de confianza no captura al 1 por lo tanto puede ser conveniente realizar la transformación. En los gráficos posteriores analizaremos si dicha transformación logra estabilizar la varianza marginal de nuestros datos.\n\nplot(forecast::BoxCox(dian2,lambda=0.1))\n\n\n\npar(mar = c(1,1,1,1))\nldian2=log(dian2)\nMASS::boxcox(lm(ldian2 ~ 1),seq(-5, 5, length = 50)) #Si captura al 1\n\n\n\n\nNotese que el intervalo de confianza de la transformación Box-cox logra capturar el valor de 1, lo cual nos indica que no es necesario transformar los datos nuevamente y que la transformación ayudo de buena manera a estabilizar la varianza marginal de nuestra serie de tiempo.\nEn el siguiente gráfico mostramos la serie de recaudo de la Dian con y sin la transformación logaritmo y es posible observar que la escala disminuye pero a su vez se observan algunos cambios considerables en la forma de la serie, lo cual es un buen indicativo de la relevancia de realizar la transformación.\n\n#par(mfrow=c(2,1))\nplot(dian2,main=\"Serie Dian sin Transformar\")\n\n\n\nplot(ldian2,main=\"Series Dian con Transformación BoxCox\")\n\n\n\n\nTeniendo lo anterior en cuenta, presentaremos un gráfico de la serie sin tendencia un poco más interactivo e informativo, con el fin de lograr conocer los distintos valores en cada una de las fechas.\n\nclass(ldian2)\n\n[1] \"ts\"\n\ndian3<-window(ldian2, start = c(2000,1))\nts_plot(dian3,title=\"Serie de tiempo del recaudo mensual interno\",\n        Ytitle=\"Recaudo interno\",\n        Xtitle=\"Tiempo\",\n        Xgrid=TRUE,\n        Ygrid=TRUE)"
  },
  {
    "objectID": "index.html#análisis-del-consumo-de-energía-de-la-empresa-pjm",
    "href": "index.html#análisis-del-consumo-de-energía-de-la-empresa-pjm",
    "title": "Análisis de series de tiempo",
    "section": "Análisis del consumo de energía de la empresa PJM",
    "text": "Análisis del consumo de energía de la empresa PJM\nLa empresa PJM es una organización de transmisión regional que coordina el movimiento de electricidad mayorista en la totalidad, o parte, de 13 estados y el Distrito de Columbia.\nEl análisis del consumo de energía es esencial para mejorar la eficiencia operativa, reducir costos, cumplir con regulaciones y promover la sostenibilidad, por lo cual, este proyecto analiza la serie de tiempo con el fin de encontrar variaciones en el consumo de energía de los 13 estados y el Distrito de Columbia a lo largo del tiempo, así como también descubrir posibles patrones.\nA continuación se presenta la manera en que se realiza la carga de los datos y un vistazo preliminar de la serie de tiempo en la Figura 2 .\n\n# Carga de la base de datos\nAEP_hourly&lt;-read.csv(\"AEP_hourly.csv\")\nAEP_hourly$Datetime&lt;-as.POSIXct(AEP_hourly$Datetime, format = \"%Y-%m-%d %H:%M:%S\")\nAEP_hourly$fecha&lt;-as.Date(AEP_hourly$Datetime)\n\nenergia &lt;- AEP_hourly %&gt;%\n  group_by(fecha) %&gt;%\n  summarise(Energia = sum(AEP_MW))\nenergia&lt;-energia[-5055,]\n\n# Gráfico de la serie de tiempo\nenergia2&lt;-ts(energia$Energia,start=c(2004,10,01),frequency=365.25)\nplot(energia2, main=\"Serie de tiempo de la energía diaria de una empresa estadounidense\",\n     cex.main=1,\n     xlab=\"Tiempo \",\n     ylab=\"Energía consumida\",\n     cex.lab=0.4)\n\n\n\n\nFigura 2: Gráfico de la serie de tiempo de la energía."
  },
  {
    "objectID": "index.html#sobre-el-trabajo",
    "href": "index.html#sobre-el-trabajo",
    "title": "Análisis de series de tiempo",
    "section": "Sobre el trabajo",
    "text": "Sobre el trabajo\nEste trabajo realiza un análisis de dos bases de datos: Recaudo de impuestos internos por la DIAN para los años 2000 a 2023 y consumo de energía por horas de la organización regional de transmisión PJM Interconnection para los años 2004 a 2018. El análisis se desarrolla de forma estadística, realizando la parte descriptiva con su correspondiente interpretación."
  },
  {
    "objectID": "Descriptivo Energia.html#estabilización-de-la-varianza-marginal",
    "href": "Descriptivo Energia.html#estabilización-de-la-varianza-marginal",
    "title": "2  Análisis del consumo de energía de la empresa PJM",
    "section": "2.1 Estabilización de la varianza marginal",
    "text": "2.1 Estabilización de la varianza marginal\nComo se observa en la gráfica de la serie de tiempo no es necesario realizar una estabilización de la varianza para continuar con el análisis descriptivo, sin embargo, para comprobar esto, se hace una transformación de Box-cox para ver que tanto se estabiliza la varianza. En la Figura 2.2 se observa que se sugiere una transformación dado que 1 no está contenido en el intervalo.\n\nMASS::boxcox(lm(energia2 ~ 1),seq(-5, 5, length = 50))\nabline(v = 1, col = \"red\", lty = 2)\n\n\n\n\nFigura 2.2: Gráfico de la verosimilitud en función del hiperparámetro lambda.\n\n\n\n\nEn la siguiente salida se puede ver que el \\(\\lambda\\) sugerido es \\(-0.25\\), como es un número negativo, se procede a hacer la transformación Box-Cox usando logaritmo natural.\n\nforecast::BoxCox.lambda(energia2, method =\"loglik\",lower = -1, upper = 3)\n\n[1] -0.25\n\n\nEn la Figura 2.3 a continuación se muestra que la serie en escala logarítmica nuevamente no tiene la varianza estabilizada, dado que no se contiene al 1.\n\nlenergia2=log(energia2)\nMASS::boxcox(lm(lenergia2 ~ 1),seq(-5, 5, length =  50))\nabline(v = 1, col = \"red\", lty = 2)\n\n\n\n\nFigura 2.3: Gráfico de la verosimilitud para la serie en escala logarítmica, en función del hiperparámetro lambda.\n\n\n\n\nAdemás, se puede notar en la Figura 2.4 , que no hay una diferencia significativa entre la serie transformada y no transformada. Por lo que el análisis descriptivo se continúa usando los datos originales.\n\npar(mar = c(1,1,1,1))\npar(mfrow=c(2,1),mar=c(3,3,3,3))\nplot(energia2,main=\"Serie energía sin Transformar\",cex.main=1)\nplot(lenergia2,main=\"Serie energía con Transformación BoxCox\",cex.main=1)\n\n\n\n\nFigura 2.4: Serie original y serie con transformación logarítmica."
  },
  {
    "objectID": "Descriptivo Energia.html#estimación-preliminar-de-la-tendencia",
    "href": "Descriptivo Energia.html#estimación-preliminar-de-la-tendencia",
    "title": "2  Análisis del consumo de energía de la empresa PJM",
    "section": "2.2 Estimación preliminar de la tendencia",
    "text": "2.2 Estimación preliminar de la tendencia\nComo se observa en la gráfica de la serie de tiempo no es necesario realizar una estimación de la tendencia para continuar con el análisis descriptivo, sin embargo, se hace una estimación preliminar usando varios métodos.\n\n2.2.1 Tendencia lineal\n\n# Creación del objeto tibble\nenergia_1=energia %&gt;% map_df(rev)\nFechas=as.Date(energia_1$fecha)\nenergia_xts=xts(x = energia_1$Energia,frequency = 365.25,order.by = Fechas)\n\n# Creación objeto tssible a partir del objeto tibble\ndf_energia=data.frame(Energia=energia_1$Energia,fecha=energia_1$fecha)\ntbl_energia=tibble(df_energia)\ntbl_energia_format_fecha=tbl_energia\ntsbl_energia=as_tsibble(tbl_energia_format_fecha,index=fecha)\n\nEn la siguiente salida se presenta el ajuste de una regresión lineal para estimar la tendencia. Como el \\(R^2\\) es \\(0.058\\), se sugiere que no hay tendencia.\n\n# Análisis de tendencia con regresion simple\nsummary(fit_e&lt;-lm(energia2~time(energia2),na.action=NULL))\n\n\nCall:\nlm(formula = energia2 ~ time(energia2), na.action = NULL)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-137653  -34064   -5533   31129  179275 \n\nCoefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    6128528.2   325172.5   18.85   &lt;2e-16 ***\ntime(energia2)   -2862.7      161.7  -17.70   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 45920 on 5052 degrees of freedom\nMultiple R-squared:  0.05841,   Adjusted R-squared:  0.05823 \nF-statistic: 313.4 on 1 and 5052 DF,  p-value: &lt; 2.2e-16\n\n\nEn la Figura 2.4 se presenta la serie de tiempo de la energía con la estimación lineal de la tendencia.\n\nplot(energia2, main=\"Serie de tiempo de la energía diaria de una empresa estadounidense\",\n     cex.main=1,\n     xlab=\"Tiempo \",\n     ylab=\"Energía consumida\",\n     cex.lab=0.4)\nabline(fit_e,col=\"darkcyan\",lwd=2)\n\n\n\n\nFigura 2.4: Gráfico de la serie de tiempo de la energía con la estimación lineal de la tendencia.\n\n\n\n\nPosteriormente, se procede a eliminar la tendencia lineal, como se puede ver en la Figura 2.5 .\n\n# Eliminación de la tendencia con la predicción la recta\nElimiTendenerg&lt;-energia2-predict(fit_e)\nplot(ElimiTendenerg,main=\"Serie energía sin tendencia\",\n     cex.main=1.3,\n     xlab=\"Tiempo\",\n     ylab=\"Consumo de energía\",\n     cex.lab=0.4)\n\n\n\n\nFigura 2.5: Gráfico de la serie de tiempo de la energía sin tendencia estimada con regresión lineal.\n\n\n\n\n\n\n2.2.2 Tendencia con promedios móviles\nEn la Figura 2.6 , se muestra un ajuste de la tendencia con promedios móviles, como se puede ver, aparentemente hay una sobrestimación de la tendencia, ya que muestra comportamientos que no son tan visibles en la serie de tiempo original.\n\n# Descomposición filtro de promedios móviles\nenergia_decompo=decompose(energia2)\nplot(energia_decompo)\n\n\n\n\nFigura 2.6: Gráfico de la serie de tiempo de la energía sin tendencia estimada con promedios móviles.\n\n\n\n\n\n\n2.2.3 Tendencia con diferenciación\nEn la Figura 2.7 se presentan los gráficos de las series sin tendencia, estimada con regresión lineal y con diferenciación respectivamente, se puede notar que la serie sin tendencia estimada con diferenciación impide ver los ciclos que se ven en la serie original.\n\ntsibble_energia&lt;-as_tsibble(energia2)\npar(mar = c(2,2,2,2))\npar(mfrow=c(2,1))\n\nplot(resid(fit_e), type=\"l\", main=\"Sin tendencia\") \nplot(diff(energia2), type=\"l\", main=\"Primera Diferencia\") \n\n\n\n\nFigura 2.7: Gráfico de la serie de tiempo de la energía sin tendencia estimada con regresión lineal y diferenciación.\n\n\n\n\n\n\n2.2.4 Comparación de los ACF\nEn la Figura 2.8 se puede notar un descenso rápido hacia 0 para las series original y sin tendencia estimada con regresión lineal, mientras que para la serie sin tendencia estimada con diferenciación, se puede apreciar mejor el ciclo estacional de aproximadamente 7 días.\n\n# Gráficos de los ACF\npar(mar = c(3,2,3,2))\npar(mfrow=c(3,1))\nacf(energia2, 60, main=\"ACF energia\")\nacf(resid(fit_e), 60, main=\"ACF Sin tendencia\") \nacf(diff(energia2), 60, main=\"ACF Primera Diferencia\")\n\n\n\n\nFigura 2.8: Gráficos de autocorrelación para la serie original, sin tendencia estimada con regresión lineal y con la primera diferencia."
  },
  {
    "objectID": "Descriptivo Energia.html#estimación-de-la-estacionalidad",
    "href": "Descriptivo Energia.html#estimación-de-la-estacionalidad",
    "title": "2  Análisis del consumo de energía de la empresa PJM",
    "section": "2.4 Estimación de la estacionalidad",
    "text": "2.4 Estimación de la estacionalidad\n\n2.4.1 Detección de estacionalidad\n\nlineal_1&lt;-cbind(as.matrix(ElimiTendenerg),as.character(energia$fecha))\nlineal_1&lt;-as.data.frame(lineal_1)\nnames(lineal_1)&lt;-c(\"Energia\",\"fecha\")\n\nlineal_1$Energia&lt;-as.numeric(lineal_1$Energia)\nlineal_1$fecha&lt;-as.Date(lineal_1$fecha)\n\ndf_lineal=data.frame(Energia=lineal_1$Energia,fecha=lineal_1$fecha)\ntbl_lineal=tibble(df_lineal)\ntbl_lineal_format_fecha=tbl_lineal\ntsbl_lineal=as_tsibble(tbl_lineal_format_fecha,index=fecha)\n\nEn la Figura 2.10 se presenta el gráfico de subseries diarias para la serie original, se puede ver que hay estacionalidad ya que el valor medio del día domingo por ejemplo, es menor al del resto de días.\n\n# Gráfica de subseries semanal con datos originales\ngg_subseries(tsbl_lineal,y=Energia,period=7)\n\n\n\n\nFigura 2.10: Gráfica de subseries diarias.\n\n\n\n\nEn la Figura 2.11 se presenta el gráfico de subseries mensuales para la serie original, se puede ver que no hay ciclos estacionales mensuales, ya que todos tienen la misma media. Sin embargo, esto puede deberse a la presencia de la múlriple estacionalidad.\n\n# Gráfica de subseries anual con datos originales\ngg_subseries(tsbl_lineal,y=Energia,period=12)\n\n\n\n\nFigura 2.11: Gráfica de subseries anuales.\n\n\n\n\n\nenergia_df&lt;-cbind(as.matrix(ElimiTendenerg),as.character(energia$fecha))\nenergia_df&lt;-as.data.frame(energia_df)\nnames(energia_df)&lt;-c(\"Energia\",\"Fecha\")\n\nenergia_df$Fecha&lt;-as.Date(energia_df$Fecha)\nenergia_df$time = as.POSIXct(energia_df$Fecha, \"%Y-%m-%d\")\nenergia_df$weekday &lt;- wday(energia_df$time, label = TRUE, abbr = TRUE)\nenergia_df$month &lt;- factor(month.abb[month(energia_df$time)], levels =   month.abb)\n\n# Agrupamos por mes y día\nenergia_df$Energia&lt;-as.numeric(energia_df$Energia)\nenergia_mensual &lt;- energia_df %&gt;%\n  dplyr::filter(weekday == \"dom\\\\.\" | weekday == \"mar\\\\.\" ) %&gt;% # martes se parece al comportamiento de lunes-viernes, domingo se parece a sabado\n  dplyr::group_by(weekday, month) %&gt;%\n  dplyr::summarise(mean = mean(Energia, na.rm = TRUE),\n                   sd = sd(Energia, na.rm = TRUE))\n\n# Grafico consumo (diferenciado) de energia mensual por dia\nplot_ly(data = energia_mensual, x = ~ month, y = ~ mean, type =\n          \"bar\",color = ~ weekday) %&gt;%\n  layout(title = \"Promedio diario de energía por día de la semana\",\n         yaxis = list(title = \"Media\"),\n         xaxis = list(title = \"Mes\"))\n\n\n\n\n\n\n\n2.4.2 Periodograma\nEn la Figura 2.12 se presenta el periodograma para la serie sin tendencia lineal, el valor del periodo donde se maximiza el periodograma nuevamente es \\(182.86\\), es decir, aproximadamente, el ciclo es de medio año.\n\n# Periodograma sin tendencia lineal\nspectrum(as.numeric(ElimiTendenerg),log='no')\n\nPeriodogramaEnergia2_lineal=spectrum(as.numeric(ElimiTendenerg),log='no')\nubicacionlogenergia=which.max(PeriodogramaEnergia2_lineal$spec)\n\nsprintf(\"El valor de la frecuencia donde se maximiza el periodograma para la serie es: %s\",PeriodogramaEnergia2_lineal$freq[ubicacionlogenergia])\n\n[1] \"El valor de la frecuencia donde se maximiza el periodograma para la serie es: 0.00546875\"\n\nsprintf(\"El periodo correspondiente es aproximadamente: %s\",1/PeriodogramaEnergia2_lineal$freq[ubicacionlogenergia])\n\n[1] \"El periodo correspondiente es aproximadamente: 182.857142857143\"\n\n\n\n\n\nFigura 2.12: Periodograma para la serie sin tendencia lineal.\n\n\n\n\n\n2.4.2.1 Para la serie sin tendencia usando diferenciación\nEn la Figura 2.13 se presenta el periodograma para la serie sin tendencia estimada usando diferenciación, el valor del periodo donde se maximiza el periodograma es \\(3.5\\), es decir, aproximadamente, el ciclo es de tres días.\n\n# Periodograma diferenciación\nspectrum(as.numeric(diff(energia2)),log='no')\n\nPeriodogramaEnergia2_dif=spectrum(as.numeric(diff(energia2)),log='no')\nubicacionlogenergia=which.max(PeriodogramaEnergia2_dif$spec)\n\nsprintf(\"El valor de la frecuencia donde se maximiza el periodograma para la serie es: %s\",PeriodogramaEnergia2_dif$freq[ubicacionlogenergia])\n\n[1] \"El valor de la frecuencia donde se maximiza el periodograma para la serie es: 0.2857421875\"\n\nsprintf(\"El periodo correspondiente es aproximadamente: %s\",1/PeriodogramaEnergia2_dif$freq[ubicacionlogenergia])\n\n[1] \"El periodo correspondiente es aproximadamente: 3.49965823650034\"\n\n\n\n\n\nFigura 2.13: Periodograma para la serie sin tendencia usando diferenciación.\n\n\n\n\n\n\n\n2.4.3 Estimación\nAhora procederemos a estimar el ciclo estacional que se observa en esta serie de tiempo, es importante resaltar que con ayuda de los graficos exploratorios y el periodograma se observo que el periodo de la componente estacional es \\(s=12\\), por lo tanto utilizaremos en primer lugar componentes de fourier, esto teniendo en cuenta que se aprecia que la componente estacional sigue un comportamiento deterministico y posiblemente sinosoidal. Teniendo lo anterior en cuenta el modelo viene dado por: \\[\\begin{align*} x_t&= ∑_{i=1}^k a_icos(k𝜔t)+b_isen(k𝜔t) + w_t \\\\ \\end{align*}\\] Donde \\(k\\) corresponderá al orden de la expansión en series de Fourier y los coeficientes \\(a_i\\) y \\(b_i\\) con \\(i=1,...,k\\) serán estimados a través del método de mínimos cuadrados. El cálculo de esta componente se muestra a continuación considerando un orden \\(k=3\\).\n\n# Frecuencia angular w=2*pi/s\nfrec_ang=(2*pi/182)\nfrec_ang2=(2*pi/7)\n\nenergia_copia&lt;-cbind(as.matrix(ElimiTendenerg),as.character(energia$fecha))\nenergia_copia&lt;-as.data.frame(energia_copia)\nnames(energia_copia)&lt;-c(\"Energia\",\"fecha\")\n\nenergia_copia$fecha&lt;-as.Date(energia_copia$fecha)\n\n#Fourier k=1 \nenergia_copia$sin = sin(c(1:5054)*(1*frec_ang))\nenergia_copia$cos = cos(c(1:5054)*(1*frec_ang))\n\n#Fourier k=2 \nenergia_copia$sin2 = sin(c(1:5054)*(2*frec_ang))\nenergia_copia$cos2 = cos(c(1:5054)*(2*frec_ang))\n\n#Fourier k=3 \nenergia_copia$sin3 = sin(c(1:5054)*(3*frec_ang))\nenergia_copia$cos3 = cos(c(1:5054)*(3*frec_ang))\n\n\n#Fourier k=1 \nenergia_copia$sin4 = sin(c(1:5054)*(1*frec_ang2))\nenergia_copia$cos4 = cos(c(1:5054)*(1*frec_ang2))\n\n#Fourier k=2 \nenergia_copia$sin5 = sin(c(1:5054)*(2*frec_ang2))\nenergia_copia$cos5 = cos(c(1:5054)*(2*frec_ang2))\n\n#Fourier k=3 \nenergia_copia$sin6 = sin(c(1:5054)*(3*frec_ang2))\nenergia_copia$cos6 = cos(c(1:5054)*(3*frec_ang2))\n\nlinmodel_ciclo&lt;-lm(Energia~1+sin+cos+sin2+cos2+sin3+cos3+sin4+cos4+sin5+cos5+sin6+cos6,data=energia_copia)\n\nresults_ciclo=linmodel_ciclo$fitted.values\nresults_ciclo&lt;-as.data.frame(results_ciclo)\nresults_ciclo_ts&lt;-ts(results_ciclo,start=c(2004,10,01),frequency=365.25)\n\nplot(ElimiTendenerg, main=\"Serie de tiempo de la energía diaria de una empresa estadounidense\",\n     cex.main=1.3,\n     xlab=\"Tiempo \",\n     ylab=\"Energía consumida\",\n     cex.lab=0.4)\nlines(results_ciclo_ts,col=\"red\")\n\n\n\nplot(ElimiTendenerg, main=\"Serie de tiempo de la energía diaria de una empresa estadounidense\",\n     cex.main=1.3,\n     xlab=\"Tiempo \",\n     ylab=\"Energía consumida\",\n     cex.lab=0.4,\n     xlim=c(2004,2007))\nlines(results_ciclo_ts,col=\"red\",xlim=c(2004,2007))\n\n\n\n\nEn la ?fig-energestacionalidad se presenta la serie original con la estimación de la componente estacional via componentes de Fourier y la serie sin estacionalidad. Se puede notar que las componentes de Fourier logran captar bien es cíclo estacional que tiene la serie. Se toma una componente de Fourier, ya que no hay una diferencia visible al utilizar 2 y 3.\n\nenergia_estacionarios&lt;-ElimiTendenerg-results_ciclo_ts\nsaveRDS(energia_estacionarios, file=\"energia_estacionarios.RDS\")\nplot(ElimiTendenerg-results_ciclo_ts)\nplot(ElimiTendenerg-results_ciclo_ts,xlim=c(2004,2007))\n\n\n\n\nFigura 2.14: Serie original con estamación de la componente estacional y serie sin estacionalidad.\n\n\n\n\n\n\n\nFigura 2.15: Serie original con estamación de la componente estacional y serie sin estacionalidad.\n\n\n\n\nA continuación, presentaremos el modelo de árboles y ell modelo de redes neuronales multicapa paraa esta serie de tiempo, disponible aquí."
  },
  {
    "objectID": "Descriptivo Energia.html#estimación-de-la-tendencia",
    "href": "Descriptivo Energia.html#estimación-de-la-tendencia",
    "title": "2  Análisis del consumo de energía de la empresa PJM",
    "section": "2.2 Estimación de la tendencia",
    "text": "2.2 Estimación de la tendencia\nComo se observa en la gráfica de la serie de tiempo no es necesario realizar una estimación de la tendencia para continuar con el análisis descriptivo, sin embargo, se hace una estimación preliminar usando varios métodos, con el fin de comprobar que la serie sin tendencia no varía mucho.\n\n2.2.1 Tendencia lineal\n\n# Creación del objeto tibble\nenergia_1=energia %&gt;% map_df(rev)\nFechas=as.Date(energia_1$fecha)\nenergia_xts=xts(x = energia_1$Energia,frequency = 365.25,order.by = Fechas)\n\n# Creación objeto tssible a partir del objeto tibble\ndf_energia=data.frame(Energia=energia_1$Energia,fecha=energia_1$fecha)\ntbl_energia=tibble(df_energia)\ntbl_energia_format_fecha=tbl_energia\ntsbl_energia=as_tsibble(tbl_energia_format_fecha,index=fecha)\n\nEn la siguiente salida se presenta el ajuste de una regresión lineal para estimar la tendencia. El \\(R^2\\) indíca qué tan bien se ajusta la recta a los datos, en este caso tiene un valor de \\(0.058\\), por lo que sugiere que no hay tendencia lineal.\n\n# Análisis de tendencia con regresion simple\nsummary(fit_e&lt;-lm(energia2~time(energia2),na.action=NULL))\n\n\nCall:\nlm(formula = energia2 ~ time(energia2), na.action = NULL)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-137653  -34064   -5533   31129  179275 \n\nCoefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    6128528.2   325172.5   18.85   &lt;2e-16 ***\ntime(energia2)   -2862.7      161.7  -17.70   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 45920 on 5052 degrees of freedom\nMultiple R-squared:  0.05841,   Adjusted R-squared:  0.05823 \nF-statistic: 313.4 on 1 and 5052 DF,  p-value: &lt; 2.2e-16\n\n\nEn la Figura 2.5 se presenta la serie de tiempo de la energía con la estimación lineal de la tendencia.\n\nplot(energia2, main=\"Serie de tiempo de la energía diaria de una empresa estadounidense\",\n     cex.main=1,\n     xlab=\"Tiempo \",\n     ylab=\"Energía consumida\",\n     cex.lab=0.4)\nabline(fit_e,col=\"darkcyan\",lwd=2)\n\n\n\n\nFigura 2.5: Gráfico de la serie de tiempo de la energía con la estimación lineal de la tendencia.\n\n\n\n\nPosteriormente, se procede a eliminar la tendencia lineal, como se puede ver en la Figura 2.6 .\n\n# Eliminación de la tendencia con la predicción la recta\nElimiTendenerg&lt;-energia2-predict(fit_e)\nplot(ElimiTendenerg,main=\"Serie energía sin tendencia\",\n     cex.main=1.3,\n     xlab=\"Tiempo\",\n     ylab=\"Consumo de energía\",\n     cex.lab=0.4)\n\n\n\n\nFigura 2.6: Gráfico de la serie de tiempo de la energía sin tendencia estimada con regresión lineal.\n\n\n\n\n\n\n2.2.2 Tendencia con promedios móviles\nEn la Figura 2.7 , se muestra un ajuste de la tendencia con promedios móviles, como se puede ver, aparentemente hay una sobrestimación de la tendencia, ya que muestra comportamientos que no son tan visibles en la serie de tiempo original.\n\n# Descomposición filtro de promedios móviles\nenergia_decompo=decompose(energia2)\nplot(energia_decompo)\n\n\n\n\nFigura 2.7: Gráfico de la serie de tiempo de la energía sin tendencia estimada con promedios móviles.\n\n\n\n\n\n\n2.2.3 Tendencia con diferenciación\nEn la Figura 2.8 se presentan los gráficos de las series sin tendencia, estimada con regresión lineal y con diferenciación respectivamente, se puede notar que la serie sin tendencia estimada con diferenciación impide ver los ciclos que se ven en la serie original.\n\ntsibble_energia&lt;-as_tsibble(energia2)\npar(mar = c(2,2,2,2))\npar(mfrow=c(2,1))\n\nplot(resid(fit_e), type=\"l\", main=\"Sin tendencia lineal\") \nplot(diff(energia2), type=\"l\", main=\"Primera Diferencia\") \n\n\n\n\nFigura 2.8: Gráfico de la serie de tiempo de la energía sin tendencia estimada con regresión lineal y diferenciación.\n\n\n\n\n\n\n2.2.4 Comparación de los ACF\nEn la Figura 2.9 se puede notar un descenso rápido hacia 0 para las series original y sin tendencia estimada con regresión lineal, mientras que para la serie sin tendencia estimada con diferenciación, se puede apreciar mejor el ciclo estacional de aproximadamente 7 días.\n\n# Gráficos de los ACF\npar(mar = c(3,2,3,2))\npar(mfrow=c(3,1))\nacf(energia2, 60, main=\"ACF energia\")\nacf(resid(fit_e), 60, main=\"ACF Sin tendencia\") \nacf(diff(energia2), 60, main=\"ACF Primera Diferencia\")\n\n\n\n\nFigura 2.9: Gráficos de autocorrelación para la serie original, sin tendencia estimada con regresión lineal y con la primera diferencia.\n\n\n\n\nSi bien se estima la tendencia con diferentes métodos, se decide trabajar con la serie sin tendencia líneal."
  },
  {
    "objectID": "Descriptivo Dian.html#tendencia-estimación-y-eliminación",
    "href": "Descriptivo Dian.html#tendencia-estimación-y-eliminación",
    "title": "2  Análisis descriptivo del recaudo de impuestos internos por la DIAN",
    "section": "2.2 Tendencia Estimación y eliminación",
    "text": "2.2 Tendencia Estimación y eliminación\nLuego de estabilizar la varianza marginal de nuestra serie, procederemos a estimar la tendencia y a eliminarla. Para estimar dicha tendencia inicaremos utilizando una tendencia lineal deterministica y posteriormente restaremos dicha tendencia estimada a los datos de nuestra serie, de este modo se tiene lo siguiente:\n\nsummary(fit<-lm(ldian2~time(ldian2),na.action=NULL))\n\n\nCall:\nlm(formula = ldian2 ~ time(ldian2), na.action = NULL)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.6587 -0.2338  0.0349  0.2164  0.8567 \n\nCoefficients:\n               Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -188.74811    5.53318  -34.11   <2e-16 ***\ntime(ldian2)    0.10150    0.00275   36.90   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3133 on 280 degrees of freedom\nMultiple R-squared:  0.8295,    Adjusted R-squared:  0.8289 \nF-statistic:  1362 on 1 and 280 DF,  p-value: < 2.2e-16\n\nplot(ldian2,ylab=\"Recaudo interno\") \nabline(fit,col=\"darkcyan\",lwd=2)\n\n\n\n\nPreliminarmente es posible ver que la recta se ajusta de un buen modo a nuestra serie de tiempo, puesto que la tendencia de nuestra serie es creciente, ahora procederemos a observar la serie de tiempo al eliminar la tendencia utilizando este metodo y tenemos lo siguiente:\n\nElimiTenddian<-ldian2-predict(fit)\nplot(ElimiTenddian,main=\"Serie Dian sin tendencia y con varianza estable\",\n     cex.main=1.3,\n     xlab=\"Tiempo\",\n     ylab=\"Recaudo interno\",\n     cex.lab=0.4)\n\n\n\n\nEs posible observar que nuestra serie de tiempo cambio considerablemente, puesto que la escala de los valores se disminujo bastante y además los datos oscilan al rededor del 0, lo cual nos indica que nuestra serie no presenta tendencia\n\nacf(ElimiTenddian,lag.max=179,main=\"Acf Serie Dian sin tendencia\")\n\n\n\n\nNotese que el gráfico de autocorrelación, nos indica preliminarmente la presencia de posibles componente estacionales, pero esto lo analizaremos un poco más en detalle más adelante.\nPero este no es el unico modo de realizar la estimación de la tendencia, tambien podemos utilizar herramientas no parametricas, pero como no hemos identificado la componente estacional, estas nos daran una estimación preliminar de la tendencia. La primera de ellas que vamos a utilizar es la descomposición via filtros de promedios moviles, que se presenta a continuación:\n\ndian_decompo=decompose(ldian2)\nplot(dian_decompo)\n\n\n\n#dian_decompo$trend\n\nNotese que la tendencia estimada via filtros de promedio moviles es aproximadamente lineal, lo cual respalda la idea de utilizar la forma deterministica de estimar la varianza, además parece estimar de mdodo correcto la componente estacional y en la componente residual se observan algunos patrones estacionales.\nAhora procederemos a utilizar la descomposción STL, para hacer un análisis similar.\n\nlibrary(feasts)\nlibrary(fable)\n### Gráfico ##\ntsibble_dian<-as_tsibble(ldian2)\nstr(tsibble_dian)\n\ntbl_ts [282 × 2] (S3: tbl_ts/tbl_df/tbl/data.frame)\n $ index: mth [1:282] 2000 ene., 2000 feb., 2000 mar., 2000 abr., 2000 may., 200...\n $ value: num [1:282] 14.2 13.9 14 14.1 14.1 ...\n - attr(*, \"key\")= tibble [1 × 1] (S3: tbl_df/tbl/data.frame)\n  ..$ .rows: list<int> [1:1] \n  .. ..$ : int [1:282] 1 2 3 4 5 6 7 8 9 10 ...\n  .. ..@ ptype: int(0) \n - attr(*, \"index\")= chr \"index\"\n  ..- attr(*, \"ordered\")= logi TRUE\n - attr(*, \"index2\")= chr \"index\"\n - attr(*, \"interval\")= interval [1:1] 1M\n  ..@ .regular: logi TRUE\n\ntsibble_dian %>%\n  model(\n    STL(value ~ trend() +\n          season(window = \"periodic\"),\n        robust = TRUE)) %>%\n  components() %>%\n  autoplot()\n\n\n\n#tsibble_dian_notendstl<-tsibble_dian$Log\n\nNotese que el gráfico anterior es bastante similar al obtenido utilizando filtro de promedios moviles y podemos realizar una interpretación bastante similar, Tambien es posible eliminar la tendencia utilizando diferenciación, pero se debe tener en cuenta que la diferenciación tambien puede eliminar la componente estacional que se tenga presente en la serie de tiempo, a continuación se muestra la manera en que se realizó la eliminación de la tendencia utilizando la diferenciación y su comparación con el primer metodo para eliminar tendencia utilizado.\n\npar(mar = c(2,2,2,2))\nfitdian = lm(ldian2~time(ldian2), na.action=NULL) \npar(mfrow=c(2,1))\nplot(resid(fitdian), type=\"l\", main=\"sin tendencia\") \nplot(diff(ldian2), type=\"l\", main=\"Primera Diferencia\") #Primera diferencia ordinaria\n\n\n\n\nNotese que cuando eliminamos la tendencia utilizando la diferenciación se observa un poco más centrada en comparación a cuando utilizamos la regresión lineal ajustada, esto puede ser producto de la posible eliminación de la componente estacional producto de la utilización de la diferenciación Revisar bien esta interpretacion con las muchachas\nEn el siguiente grafico se compara las funciones de autocorrelación obtenidas para la series cuando eliminamos la tendencia utilizando lm y utilizando diferenciación, junto con la función de autocorrelación para la serie de tiempo con varianza marginal estable.\n\npar(mar = c(3,2,3,2))\npar(mfrow=c(3,1)) # plot ACFs\nacf(ldian2, 60, main=\"ACF Dian objeto ts varianza estable por boxcox\")\nacf(resid(fitdian), 60, main=\"ACF Sin tendencia (resid(fitdian))\") \nacf(diff(ldian2), 60, main=\"ACF Primera Diferencia\")\n\n\n\n\nFalta interpretación WAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA"
  },
  {
    "objectID": "Descriptivo Dian.html#detección-de-estacionalidad",
    "href": "Descriptivo Dian.html#detección-de-estacionalidad",
    "title": "2  Análisis descriptivo del recaudo de impuestos internos por la DIAN",
    "section": "2.3 Detección de estacionalidad",
    "text": "2.3 Detección de estacionalidad\nLuego de estabilizar la varianza marginal y de tratar la tendencia, procedemos a observar si existe presencia de posibles ciclos o ciclos estacionales, para dicha tarea vamos a emplear multiples metodos descriptivos que nos permiten obtener información sobre esta componente. Iniciaremos por observar el grafico de retardos, el cual viene dado a continuación:\n\nts_info(ElimiTenddian)\n\n The ElimiTenddian series is a ts object with 1 variable and 282 observations\n Frequency: 12 \n Start time: 2000 1 \n End time: 2023 6 \n\npar(mar = c(3,2,3,2))\nastsa::lag1.plot(ElimiTenddian, 12,corr=F)\n\n\n\nts_lags(ElimiTenddian,lags=1:12)\n\n\n\n\n\nEl gráfico de retardos nos indica de manera descriptiva la posible relación existente entre un tiempo y algunos de sus retardos, para este caso en particular se toman 12 retardos (esto teniendo en cuenta la frecuencia mensual de la serie de tiempo), en este caso es posible observar que existe una clara relación lineal y directa con el rezago 12, los demás rezagos no parecen ser del todo significativos. Notese que los dos graficos anteriores nos dan una información bastante similar.\nAhora observemos el gráfico de subseries, el cual toma los valores por cada mes de cada uno de los años dentro la serie, como sabemos buscamos obsevar si en el historico encontramos dieferentes valores medio mes tras mes, de este modo tenemos lo siguiente:\n\nrequire(feasts)\ndian2_tsbl_notend=as_tsibble(ElimiTenddian)\ndian2_tsbl_notend%>%gg_subseries(value)\n\n\n\n\nEs posible observar que la media en cada uno de los meses es distinta, esto es un claro indicio de la presencia de una componente ciclica estacional o ciclica, a contibuación se presentan algunas otras graficas descriptivas para observar la presencia de un ciclo estaciona.\n\ndian2sint_df <- data.frame(year = floor(time(ElimiTenddian)), month = cycle(ElimiTenddian),ElimiTenddian = as.numeric(ElimiTenddian))\ndian2sint_df$month <- factor(month.abb[dian2sint_df$month], levels = month.abb)\ndian2sint_summary <- dian2sint_df %>%group_by(month) %>%summarise(mean= mean(ElimiTenddian),sd = sd(ElimiTenddian))\ndian2sint_summary\n\n# A tibble: 12 × 3\n   month    mean     sd\n   <fct>   <dbl>  <dbl>\n 1 Jan    0.320  0.150 \n 2 Feb   -0.230  0.206 \n 3 Mar   -0.0446 0.0880\n 4 Apr    0.244  0.311 \n 5 May    0.196  0.226 \n 6 Jun    0.199  0.259 \n 7 Jul    0.0320 0.123 \n 8 Aug   -0.230  0.255 \n 9 Sep    0.240  0.187 \n10 Oct   -0.386  0.128 \n11 Nov    0.0676 0.0882\n12 Dec   -0.439  0.0985\n\nplot_ly (data = dian2sint_summary, x = ~ month, y = ~ mean, type = \"bar\", name   = \"Mean\") %>%\n  layout (title = \"dian2sint - Monthly Average\", yaxis =list(title = \"Mean\",   range = c(min(dian2sint_summary$mean), max(dian2sint_summary$mean))))\n\n\n\n\n\nEn el anterior gráfico se observa el valor medio tomado por cada uno de los meses, es posible observar que tiene un comportamiento parecido al grafico de subseries y de manera analoga nos muestra que exite una componente estacional.\nA continuación se muestran los mapas de calor para la serie Dian con varianza maeginal estable y tendencia eliminada por el metodo de diferenciacion y lineal.\n\nTSstudio::ts_heatmap(ElimiTenddian,title = \"Mapa de Calor - Impuestos Dian sin tendencia\")\n\n\n\n\nTSstudio::ts_heatmap(diff(ldian2),title = \"Mapa de Calor - Impuestos Dian sin tendencia\")\n\n\n\n\n\nAmbos mapas nos dan una información similar, en los cuales es posible observar que en los meses de noviembre, enero, junio, mayo y abril se tienen una mayor cantidad de recaudo de impuestos, mientras que en diciembre,octubre, agosto, marzo y febrero tienen un menor valor de recaudo de impuestos año tras año, nuevamente este gráfico nos ayuda a comprender la existencia de un cliclo estacional que posiblemente tenga un periodo de 12 meses.\n\n2.3.1 Periodograma\nCuando hablamos de una componente estacional dentro de nuestra serie de tiempo, tambien necesitamos hablar de su periodo y de su frecuencia, para esto utilizaremos el periodograma.\n\nspectrum(as.numeric(ElimiTenddian),log='no')\nabline(v=0.5, lty=2,col=\"red\")\n\n\n\nspectrum(as.numeric(ElimiTenddian),log='no',span=5)\n\n\n\nspectrum(as.numeric(ElimiTenddian),log='no',span=c(5,5))\n\n\n\nspectrum(as.numeric(ElimiTenddian),log='no',span=c(2,2))\n\n\n\n\nNotese que en los graficos anteriores se tienen diferentes valores de suavizamiento para nuestro periodograma, pues aunque en este caso no es dificil observar los puntos donde se tiene un pico, el suavizamiento puede ayudarnos a observar de mdood más simple los picos que son verdaderamente significativos.\n\nPeriodgramadldian2_sintendencia=spectrum(as.numeric(ElimiTenddian),log='no')\n\n\n\nubicacionlogdian=which.max(Periodgramadldian2_sintendencia$spec)\nsprintf(\"El valor de la frecuencia donde se máximiza el periodograma para la serie es: %s\",Periodgramadldian2_sintendencia$freq[ubicacionlogdian])\n\n[1] \"El valor de la frecuencia donde se máximiza el periodograma para la serie es: 0.5\"\n\nsprintf(\"El periodo correspondiente es aproximadamente: %s\",1/Periodgramadldian2_sintendencia$freq[ubicacionlogdian])\n\n[1] \"El periodo correspondiente es aproximadamente: 2\"\n\n\nNotese que según la salida obtenida, la frecuencia maxima se alcanza en 0.5 (es decir en 6/12=0.5) y se obtuvo que el periodo es 2, esto quiere decir que el ciclo se repite cada dos meses, pero notese que este es un multiplo no entero de 12, por lotanto en realidad se tiene que el periodo de la componente estacional serie de tipo anual (12 meses) Mirar esta interpretación con las muchachas y preguntar al profe si esta correcto."
  },
  {
    "objectID": "Descriptivo Dian.html#desestacionalizar-o-eliminación-de-la-componente-estacional",
    "href": "Descriptivo Dian.html#desestacionalizar-o-eliminación-de-la-componente-estacional",
    "title": "2  Análisis descriptivo del recaudo de impuestos internos por la DIAN",
    "section": "2.4 Desestacionalizar o eliminación de la componente estacional",
    "text": "2.4 Desestacionalizar o eliminación de la componente estacional"
  },
  {
    "objectID": "Descriptivo Dian (2).html#estabilización-de-la-varianza-marginal",
    "href": "Descriptivo Dian (2).html#estabilización-de-la-varianza-marginal",
    "title": "1  Análisis descriptivo del recaudo de impuestos internos por la DIAN",
    "section": "1.1 Estabilización de la varianza marginal",
    "text": "1.1 Estabilización de la varianza marginal\nTeniendo en cuenta lo observado utilizando el gráfico de la serie de tiempo, se puede evidenciar una heteroscedasticidad marginal la cual debemos corregir, para esto utilizaremos la transformación de Box-cox, la cual está dada por la siguiente fórmula. \\[\\begin{equation}\n    f_{\\lambda}(u_{t})= \\begin{cases}\n        \\lambda^{-1}(u^{\\lambda}_{t}-1), &  \\text{si  $u_{t} \\geq 0$, para $\\lambda&gt;0$,}\\\\\n        \\ln(u_{t}), &\\text{ si $u_{t}&gt;0$, para $\\lambda=0$}.\n    \\end{cases}\n\\end{equation}\\]\nDonde el \\(λ\\) apropiado debe ser estimado. Nótese que esta transformación es posible, puesto que no se tienen valores negativos, de este modo se tiene según la Figura 1.1 que:\n\nMASS::boxcox(lm(dian2 ~ 1),seq(-5, 5, length = 50)) ##Notese que no acputra al 1\nforecast::BoxCox.lambda(dian2, method =\"loglik\",\n                        lower = -1, upper = 3)#Entrega el valor de lambda (0.1).\n\n[1] 0.1\n\n\n\n\n\nFigura 1.1: Gráfico del valor lambda que maximiza la logverosmilitud.\n\n\n\n\nCon el anterior gráfico y salida podemos observar que el valor que maximiza la log-verosimilitud es 0.1, pero este valor es bastante cercano a 0, por lo tanto, lo aproximaremos a 0 para así poder utilizar la transformación logaritmo, nótese que el intervalo de confianza no captura al 1 en consecuencia puede ser conveniente realizar la transformación. En los gráficos de Figura 1.2 y Figura 1.3 analizaremos si dicha transformación logra estabilizar la varianza marginal de nuestros datos.\n\nplot(forecast::BoxCox(dian2,lambda=0.1))\n\n\n\n\nFigura 1.2: Grafico de la serie con varianza estable utilizando lambda=0.1.\n\n\n\n\n\npar(mar = c(1,1,1,1))\nldian2=log(dian2)\nMASS::boxcox(lm(ldian2 ~ 1),seq(-5, 5, length = 50)) #Si captura al 1\n\n\n\n\nFigura 1.3: Grafico de la serie con varianza estable utilizando el logaritmo.\n\n\n\n\nNótese que el intervalo de confianza de la transformación Box-cox logra capturar el valor de 1, lo cual nos indica que no es necesario transformar los datos nuevamente o buscar otro valor para \\(\\lambda\\), además la transformación ayudo de buena manera a estabilizar la varianza marginal de nuestra serie de tiempo.\nEn el gráfico Figura 1.4 y Figura 1.5 mostramos la serie de recaudo de la DIAN con y sin la transformación logaritmo y es posible observar que la escala disminuyey que a su vez se observan algunos cambios considerables en la forma de la serie, lo cual es un buen indicativo de la relevancia de realizar la transformación.\n\n#par(mfrow=c(2,1))\nplot(dian2,main=\"Serie Dian sin Transformar\")\n\n\n\n\nFigura 1.4: Serie DIAN sin transformar los datos utilizando el logaritmo.\n\n\n\n\n\nplot(ldian2,main=\"Series Dian con Transformación BoxCox\")\n\n\n\n\nFigura 1.5: Serie DIAN con transformación de los datos utilizando el logaritmo.\n\n\n\n\nTeniendo lo anterior en cuenta, presentaremos un gráfico (Figura 1.6) de la serie sin tendencia un poco más interactivo e informativo, con el fin de lograr conocer los distintos valores en cada una de las fechas.\n\nclass(ldian2)\n\n[1] \"ts\"\n\ndian3&lt;-window(ldian2, start = c(2000,1))\nts_plot(dian3,title=\"Serie de tiempo del recaudo mensual interno\",\n        Ytitle=\"Recaudo interno\",\n        Xtitle=\"Tiempo\",\n        Xgrid=TRUE,\n        Ygrid=TRUE)\n\n\n\n\nFigura 1.6: Gráfico de la serie DIAN con los datos transformados."
  },
  {
    "objectID": "Descriptivo Dian (2).html#tendencia-estimación-y-eliminación",
    "href": "Descriptivo Dian (2).html#tendencia-estimación-y-eliminación",
    "title": "1  Análisis descriptivo del recaudo de impuestos internos por la DIAN",
    "section": "1.2 Tendencia Estimación y eliminación",
    "text": "1.2 Tendencia Estimación y eliminación\nLuego de estabilizar la varianza marginal de nuestra serie, procederemos a estimar la tendencia y a eliminarla. Para estimar dicha tendencia iniciaremos utilizando una estimación lineal determinística de la tendencia y posteriormente restaremos la tendencia estimada a los datos de nuestra serie. EL ajuste de la recta se presenta en la Figura 1.7:\n\nsummary(fit&lt;-lm(ldian2~time(ldian2),na.action=NULL))\n\n\nCall:\nlm(formula = ldian2 ~ time(ldian2), na.action = NULL)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.6587 -0.2338  0.0349  0.2164  0.8567 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  -188.74811    5.53318  -34.11   &lt;2e-16 ***\ntime(ldian2)    0.10150    0.00275   36.90   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3133 on 280 degrees of freedom\nMultiple R-squared:  0.8295,    Adjusted R-squared:  0.8289 \nF-statistic:  1362 on 1 and 280 DF,  p-value: &lt; 2.2e-16\n\nplot(ldian2,ylab=\"Recaudo interno\") \nabline(fit,col=\"darkcyan\",lwd=2)\n\n\n\n\nFigura 1.7: Estimación de la tendencia de manera deterministica.\n\n\n\n\nPreliminarmente, es posible ver que la recta se ajusta de un buen modo a nuestra serie de tiempo, puesto que la tendencia de nuestra serie es monotona creciente, ahora procederemos a observar la serie de tiempo al eliminar la tendencia utilizando este método, esto se observa en la gráfica Figura 1.8:\n\nElimiTenddian&lt;-ldian2-predict(fit)\nplot(ElimiTenddian,main=\"Serie Dian sin tendencia y con varianza estable\",\n     cex.main=1.3,\n     xlab=\"Tiempo\",\n     ylab=\"Recaudo interno\",\n     cex.lab=0.4)\n\n\n\n\nFigura 1.8: Serie DIANsin tendencia.\n\n\n\n\nEs posible observar que nuestra serie de tiempo cambio considerablemente, puesto que la escala de los valores se disminuyó bastante y además los datos oscilan al rededor del 0, pero aun es posible observar una posible tendencia en nuestros datos, por lo tanto procedemos a analizar otras formas de eliminar la tendencia.\n\nacf(ElimiTenddian,lag.max=179,main=\"Acf Serie Dian sin tendencia\")\n\n\n\n\nFigura 1.9: Gráfico acf series DIAN sin tendencia.\n\n\n\n\nNótese que el gráfico de autocorrelación (Figura 1.9), nos indica preliminarmente la presencia de posibles componentes estacionales, pero esto lo analizaremos en detalle más adelante.\nPero este no es el único modo de realizar la estimación de la tendencia, también podemos utilizar herramientas no paramétricas, pero como no hemos identificado la componente estacional, estas nos darán una estimación preliminar de la tendencia. La primera de ellas que vamos a utilizar es la descomposición vía filtros de promedios móviles, que se presenta a continuación (Figura 1.10):\n\ndian_decompo=decompose(ldian2)\nplot(dian_decompo)\n#dian_decompo$trend\n\n\n\n\nFigura 1.10: Descomposición via filtros de promedio moviles.\n\n\n\n\nNótese que parece estimar de modo correcto la componente estacional y en la componente residual se observan algunos patrones estacionales, al análizar la tendencia de este modo, podemos ver que aunque parece bastante lineal existen algunos lugares donde se ajusta mejor a ciertos comportamientos de la serie, por lo tanto podria ser viable utilizar esta tecnica para explorar la componente de tendencia.\nAhora procederemos a utilizar la descomposición STL, para hacer un análisis similar(Figura 1.11).\n\nlibrary(feasts)\nlibrary(fable)\n### Gráfico ##\ntsibble_dian&lt;-as_tsibble(ldian2)\nstr(tsibble_dian)\n\ntbl_ts [282 × 2] (S3: tbl_ts/tbl_df/tbl/data.frame)\n $ index: mth [1:282] 2000 ene., 2000 feb., 2000 mar., 2000 abr., 2000 may., 200...\n $ value: num [1:282] 14.2 13.9 14 14.1 14.1 ...\n - attr(*, \"key\")= tibble [1 × 1] (S3: tbl_df/tbl/data.frame)\n  ..$ .rows: list&lt;int&gt; [1:1] \n  .. ..$ : int [1:282] 1 2 3 4 5 6 7 8 9 10 ...\n  .. ..@ ptype: int(0) \n - attr(*, \"index\")= chr \"index\"\n  ..- attr(*, \"ordered\")= logi TRUE\n - attr(*, \"index2\")= chr \"index\"\n - attr(*, \"interval\")= interval [1:1] 1M\n  ..@ .regular: logi TRUE\n\ntsibble_dian %&gt;%\n  model(\n    STL(value ~ trend() +\n          season(window = \"periodic\"),\n        robust = TRUE)) %&gt;%\n  components() %&gt;%\n  autoplot()\n\n\n\n\nFigura 1.11: Descomposición via STL.\n\n\n\n\n\n### Eliminando la tendencia por STL\nmodelo_stl &lt;- tsibble_dian %&gt;%\n  model(\n    STL(value ~ trend() +\n          season(window = \"periodic\"),\n        robust = TRUE)\n  ) %&gt;%\n  components()\n\n\nElimiTenddian_STL&lt;-ldian2-modelo_stl$trend\nplot(ElimiTenddian_STL,main=\"Serie Dian sin tendencia y con varianza estable (STL)\",\n     cex.main=1.3,\n     xlab=\"Tiempo\",\n     ylab=\"Recaudo interno\",\n     cex.lab=0.4)\n\n\n\n\nFigura 1.12: Desrie DIAN sin tendencia via STL.\n\n\n\n\nEs posible observar que el gráfico anterior (Figura 1.12) es bastante similar al obtenido utilizando filtro de promedios móviles (Figura 1.10) y podemos realizar una interpretación bastante similar, para continuar con nuestro análisis procederemos a continuar utilizando la eliminación de la tendencia via descomposición STL, pues es aquella que presenta un mejor desempeño,también es posible eliminar la tendencia utilizando diferenciación, pero se debe tener en cuenta que la diferenciación puede eliminar la componente estacional que se tenga presente en la serie de tiempo, a continuación se muestra la manera en que se realizó la eliminación de la tendencia utilizando la diferenciación y su comparación con el método STL para eliminar tendencia utilizado en este trabajo (Figura 1.13).\n\npar(mar = c(2,2,2,2))\nfitdian = lm(ldian2~time(ldian2), na.action=NULL) \npar(mfrow=c(2,1))\nplot(ElimiTenddian_STL, type=\"l\", main=\"Sin tendencia via STL\") \nplot(diff(ldian2), type=\"l\", main=\"Primera Diferencia\") #Primera diferencia ordinaria\n\n\n\n\nFigura 1.13: Serie DIAN sin tendencia via STL vs diferenciación.\n\n\n\n\nPodemos observar que a simple vista no hay diferencias muy importantes en cada una de las graficas, puesto que ambas se centran en 0 y parecen tener un comportamiento parecido.\nEn el siguiente gráfico (Figura 1.14) se compara las funciones de autocorrelación obtenidas para la serie cuando eliminamos la tendencia utilizando descomposición STL y utilizando diferenciación, junto con la función de autocorrelación para la serie de tiempo con tendencia.\n\npar(mar = c(3,2,3,2))\npar(mfrow=c(3,1)) # plot ACFs\nacf(ldian2, 60, main=\"ACF Dian con tendencia.\")\nacf(ElimiTenddian_STL, 60, main=\"ACF Sin tendencia STL.\") \nacf(diff(ldian2), 60, main=\"ACF Primera Diferencia.\")\n\n\n\n\nFigura 1.14: Comparacion de los gráficos acf.\n\n\n\n\nEn el anterior gráfico (Figura 1.14), podemos observar que al eliminar la tendencia, el gráfico ACF baja mucho más rápido en las series de tiempo donde se eliminó la tendencia (por el método STL, como por el método de diferenciación) en comparación con la serie a la cual solo se le ajustó la varianza marginal, pero tanto en la serie diferenciada como en la serie eliminada por STL, se observa la presencia de una alta correlación en rezagos de tamaño 12, lo cual es un indicio de la presencia de una componente estacional."
  },
  {
    "objectID": "Descriptivo Dian (2).html#detección-de-estacionalidad",
    "href": "Descriptivo Dian (2).html#detección-de-estacionalidad",
    "title": "1  Análisis descriptivo del recaudo de impuestos internos por la DIAN",
    "section": "1.3 Detección de estacionalidad",
    "text": "1.3 Detección de estacionalidad\nLuego de estabilizar la varianza marginal y de tratar la tendencia, procedemos a observar si existe presencia de posibles ciclos o ciclos estacionales, para dicha tarea vamos a emplear múltiples métodos descriptivos que nos permiten obtener información sobre esta componente. Iniciaremos por observar el gráfico de retardos, el cual viene dado a continuación:\n\nts_info(ElimiTenddian_STL)\n\n The ElimiTenddian_STL series is a ts object with 1 variable and 282 observations\n Frequency: 12 \n Start time: 2000 1 \n End time: 2023 6 \n\npar(mar = c(3,2,3,2))\nastsa::lag1.plot(ElimiTenddian_STL, 12,corr=F)\n\n\n\n\nFigura 1.15: Gráfico de retardos.\n\n\n\n\n\nts_lags(ElimiTenddian_STL,lags=1:12)\n\n\n\n\nFigura 1.16: Gráfico de retardos.\n\n\n\nEl gráfico de retardos dado en Figura 1.15 y Figura 1.16, nos indican de manera descriptiva la posible relación existente entre un tiempo y algunos de sus retardos, para este caso en particular se toman 12 retardos (esto teniendo en cuenta la frecuencia mensual de la serie de tiempo), en este caso es posible observar que existe una clara relación lineal y directa con el rezago 12, los demás rezagos no parecen ser del todo significativos. Nótese que los dos gráficos anteriores nos dan una información bastante similar.\nAhora observemos el gráfico de sub series (Figura 1.17), el cual toma los valores por cada mes de cada uno de los años dentro de la serie, como sabemos, se busca observar si en el histórico encontramos diferentes valores medios, mes tras mes, de este modo tenemos lo siguiente:\n\nrequire(feasts)\ndian2_tsbl_notend=as_tsibble(ElimiTenddian_STL)\ndian2_tsbl_notend%&gt;%gg_subseries(value)\n\n\n\n\nFigura 1.17: Gráfico de subseries.\n\n\n\n\nAl analizar el gráfico de sub series (Figura 1.17) es posible observar que la media en cada uno de los meses es distinta y no oscilan al rededor de un mismo valor, tomando su valor máximo en los meses de enero, disminuyendo luego en los meses de febrero y marzo, luego vuelve a aumentar y a mantenerse estable durante los meses de abril, mayo y junio. Esto es un claro indicio de la presencia de una componente cíclica estacional o cíclica. A continuación se presentan algunas otras gráficas descriptivas para observar la presencia de un ciclo estaciona.\n\ndian2sint_df &lt;- data.frame(year = floor(time(ElimiTenddian_STL)), month = cycle(ElimiTenddian_STL),ElimiTenddian_STL = as.numeric(ElimiTenddian_STL))\ndian2sint_df$month &lt;- factor(month.abb[dian2sint_df$month], levels = month.abb)\ndian2sint_summary &lt;- dian2sint_df %&gt;%group_by(month) %&gt;%summarise(mean= mean(ElimiTenddian_STL),sd = sd(ElimiTenddian_STL))\ndian2sint_summary\n\n# A tibble: 12 × 3\n   month    mean     sd\n   &lt;fct&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n 1 Jan    0.341  0.0923\n 2 Feb   -0.211  0.177 \n 3 Mar   -0.0279 0.0540\n 4 Apr    0.259  0.248 \n 5 May    0.209  0.139 \n 6 Jun    0.210  0.175 \n 7 Jul    0.0473 0.0589\n 8 Aug   -0.216  0.226 \n 9 Sep    0.254  0.123 \n10 Oct   -0.374  0.104 \n11 Nov    0.0777 0.0591\n12 Dec   -0.431  0.102 \n\nplot_ly (data = dian2sint_summary, x = ~ month, y = ~ mean, type = \"bar\", name   = \"Mean\") %&gt;%\n  layout (title = \"dian2sint - Monthly Average\", yaxis =list(title = \"Mean\",   range = c(min(dian2sint_summary$mean), max(dian2sint_summary$mean))))\n\n\n\n\nFigura 1.18: Promedio mensual.\n\n\n\nEn el anterior gráfico (Figura 1.18) se observa el valor medio tomado por cada uno de los meses, es posible observar que tiene un comportamiento parecido al gráfico de sub series y de manera análoga nos muestra que existe una componente estacional.\nA continuación se muestran los mapas de calor para la serie DIAN con varianza marginal estable y tendencia eliminada por el método de descomposición STL y el metodo de diferenciacio STL.\n\nTSstudio::ts_heatmap(ElimiTenddian_STL,title = \"Mapa de Calor - Impuestos Dian sin tendencia (STL)\")\n\n\n\n\nFigura 1.19: Graficos de calor serie DIAN sin tendencia por STLn.\n\n\n\n\nTSstudio::ts_heatmap(diff(ldian2),title = \"Mapa de Calor - Impuestos Dian sin tendencia (dif)\")\n\n\n\n\nFigura 1.20: Graficos de calor serie DIAN sin tendencia por diferenciación.\n\n\n\nAmbos mapas (Figura 1.19 y Figura 1.20) nos dan una información similar, en los cuales es posible observar que en los meses de noviembre, enero, junio, mayo y abril se tienen una mayor cantidad de recaudo de impuestos, mientras que en diciembre, octubre, agosto, marzo y febrero tienen un menor valor de recaudo de impuestos año tras año, pero se observa un valor grande en mayo del 2007, nuevamente este gráfico nos ayuda a comprender la existencia de un ciclo estacional que posiblemente tenga un periodo de 12 meses. Es importante resaltar que el tener un valor medio alto en el mes de enero puede deberse al pago del impuesto predial en los primeros meses del año.\nCuando hablamos de una componente estacional dentro de nuestra serie de tiempo, también necesitamos hablar de su periodo y de su frecuencia, para esto utilizaremos el periodograma.\n\nspectrum(as.numeric(ElimiTenddian_STL),log='no')\nabline(v=0.5, lty=2,col=\"red\")\n\n\n\n\nFigura 1.21: Peridograma serie DIAN.\n\n\n\n\n\nspectrum(as.numeric(ElimiTenddian_STL),log='no',span=5)\n\n\n\n\nFigura 1.22: Peridograma serie DIAN.\n\n\n\n\n\nspectrum(as.numeric(ElimiTenddian_STL),log='no',span=c(5,5))\n\n\n\n\nFigura 1.23: Peridograma serie DIAN.\n\n\n\n\n\nspectrum(as.numeric(ElimiTenddian_STL),log='no',span=c(2,2))\n\n\n\n\nFigura 1.24: Peridograma serie DIAN.\n\n\n\n\nAl observar los gráficos anteriores (Figura 1.21,Figura 1.22,Figura 1.23,Figura 1.24), es posible observar que se tienen diferentes valores de suavizamiento para nuestro periodograma, pues aunque en este caso no es difícil observar los puntos donde se tiene un pico, el suavizamiento puede ayudarnos a observar de modo más simple los picos que son verdaderamente significativos.\n\nPeriodgramadldian2_sintendencia=spectrum(as.numeric(ElimiTenddian_STL),log='no')\nubicacionlogdian=which.max(Periodgramadldian2_sintendencia$spec)\nsprintf(\"El valor de la frecuencia donde se máximiza el periodograma para la serie es: %s\",Periodgramadldian2_sintendencia$freq[ubicacionlogdian])\n\n[1] \"El valor de la frecuencia donde se máximiza el periodograma para la serie es: 0.5\"\n\nsprintf(\"El periodo correspondiente es aproximadamente: %s\",1/Periodgramadldian2_sintendencia$freq[ubicacionlogdian])\n\n[1] \"El periodo correspondiente es aproximadamente: 2\"\n\n\n\n\n\nFigura 1.25: Periodograma serie DIAN.\n\n\n\n\nNótese que según la salida obtenida, la frecuencia máxima se alcanza en 0.5 (es decir, en 6/12=0.5) y se obtuvo que el periodo es 2, esto quiere decir que el ciclo se repite cada dos meses, pero se tiene que 12 es un múltiplo de 2, por lo tanto, en realidad se tiene que el periodo de la componente estacional seria de tipo anual (12 meses)"
  },
  {
    "objectID": "Descriptivo Dian (2).html#desestacionalizar-o-eliminación-de-la-componente-estacional",
    "href": "Descriptivo Dian (2).html#desestacionalizar-o-eliminación-de-la-componente-estacional",
    "title": "1  Análisis descriptivo del recaudo de impuestos internos por la DIAN",
    "section": "1.4 Desestacionalizar o eliminación de la componente estacional",
    "text": "1.4 Desestacionalizar o eliminación de la componente estacional\nPara la estimación de la tendencia pasaremos al archivo en phyton, donde se presenta la eliminación de la tendencia nuevamente utilizando el metodo de descomposición STL, se estimara la componente estacional y por último se hará un modelo de árboles de decisión, un modelo de redes neuronales mutlicapa y un modelo de redes recurrentes, finalmente se va a comparar su desempeño basandonos en el error cuadratico medio."
  },
  {
    "objectID": "Descriptivo Energia.html#gráficas-de-retardos-e-índice-ami",
    "href": "Descriptivo Energia.html#gráficas-de-retardos-e-índice-ami",
    "title": "2  Análisis del consumo de energía de la empresa PJM",
    "section": "2.3 Gráficas de retardos e índice AMI",
    "text": "2.3 Gráficas de retardos e índice AMI\n\npar(mar = c(3, 2, 3, 2))\nastsa::lag1.plot(ElimiTendenerg, 7,corr=F)\n\n\n\n\n\ntseriesChaos::mutual(ElimiTendenerg, partitions = 50, lag.max = 10, plot=TRUE) # AMI serie sin tendencia lineal\n\n\n\n\nEs posible ver que el primer rezago reduce el estado de incertidumbre para la observación en el tiempo \\(t\\)."
  },
  {
    "objectID": "Entrega 2 bonito.html",
    "href": "Entrega 2 bonito.html",
    "title": "3  Entrega 2",
    "section": "",
    "text": "4 Ajuste de modelos para serie de Energía\nComo vimos en la sección anterior. Para la serie de energía no fue necesario estabilizar la varianza, sin embargo, esta presenta tanto tendencia como multiple estacionalidad (\\(7\\) y \\(365.25\\))\nUna vez realizado el análisis descriptivo de la serie de energía, se da inicio al modelamiento de la misma. Este se hará por medio de 3 modelos:\nEstos modelos serán contrastados con base en su capacidad predictiva para seleccionar el mejor y realizar prediciones con él acerca del consumo diario de energia de la empresa PJM para fechas poseriores al año 2018.\n# Librerías necesarias\nlibrary(TSstudio)\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(lubridate)\nlibrary(astsa)\nlibrary(feasts)\nlibrary(fable)\nlibrary(timetk)\nlibrary(tsibble)\nlibrary(zoo)\nlibrary(xts)\nlibrary(readxl)\nlibrary(tidyverse)\nlibrary(nonlinearTseries)\nlibrary(tseriesChaos) \nlibrary(forecast)\nlibrary(plotly)\nlibrary(dplyr)\nlibrary(parsnip)\nlibrary(rsample)\nlibrary(timetk)\nlibrary(modeltime)\nlibrary(tsibble)\nlibrary(tidymodels)\nlibrary(greybox)\nlibrary(TSA)\nlibrary(urca)\nlibrary(lmtest)\nlibrary(uroot)\nlibrary(fUnitRoots)\nlibrary(sarima)\nlibrary(TSA)\nrequire(\"PolynomF\")\nrequire(\"forecast\")"
  },
  {
    "objectID": "Entrega 2 bonito.html#suavizamiento-exponencial",
    "href": "Entrega 2 bonito.html#suavizamiento-exponencial",
    "title": "3  Ajuste de modelos para serie de Energía",
    "section": "3.1 Suavizamiento Exponencial",
    "text": "3.1 Suavizamiento Exponencial\n\n3.1.0.0.1 Carga de la base de datos\n\n# Carga de la base de datos\nAEP_hourly&lt;-read.csv(\"AEP_hourly.csv\")\nAEP_hourly$Datetime&lt;-as.POSIXct(AEP_hourly$Datetime, format = \"%Y-%m-%d %H:%M:%S\")\nAEP_hourly$fecha&lt;-as.Date(AEP_hourly$Datetime)\n\nenergia &lt;- AEP_hourly %&gt;%\n  group_by(fecha) %&gt;%\n  summarise(Energia = sum(AEP_MW))\nenergia&lt;-energia[-5055,]\nenergia2&lt;-ts(energia$Energia,start=c(2004,10,01),frequency=365.25)\n\n\n# Creación del objeto msts indicando las dos estacionalidades\nly &lt;- msts(energia$Energia,start=c(2004,10,01), seasonal.periods=c(7,365.25))\n\n#HW_ly=stats::HoltWinters(ly,seasonal=\"additive\") # parece que sí funciona\n\n# Predicciones\n#forecast::forecast(HW_ly,h=7,level =0.95)\n#plot(forecast::forecast(HW_ly,h=7,level =0.95))\n\n\n\n3.1.0.1 Separación datos de entrenamiento y prueba\nSe hizo una división de los datos originales, el \\(85\\%\\) para datos de entrenamiento y el \\(15\\%\\) restante para datoos de prueba.\n\n# Separar train y test\n\nh=1 # Haremos predicciones 1-paso hacia delante\n\n# Datos entrenamiento\nntrain=trunc(length(ly)*0.85) # 4295 datos\ntrain=window(ly,end=time(ly)[ntrain])\n\n# Datos prueba\ntest=window(ly,start=time(ly)[ntrain]+1/365.25)\nntest=length(test) # 729 datos\n\n# fchstepahe: Vector para guardar las predicciones h-pasos adelante\nfchstepahe=matrix(0,nrow=ntest,ncol=h) \n\n# verval: Vector con los verdaderos valores de la serie en el conjunto de prueba con los que se compararán los pronósticos\nverval=test[1:ntest]\n\n\n\n3.1.0.2 Ajuste del modelo\nEn el modelo por medio de suavizamiento exponencial también se considera una descomposición de la serie de forma aditiva. Las componentes de tenendecia y la estacionalidad se estiman por medio de una estadística EWMA (promedio movil ponderado exponencialmente), dándole más peso a las observaciones más cercanas en cada tiempo.\nAdemás, para este caso, se descompone la componente de tendencia en nivel y pendiente, y se estima un parámetro de la componente estacional. Las estimaciones se hallan de la siguiente manera:\n\\[\\begin{align*}\n\\text{Componente de nivel: } & a_t=α(x_t-S_{t-p})+(1−α)(a_{t−1}+b_{t−1})\\\\\n\\text{Componente de pendiente: } & b_t=β(a_t−a_{t−1})+(1−β)b_{t−1} \\\\\n\\text{Componente estacional: } & S_t=\\gamma(x_t−a_t)+(1−γ)S_{t−p} \\\\\n\\end{align*}\\]\nPara encontrar los parámetros de suavizamiento \\(\\alpha\\), \\(\\beta\\) y \\(\\gamma\\) usamos una grilla con valores desde \\(0.001\\) hasta \\(0.999\\) de a \\(0.1\\) para cada parámetro.\n\nrequire(utils)\n\n# Propuestas para cada parámetro\nsuav_inputs=cbind(seq(0.001,0.999,0.1),seq(0.001,0.999,0.1),seq(0.001,0.999,0.1))\ncolnames(suav_inputs)&lt;-c(\"alpha\",\"beta\",\"gamma\")\nsuav_inputs_tbl=tibble::as_tibble(suav_inputs)\n\n# Creación de la grilla\ngrilla_suav=expand.grid(alpha=suav_inputs_tbl$alpha,beta=suav_inputs_tbl$beta,gamma=suav_inputs_tbl$gamma)\n\n# Matriz para almacenar los errores\nerrores&lt;-matrix(NA, nrow=1000,ncol=3) \n\n# Búsqueda de alpha, beta y gamma con rolling, queremos que minimice ECM\nfor(i in 1:1000){\n  ourCallETS &lt;- \"forecast::forecast(stats::HoltWinters(x=data,alpha=grilla_suav[i,1],beta=grilla_suav[i,2],gamma=grilla_suav[i,3]),h=h,level=95)\"\n  ourValueETS &lt;- c(\"mean\",\"lower\",\"upper\")\n  origins=ntest   # Número de rolling windows\n  Valoresretornados1 &lt;- ro(ly, h=h, origins=origins, call=ourCallETS, value=ourValueETS,ci=FALSE,co=FALSE)\n  t(Valoresretornados1$holdout) # Permiten verificar los verdaderos valores h-pasos adelante. \n  t(Valoresretornados1$mean)\n  errores[i,]&lt;-sqrt(apply((Valoresretornados1$holdout -Valoresretornados1$mean)^2,1,mean,na.rm=TRUE)) # Se calcula la raíz del error cuadrático medio de predicción\n}\n\n# Error medio absoluto escalado\nerrores&lt;-na.omit(errores) \nmin(errores[,1]) # RECM= 47201.82\nwhich(errores[,1] == min(errores[,1])) # 885\ngrilla_suav[885,] # alpha=0.701, beta=0.701, gamma=0.501\n\n\n\n[1] 47201.82\n\n\nDe modo que el modelo final para suavizamiento exponencial es\n\\[\\begin{align*}\n\\text{Componente de nivel: } & a_t=0.701(x_t-S_{t-p})+(1−0.701)(a_{t−1}+b_{t−1})\\\\\n\\text{Componente de pendiente: } & b_t=0.701(a_t−a_{t−1})+(1−0.701)b_{t−1} \\\\\n\\text{Componente estacional: } & S_t=0.7501(x_t−a_t)+(1−0.501)S_{t−p} \\\\\n\\end{align*}\\]\n\n\n3.1.0.3 Evaluar los supuestos\nAunque en suavizamiento exponencial no se hacen supuestos sobre los residuales, aún así hicimos las pruebas para ver si los residuales tenían un comportamiento similar a ruido blanco.\n\n# Verificación de supuestos\nHW_train_grilla=stats::HoltWinters(train,seasonal=\"additive\",alpha=0.701,beta=0.701,gamma=0.501) # con los parámetros que dieron mejor en la grilla\n\n# Residuales\nres &lt;- ly-HW_train_grilla$fitted[,1]\nplot(res)\n\n\n\n\n\n3.1.0.3.0.1 No autocorrelación\nLuego de ser modelados con el suavizamiento exponencial, parece que aún queda correlación por explicar\n\n# ACF\nacf(as.numeric(res)) # No deberían estar fuera de las bandas\n\n\n\n#acf(res^2)\n\n\n\n3.1.0.3.0.2 No autocorrelación parcial\n\n# PACF\npacf(as.numeric(res)) # No deberían estar fuera de las bandas\n\n\n\n\n\n\n3.1.0.3.0.3 Test de normalidad\nParece que no hay normalidad en los residuales\n\n# Test de normalidad\n## NO queremos rechazar H0 pero pues no es tan grave\ntseries::jarque.bera.test(res) # Dice que no son normales\n\n\n    Jarque Bera Test\n\ndata:  res\nX-squared = 49.017, df = 2, p-value = 2.27e-11\n\n\n\n\n3.1.0.3.0.4 Test de autocorrelación\nLuego de ser modelados con el suavizamiento exponencial, parece que los residuales están correlacionados\n\n# Test de autocorrelacion \n## No quieremos rechazar H0\nBox.test(res, lag =20 , type = \"Ljung-Box\", fitdf = 2) # No puedo Rechazar la hipótesis de no autocorrelación!\n\n\n    Box-Ljung test\n\ndata:  res\nX-squared = 6590.4, df = 18, p-value &lt; 2.2e-16\n\n\n\n\n3.1.0.3.0.5 Estabilización de la varianza\nCREO QUE ESTO ES MEJOR NO PONERLO PQ NO SÉ SI SIRVA PARA SUAVIZAMIENTO\n\n# Estadisticas CUSUM\n## Mide la estabilidad en los parámetros del modelo\ncum=cumsum(res)/sd(res)\nN=length(res)\ncumq=cumsum(res^2)/sum(res^2)\nAf=0.948 ###Cuantil del 95% para la estad?stica cusum\nco=0.01717####Valor del cuantil aproximado para cusumsq para n/2\nLS=Af*sqrt(N)+2*Af*c(1:length(res))/sqrt(N)\nLI=-LS\nLQS=co+(1:length(res))/N\nLQI=-co+(1:length(res))/N\nplot(cum,type=\"l\",ylim=c(min(LI),max(LS)),xlab=\"t\",ylab=\"\",main=\"CUSUM\")\nlines(LS,type=\"S\",col=\"red\")\nlines(LI,type=\"S\",col=\"red\")\n\n\n\n# Estadísticas CUSUMSQ\n## Mide la estabilidad en la varianza del modelo\nplot(cumq,type=\"l\",xlab=\"t\",ylab=\"\",main=\"CUSUMSQ\")                      \nlines(LQS,type=\"S\",col=\"red\")                                           \nlines(LQI,type=\"S\",col=\"red\")\n\n\n\n\n\n\n\n3.1.0.4 Predicciones sobre datos de prueba\n\nverval_ts&lt;-ts(verval,start=time(ly)[ntrain]+1/365.25,frequency=365.25)\nfchstepahe_ts&lt;-ts(fchstepahe,start=time(ly)[ntrain]+1/365.25,frequency=365.25)\n\nplot(verval_ts, col = \"blue\", ylab = \"Energía\", xlab = \"Tiempo\")\nlines(fchstepahe_ts, col = \"red\")\nlegend(\"topright\", legend = c(\"Reales\", \"Predicciones\"), col = c(\"blue\", \"red\"), lty = 1)"
  },
  {
    "objectID": "Entrega 2 bonito.html#proceso-arma",
    "href": "Entrega 2 bonito.html#proceso-arma",
    "title": "3  Ajuste de modelos para serie de Energía",
    "section": "3.2 Proceso ARMA",
    "text": "3.2 Proceso ARMA\n\n3.2.0.1 Carga de la base de datos\nPara ajustar un modelo de la familia ARMA(p,q) es necesario que los datos sean estacionarios, por lo tanto, usamos los datos que resultan luego de eliminar la tendencia línealmente y eliminar la doble estacionalidad que fue modelada usando 6 componentes de Fourier (3 para \\(s=7\\) y 3 para \\(s=182\\))\n\n# Datos estacionales\ny&lt;-readRDS(\"energia_estacionarios.RDS\") # datos estacionarios\nplot(y)\n\n\n\nplot(y,xlim=c(2004,2006))\n\n\n\n\nComprobamos que son estacionarios observando la subserie semanal y la subserie mensual\n\n# Preliminares\nest_1&lt;-cbind(as.matrix(y),as.character(energia$fecha))\nest_1&lt;-as.data.frame(est_1)\nnames(est_1)&lt;-c(\"Energia\",\"fecha\")\n\nest_1$Energia&lt;-as.numeric(est_1$Energia)\nest_1$fecha&lt;-as.Date(est_1$fecha)\n\ndf_est=data.frame(Energia=est_1$Energia,fecha=est_1$fecha)\ntbl_est=tibble(df_est)\ntbl_est_format_fecha=tbl_est\ntsbl_est=as_tsibble(tbl_est_format_fecha,index=fecha)\n\n# Subserie semanal\ngg_subseries(tsbl_est,y=Energia,period=7)\n\n\n\n# Subserie mensual\ngg_subseries(tsbl_est,y=Energia,period=12)\n\n\n\n\n\n\n3.2.0.2 Búsqueda de los hiperparámetros p y q\nLa búsqueda de los hiperparámetros p y q se hace vía ACF y PACF\n\n# Búsqueda de p,q vía acf y pacf\n\n# Búsqueda de q\nacf(as.numeric(y)) # Parece que q es gigante\n\n\n\n#acf(as.numeric(y),ci.type='ma') # En efecto, q es grande\n\n# Búsqueda de p\npacf(as.numeric(y)) # p máximo 3, posiblemente 5 o 6\n\n\n\n\nLuego de observar los gráficos, vemos que es posible que \\(p=6\\) o menos, y \\(q\\) debe ser grandísimo, por razones prácticas postulamos inicialmente \\(q=20\\), es razonable postular un modelo AR(6) y refinarlo, así como también un modelo mixto ARMA(6,20) y refinarlo. No es nada razonable pensar en un \\(MA(q)\\) puro por lo que vemos que el ACF decae excesivamente lento.\n\n\n3.2.0.3 Ajuste del modelo ARMA\nInicialmente se ajustó un modelo AR(6) y se refinó, sin embargo no se encontró un modelo autoregresivo puro que cumpliera los supuestos. Luego de una ardua búsqueda, finalmente encontramos un modelo mixto que cumpliera los supuestos, este es ARMA(5,8) que también fue refinado, de modo que el modelo final es:\n\\[X_t=\\phi_1 X_{t-1}+\\phi_2 X_{t-2}+\\phi_3 X_{t-3}+Z_t+\\theta_1 Z_{t-1}+\\theta_2 Z_{t-2}+\\theta_3 Z_{t-3}+\\theta_4 Z_{t-4}+\\theta_6 Z_{t-6}\\]\n\n# Propuesta modelo ARMA\nmodelo.propuesto2=forecast::Arima(y,order=c(5,0,8),fixed=c(NA,NA,0,NA,0,NA,NA,NA,NA,0,NA,0,0,0)) # ARMA(5,8)\nlmtest::coeftest(modelo.propuesto2)\n\n\nz test of coefficients:\n\n     Estimate Std. Error  z value  Pr(&gt;|z|)    \nar1  0.278287   0.116425   2.3903   0.01684 *  \nar2  1.017041   0.143894   7.0680 1.572e-12 ***\nar4 -0.312920   0.034978  -8.9463 &lt; 2.2e-16 ***\nma1  0.819146   0.116858   7.0098 2.387e-12 ***\nma2 -0.567652   0.028526 -19.8992 &lt; 2.2e-16 ***\nma3 -0.828137   0.071508 -11.5811 &lt; 2.2e-16 ***\nma4 -0.244673   0.027497  -8.8982 &lt; 2.2e-16 ***\nma6  0.026696   0.011651   2.2913   0.02194 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n3.2.0.4 Evaluar los supuestos\nPara los modelos de la familia ARMA sí se hacen supuestos sobre los residuales que deben comportarse como ruido blanco. Por lo tanto, es necesario validar los supuestos\n\n# Verificación de supuestos ARMA\nres &lt;- modelo.propuesto2$residuals\nplot(res)\n\n\n\n\n\n3.2.0.4.0.1 No autocorrelación\nEn general, los residuales presentan un buen comportamiento. No qued nada por explicar que no haya explicado ya el modelo.\n\n# ACF\nacf(as.numeric(res)) # No deberían estar fuera de las bandas\n\n\n\n# acf(as.numeric(res^2))\n\n\n\n3.2.0.4.0.2 No autocorrelación parcial\nEn general, los residuales presentan un buen comportamiento. No qued nada por explicar que no haya explicado ya el modelo.\n\n# PACF\npacf(as.numeric(res)) # No deberían estar fuera de las bandas\n\n\n\n\n\n\n3.2.0.4.1 Test de normalidad\nParece ser que los datos NO son normales.\n\n#Test de normalidad \n## No queremos rechazar H0 pero pues no es tan grave\ntseries::jarque.bera.test(res)\n\n\n    Jarque Bera Test\n\ndata:  res\nX-squared = 2096.9, df = 2, p-value &lt; 2.2e-16\n\n\n\n\n3.2.0.4.2 Test de autocorrelación\nCon un \\(p-value=\\) no hay suficiente evidencia estadística para rechazar la hipóstesis nula, es decir, los residuales NO están correlacionados.\n\n#Test de autocorrelacion \n## No queremos rechazar H0 pq es la hipótesis de no autocorrelación\nBox.test(res, lag =20 , type = \"Ljung-Box\", fitdf = 2)\n\n\n    Box-Ljung test\n\ndata:  res\nX-squared = 19.468, df = 18, p-value = 0.3636\n\n\n\n\n3.2.0.4.3 Estabilización de la varianza\nParece que tanto los parámetros como la varianza están “estables”.\n\n# Estadisticas CUSUM\n## Mide la estabilidad en los parámetros del modelo\ncum=cumsum(res)/sd(res)\nN=length(res)\ncumq=cumsum(res^2)/sum(res^2)\nAf=0.948 ###Cuantil del 95% para la estad?stica cusum\nco=0.01717####Valor del cuantil aproximado para cusumsq para n/2\nLS=Af*sqrt(N)+2*Af*c(1:length(res))/sqrt(N)\nLI=-LS\nLQS=co+(1:length(res))/N\nLQI=-co+(1:length(res))/N\nplot(cum,type=\"l\",ylim=c(min(LI),max(LS)),xlab=\"t\",ylab=\"\",main=\"CUSUM\")\nlines(LS,type=\"S\",col=\"red\")\nlines(LI,type=\"S\",col=\"red\")\n\n\n\n# Estadísticas CUSUMSQ\n## Mide la estabilidad en la varianza del modelo\nplot(cumq,type=\"l\",xlab=\"t\",ylab=\"\",main=\"CUSUMSQ\")                      \nlines(LQS,type=\"S\",col=\"red\")                                           \nlines(LQI,type=\"S\",col=\"red\")\n\n\n\n\n\n\n3.2.0.4.4 Rolling\nUna vez verificados los supuestos, se procede a evaluar la capacidad predictiva del modelo mixto. Para ello utilizamos rolling.\n\n# Rolling corregido\nfcmat=matrix(0,nrow=ntest,ncol=h)\nfor(i in 1:ntest){\n  x=window(y,end=time(ly)[ntrain]+(i-1)/365.25)\n  refit=Arima(x,model=modelo.propuesto2)\n  fcmat[i,]=as.numeric(forecast::forecast(refit,h=h)$mean) # Pronósticos para datos estacionarios\n}\n\n\n# Para volver a la escala original\nestacionalidad&lt;-as.vector(results_ciclo_ts)\ntendencia&lt;-as.vector(predict(fit_e))\nfchstepahe&lt;-(fcmat+estacionalidad[4296:5054])+tendencia[4296:5054] # primero sumamos la estacionalidad y luego la tendencia\n\nerrores_pred = verval-fchstepahe \nECM=apply(errores_pred^2,MARGIN = 2,mean,na.rm=TRUE)\nRECM=sqrt(ECM)\nRECM # 22840.1\n\n[1] 22840.1\n\n\n\n\n\n3.2.0.5 Predicciones sobre datos de prueba\n\nfchstepahe_ts&lt;-ts(fchstepahe,start=time(ly)[ntrain]+1/365.25,frequency=365.25)\n\nplot(verval_ts, col = \"blue\", ylab = \"Energía\", xlab = \"Tiempo\")\nlines(fchstepahe_ts, col = \"red\")\nlegend(\"topright\", legend = c(\"Reales\", \"Predicciones\"), col = c(\"blue\", \"red\"), lty = 1)"
  },
  {
    "objectID": "Entrega 2 bonito.html#proceso-arima",
    "href": "Entrega 2 bonito.html#proceso-arima",
    "title": "3  Ajuste de modelos para serie de Energía",
    "section": "3.3 Proceso ARIMA",
    "text": "3.3 Proceso ARIMA\nPara ajustar un modelo ARIMA (aunque no es lo más adecuado dado que la serie presenta componente estacional), primero se debe comprobar si la serie de tiempo presenta una raíz unitaria. Teniendo en cuenta que, para la prueba de Dicker Fuller, si el \\(p-valor\\) es menor que un nivel de significancia \\(\\alpha\\) se rechaza la hipotesis nula de que la serie de tiempo presenta una raíz unitaria, se tiene lo siguiente.\n\nstats::ar(energia2) # Selecciona un modelo AR usando el criterio de Akaike, sugiere tomar lags=36\n\n\nCall:\nstats::ar(x = energia2)\n\nCoefficients:\n      1        2        3        4        5        6        7        8  \n 1.0967  -0.4319   0.1631  -0.0202   0.0112   0.0217   0.1385  -0.1334  \n      9       10       11       12       13       14       15       16  \n 0.0302   0.0394  -0.0436  -0.0045   0.0394   0.1196  -0.1604   0.0593  \n     17       18       19       20       21       22       23       24  \n 0.0172  -0.0279   0.0320  -0.0221   0.1656  -0.1895   0.0736  -0.0536  \n     25       26       27       28       29       30       31       32  \n 0.0436  -0.0453   0.0435   0.1166  -0.1403   0.0378  -0.0228  -0.0066  \n     33       34       35       36  \n-0.0332   0.0232   0.1493  -0.1453  \n\nOrder selected 36  sigma^2 estimated as  329070266\n\ntseries::adf.test(energia2,k=36) # Prueba Dicker Fuller: No hay raíz unitaria\n\nWarning in tseries::adf.test(energia2, k = 36): p-value smaller than printed\np-value\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  energia2\nDickey-Fuller = -8.1586, Lag order = 36, p-value = 0.01\nalternative hypothesis: stationary\n\nsummary(ur.df(energia2,type=\"trend\",lags = 36))\n\n\n############################################### \n# Augmented Dickey-Fuller Test Unit Root Test # \n############################################### \n\nTest regression trend \n\n\nCall:\nlm(formula = z.diff ~ z.lag.1 + 1 + tt + z.diff.lag)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-144842  -10683    -880   10058   98316 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   2.648e+04  3.278e+03   8.079 8.14e-16 ***\nz.lag.1      -6.722e-02  8.239e-03  -8.159 4.25e-16 ***\ntt           -5.746e-01  1.879e-01  -3.058 0.002240 ** \nz.diff.lag1   1.757e-01  1.554e-02  11.307  &lt; 2e-16 ***\nz.diff.lag2  -2.754e-01  1.569e-02 -17.549  &lt; 2e-16 ***\nz.diff.lag3  -9.995e-02  1.614e-02  -6.193 6.37e-10 ***\nz.diff.lag4  -1.297e-01  1.614e-02  -8.032 1.18e-15 ***\nz.diff.lag5  -1.096e-01  1.623e-02  -6.755 1.59e-11 ***\nz.diff.lag6  -9.557e-02  1.628e-02  -5.869 4.66e-09 ***\nz.diff.lag7   4.296e-02  1.633e-02   2.630 0.008558 ** \nz.diff.lag8  -8.916e-02  1.632e-02  -5.463 4.90e-08 ***\nz.diff.lag9  -5.914e-02  1.633e-02  -3.621 0.000297 ***\nz.diff.lag10 -1.984e-02  1.634e-02  -1.214 0.224918    \nz.diff.lag11 -6.555e-02  1.630e-02  -4.022 5.86e-05 ***\nz.diff.lag12 -6.658e-02  1.631e-02  -4.081 4.55e-05 ***\nz.diff.lag13 -2.957e-02  1.630e-02  -1.814 0.069749 .  \nz.diff.lag14  8.892e-02  1.630e-02   5.455 5.13e-08 ***\nz.diff.lag15 -7.011e-02  1.628e-02  -4.306 1.69e-05 ***\nz.diff.lag16 -1.172e-02  1.627e-02  -0.720 0.471424    \nz.diff.lag17  8.099e-03  1.623e-02   0.499 0.617737    \nz.diff.lag18 -2.567e-02  1.621e-02  -1.584 0.113336    \nz.diff.lag19  1.229e-02  1.616e-02   0.760 0.447063    \nz.diff.lag20 -1.552e-02  1.614e-02  -0.961 0.336397    \nz.diff.lag21  1.543e-01  1.610e-02   9.584  &lt; 2e-16 ***\nz.diff.lag22 -4.081e-02  1.614e-02  -2.529 0.011471 *  \nz.diff.lag23  3.898e-02  1.614e-02   2.415 0.015773 *  \nz.diff.lag24 -1.987e-02  1.609e-02  -1.235 0.217069    \nz.diff.lag25  2.709e-02  1.598e-02   1.695 0.090117 .  \nz.diff.lag26 -2.176e-02  1.588e-02  -1.371 0.170571    \nz.diff.lag27  2.413e-02  1.584e-02   1.524 0.127655    \nz.diff.lag28  1.405e-01  1.574e-02   8.923  &lt; 2e-16 ***\nz.diff.lag29 -5.265e-04  1.572e-02  -0.034 0.973277    \nz.diff.lag30  3.564e-02  1.571e-02   2.268 0.023358 *  \nz.diff.lag31  1.438e-02  1.555e-02   0.925 0.355066    \nz.diff.lag32  6.620e-03  1.535e-02   0.431 0.666276    \nz.diff.lag33 -2.859e-02  1.510e-02  -1.894 0.058303 .  \nz.diff.lag34 -4.864e-03  1.491e-02  -0.326 0.744260    \nz.diff.lag35  1.495e-01  1.411e-02  10.598  &lt; 2e-16 ***\nz.diff.lag36 -8.638e-03  1.415e-02  -0.610 0.541638    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 17980 on 4978 degrees of freedom\nMultiple R-squared:  0.5122,    Adjusted R-squared:  0.5084 \nF-statistic: 137.5 on 38 and 4978 DF,  p-value: &lt; 2.2e-16\n\n\nValue of test-statistic is: -8.1586 22.1938 33.2897 \n\nCritical values for test statistics: \n      1pct  5pct 10pct\ntau3 -3.96 -3.41 -3.12\nphi2  6.09  4.68  4.03\nphi3  8.27  6.25  5.34\n\n\nComo se puede ver, en ambos casos las pruebas muestran que la serie no presenta raíces unitarias, por lo que ajustar este modelo no es adecuado."
  },
  {
    "objectID": "Entrega 2 bonito.html#proceso-sarima",
    "href": "Entrega 2 bonito.html#proceso-sarima",
    "title": "3  Ajuste de modelos para serie de Energía",
    "section": "3.4 Proceso SARIMA",
    "text": "3.4 Proceso SARIMA\nDado que la serie presenta multiple estacionalidad, no es posible ajustar un modelo de la familia SARIMA."
  }
]