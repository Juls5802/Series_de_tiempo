[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "An√°lisis de series de tiempo",
    "section": "",
    "text": "Introducci√≥n"
  },
  {
    "objectID": "index.html#esquina",
    "href": "index.html#esquina",
    "title": "An√°lisis de series de tiempo",
    "section": "Esquina",
    "text": "Esquina\nEste trabajo realiza un an√°lisis de dos bases de datos: Recaudo de impuestos internos por la DIAN para los a√±os 2000 a 2023 y consumo de energ√≠a por horas de la organizaci√≥n regional de transmisi√≥n PJM Interconnection para los a√±os 2004 a 2018. El an√°lisis se desarrolla de forma estad√≠stica, realizando la parte descriptiva con su correspondiente interpretaci√≥n."
  },
  {
    "objectID": "index.html#an√°lisis-del-recaudo-de-impuestos-internos-por-la-dian",
    "href": "index.html#an√°lisis-del-recaudo-de-impuestos-internos-por-la-dian",
    "title": "An√°lisis de series de tiempo",
    "section": "An√°lisis del recaudo de impuestos internos por la DIAN",
    "text": "An√°lisis del recaudo de impuestos internos por la DIAN\nLa DIAN es la entidad encargada de administrar y recaudar los impuestos internos y aduaneros en el pa√≠s. El recaudo de impuestos internos que realiza la DIAN cada mes se refiere a la suma total de los impuestos nacionales recaudados dentro del territorio colombiano durante ese per√≠odo mensual. Los impuestos internos son aquellos que se aplican a las actividades econ√≥micas y transacciones que ocurren dentro del pa√≠s, los cuales pueden incluir: IVA, impuesto de renta y complementarios, impuesto de timbre, impuesto de consumo, impuesto a la riqueza, impuesto predial, ICA, entre otros.\nCon el proyecto se busca estudiar esta serie de tiempo para ver como es el comportamiento de los impuestos internos de Colombia a lo largo de los a√±os, por ejemplo, encontrar patrones y observar qu√© tanto han aumentado dichos impuestos.\nA continuaci√≥n se presenta la manera en que se realiza la carga de los datos y un vistazo preliminar de la serie de tiempo en la Figura¬†1 .\n\n# Carga de la base de datos\ndian&lt;-read_excel(\"dian.xlsx\", range=\"A7:C313\", sheet = \"Rec mensual a junio 2023\" )\na√±os&lt;-2000:2023\ndian&lt;-dplyr::filter(dian,A√±o %in% a√±os)\ncolnames(dian)&lt;-c(\"A√±o\",\"Mes\",\"Impuestos\")\ndian$fecha&lt;-as.Date(paste(dian$A√±o, dian$Mes, \"1\", sep = \"-\"), format = \"%Y-%B-%d\")\ndian&lt;-dian[,3:4]\n\n# Gr√°fico de la serie de tiempo\ndian2&lt;-ts(dian$Impuestos,start=c(2000,01),frequency=12)\nplot(dian2, main=\"Serie de tiempo del recaudo mensual interno\",\n     cex.main=1.3,\n     xlab=\"Tiempo\",\n     ylab=\"Recaudo interno\",\n     cex.lab=0.4)\n\n\n\n\nFigura¬†1: Gr√°fico de la serie de tiempo de la DIAN."
  },
  {
    "objectID": "Descriptivo Dian.html",
    "href": "Descriptivo Dian.html",
    "title": "1¬† Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. ¬´Literate Programming¬ª. Comput. J. 27 (2): 97-111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "Descriptivo Energia.html",
    "href": "Descriptivo Energia.html",
    "title": "2¬† An√°lisis descriptivo Energ√≠a",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. ‚ÄúLiterate Programming.‚Äù Comput.\nJ. 27 (2): 97‚Äì111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "Descriptivo Dian.html#estabilizaci√≥n-de-la-varianza-marginal",
    "href": "Descriptivo Dian.html#estabilizaci√≥n-de-la-varianza-marginal",
    "title": "2¬† An√°lisis descriptivo del recaudo de impuestos internos por la DIAN",
    "section": "2.1 Estabilizaci√≥n de la varianza marginal",
    "text": "2.1 Estabilizaci√≥n de la varianza marginal\nTeniendo en cuenta lo observado utilizando el gr√°fico de la serie de tiempo, se puede evidenciar una heterocedasticidad marginal la cual debemos corregir, para esto utilizaremos la transformaci√≥n de Box-cox, esto teniendo en cuenta que no se tienen valors negativos, de este modo se tiene que\n\nMASS::boxcox(lm(dian2 ~ 1),seq(-5, 5, length = 50)) ##Notese que no acputra al 1\n\n\n\nforecast::BoxCox.lambda(dian2, method =\"loglik\",\n                        lower = -1, upper = 3)#Entrega el valor de lambda (0.1).\n\n[1] 0.1\n\n\nCon el anterior gr√°fico y salida podemos observar que el valor que maximiza la log-verosimilitud es 0.1, pero este valor es bastante cercano a 0, por lo tanto lo aproximaremos para asi poder utilizar la transformaci√≥n logaritmo, notese que el intervalo de confianza no captura al 1 por lo tanto puede ser conveniente realizar la transformaci√≥n. En los gr√°ficos posteriores analizaremos si dicha transformaci√≥n logra estabilizar la varianza marginal de nuestros datos.\n\nplot(forecast::BoxCox(dian2,lambda=0.1))\n\n\n\npar(mar = c(1,1,1,1))\nldian2=log(dian2)\nMASS::boxcox(lm(ldian2 ~ 1),seq(-5, 5, length = 50)) #Si captura al 1\n\n\n\n\nNotese que el intervalo de confianza de la transformaci√≥n Box-cox logra capturar el valor de 1, lo cual nos indica que no es necesario transformar los datos nuevamente y que la transformaci√≥n ayudo de buena manera a estabilizar la varianza marginal de nuestra serie de tiempo.\nEn el siguiente gr√°fico mostramos la serie de recaudo de la Dian con y sin la transformaci√≥n logaritmo y es posible observar que la escala disminuye pero a su vez se observan algunos cambios considerables en la forma de la serie, lo cual es un buen indicativo de la relevancia de realizar la transformaci√≥n.\n\n#par(mfrow=c(2,1))\nplot(dian2,main=\"Serie Dian sin Transformar\")\n\n\n\nplot(ldian2,main=\"Series Dian con Transformaci√≥n BoxCox\")\n\n\n\n\nTeniendo lo anterior en cuenta, presentaremos un gr√°fico de la serie sin tendencia un poco m√°s interactivo e informativo, con el fin de lograr conocer los distintos valores en cada una de las fechas.\n\nclass(ldian2)\n\n[1] \"ts\"\n\ndian3<-window(ldian2, start = c(2000,1))\nts_plot(dian3,title=\"Serie de tiempo del recaudo mensual interno\",\n        Ytitle=\"Recaudo interno\",\n        Xtitle=\"Tiempo\",\n        Xgrid=TRUE,\n        Ygrid=TRUE)"
  },
  {
    "objectID": "index.html#an√°lisis-del-consumo-de-energ√≠a-de-la-empresa-pjm",
    "href": "index.html#an√°lisis-del-consumo-de-energ√≠a-de-la-empresa-pjm",
    "title": "An√°lisis de series de tiempo",
    "section": "An√°lisis del consumo de energ√≠a de la empresa PJM",
    "text": "An√°lisis del consumo de energ√≠a de la empresa PJM\nLa empresa PJM es una organizaci√≥n de transmisi√≥n regional que coordina el movimiento de electricidad mayorista en la totalidad, o parte, de 13 estados y el Distrito de Columbia.\nEl an√°lisis del consumo de energ√≠a es esencial para mejorar la eficiencia operativa, reducir costos, cumplir con regulaciones y promover la sostenibilidad, por lo cual, este proyecto analiza la serie de tiempo con el fin de encontrar variaciones en el consumo de energ√≠a de los 13 estados y el Distrito de Columbia a lo largo del tiempo, as√≠ como tambi√©n descubrir posibles patrones.\nA continuaci√≥n se presenta la manera en que se realiza la carga de los datos y un vistazo preliminar de la serie de tiempo en la Figura¬†2 .\n\n# Carga de la base de datos\nAEP_hourly&lt;-read.csv(\"AEP_hourly.csv\")\nAEP_hourly$Datetime&lt;-as.POSIXct(AEP_hourly$Datetime, format = \"%Y-%m-%d %H:%M:%S\")\nAEP_hourly$fecha&lt;-as.Date(AEP_hourly$Datetime)\n\nenergia &lt;- AEP_hourly %&gt;%\n  group_by(fecha) %&gt;%\n  summarise(Energia = sum(AEP_MW))\nenergia&lt;-energia[-5055,]\n\n# Gr√°fico de la serie de tiempo\nenergia2&lt;-ts(energia$Energia,start=c(2004,10,01),frequency=365.25)\nplot(energia2, main=\"Serie de tiempo de la energ√≠a diaria de una empresa estadounidense\",\n     cex.main=1,\n     xlab=\"Tiempo \",\n     ylab=\"Energ√≠a consumida\",\n     cex.lab=0.4)\n\n\n\n\nFigura¬†2: Gr√°fico de la serie de tiempo de la energ√≠a."
  },
  {
    "objectID": "index.html#sobre-el-trabajo",
    "href": "index.html#sobre-el-trabajo",
    "title": "An√°lisis de series de tiempo",
    "section": "Sobre el trabajo",
    "text": "Sobre el trabajo\nEste trabajo realiza un an√°lisis de dos bases de datos: Recaudo de impuestos internos por la DIAN para los a√±os 2000 a 2023 y consumo de energ√≠a por horas de la organizaci√≥n regional de transmisi√≥n PJM Interconnection para los a√±os 2004 a 2018. El an√°lisis se desarrolla de forma estad√≠stica, realizando la parte descriptiva con su correspondiente interpretaci√≥n."
  },
  {
    "objectID": "Descriptivo Energia.html#estabilizaci√≥n-de-la-varianza-marginal",
    "href": "Descriptivo Energia.html#estabilizaci√≥n-de-la-varianza-marginal",
    "title": "2¬† An√°lisis del consumo de energ√≠a de la empresa PJM",
    "section": "2.1 Estabilizaci√≥n de la varianza marginal",
    "text": "2.1 Estabilizaci√≥n de la varianza marginal\nComo se observa en la gr√°fica de la serie de tiempo no es necesario realizar una estabilizaci√≥n de la varianza para continuar con el an√°lisis descriptivo, sin embargo, para comprobar esto, se hace una transformaci√≥n de Box-cox para ver que tanto se estabiliza la varianza. En la Figura¬†2.2 se observa que se sugiere una transformaci√≥n dado que 1 no est√° contenido en el intervalo.\n\nMASS::boxcox(lm(energia2 ~ 1),seq(-5, 5, length = 50))\nabline(v = 1, col = \"red\", lty = 2)\n\n\n\n\nFigura¬†2.2: Gr√°fico de la verosimilitud en funci√≥n del hiperpar√°metro lambda.\n\n\n\n\nEn la siguiente salida se puede ver que el \\(\\lambda\\) sugerido es \\(-0.25\\), como es un n√∫mero negativo, se procede a hacer la transformaci√≥n Box-Cox usando logaritmo natural.\n\nforecast::BoxCox.lambda(energia2, method =\"loglik\",lower = -1, upper = 3)\n\n[1] -0.25\n\n\nEn la Figura¬†2.3 a continuaci√≥n se muestra que la serie en escala logar√≠tmica nuevamente no tiene la varianza estabilizada, dado que no se contiene al 1.\n\nlenergia2=log(energia2)\nMASS::boxcox(lm(lenergia2 ~ 1),seq(-5, 5, length =  50))\nabline(v = 1, col = \"red\", lty = 2)\n\n\n\n\nFigura¬†2.3: Gr√°fico de la verosimilitud para la serie en escala logar√≠tmica, en funci√≥n del hiperpar√°metro lambda.\n\n\n\n\nAdem√°s, se puede notar en la Figura¬†2.4 , que no hay una diferencia significativa entre la serie transformada y no transformada. Por lo que el an√°lisis descriptivo se contin√∫a usando los datos originales.\n\npar(mar = c(1,1,1,1))\npar(mfrow=c(2,1),mar=c(3,3,3,3))\nplot(energia2,main=\"Serie energ√≠a sin Transformar\",cex.main=1)\nplot(lenergia2,main=\"Serie energ√≠a con Transformaci√≥n BoxCox\",cex.main=1)\n\n\n\n\nFigura¬†2.4: Serie original y serie con transformaci√≥n logar√≠tmica."
  },
  {
    "objectID": "Descriptivo Energia.html#estimaci√≥n-preliminar-de-la-tendencia",
    "href": "Descriptivo Energia.html#estimaci√≥n-preliminar-de-la-tendencia",
    "title": "2¬† An√°lisis del consumo de energ√≠a de la empresa PJM",
    "section": "2.2 Estimaci√≥n preliminar de la tendencia",
    "text": "2.2 Estimaci√≥n preliminar de la tendencia\nComo se observa en la gr√°fica de la serie de tiempo no es necesario realizar una estimaci√≥n de la tendencia para continuar con el an√°lisis descriptivo, sin embargo, se hace una estimaci√≥n preliminar usando varios m√©todos.\n\n2.2.1 Tendencia lineal\n\n# Creaci√≥n del objeto tibble\nenergia_1=energia %&gt;% map_df(rev)\nFechas=as.Date(energia_1$fecha)\nenergia_xts=xts(x = energia_1$Energia,frequency = 365.25,order.by = Fechas)\n\n# Creaci√≥n objeto tssible a partir del objeto tibble\ndf_energia=data.frame(Energia=energia_1$Energia,fecha=energia_1$fecha)\ntbl_energia=tibble(df_energia)\ntbl_energia_format_fecha=tbl_energia\ntsbl_energia=as_tsibble(tbl_energia_format_fecha,index=fecha)\n\nEn la siguiente salida se presenta el ajuste de una regresi√≥n lineal para estimar la tendencia. Como el \\(R^2\\) es \\(0.058\\), se sugiere que no hay tendencia.\n\n# An√°lisis de tendencia con regresion simple\nsummary(fit_e&lt;-lm(energia2~time(energia2),na.action=NULL))\n\n\nCall:\nlm(formula = energia2 ~ time(energia2), na.action = NULL)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-137653  -34064   -5533   31129  179275 \n\nCoefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    6128528.2   325172.5   18.85   &lt;2e-16 ***\ntime(energia2)   -2862.7      161.7  -17.70   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 45920 on 5052 degrees of freedom\nMultiple R-squared:  0.05841,   Adjusted R-squared:  0.05823 \nF-statistic: 313.4 on 1 and 5052 DF,  p-value: &lt; 2.2e-16\n\n\nEn la Figura¬†2.4 se presenta la serie de tiempo de la energ√≠a con la estimaci√≥n lineal de la tendencia.\n\nplot(energia2, main=\"Serie de tiempo de la energ√≠a diaria de una empresa estadounidense\",\n     cex.main=1,\n     xlab=\"Tiempo \",\n     ylab=\"Energ√≠a consumida\",\n     cex.lab=0.4)\nabline(fit_e,col=\"darkcyan\",lwd=2)\n\n\n\n\nFigura¬†2.4: Gr√°fico de la serie de tiempo de la energ√≠a con la estimaci√≥n lineal de la tendencia.\n\n\n\n\nPosteriormente, se procede a eliminar la tendencia lineal, como se puede ver en la Figura¬†2.5 .\n\n# Eliminaci√≥n de la tendencia con la predicci√≥n la recta\nElimiTendenerg&lt;-energia2-predict(fit_e)\nplot(ElimiTendenerg,main=\"Serie energ√≠a sin tendencia\",\n     cex.main=1.3,\n     xlab=\"Tiempo\",\n     ylab=\"Consumo de energ√≠a\",\n     cex.lab=0.4)\n\n\n\n\nFigura¬†2.5: Gr√°fico de la serie de tiempo de la energ√≠a sin tendencia estimada con regresi√≥n lineal.\n\n\n\n\n\n\n2.2.2 Tendencia con promedios m√≥viles\nEn la Figura¬†2.6 , se muestra un ajuste de la tendencia con promedios m√≥viles, como se puede ver, aparentemente hay una sobrestimaci√≥n de la tendencia, ya que muestra comportamientos que no son tan visibles en la serie de tiempo original.\n\n# Descomposici√≥n filtro de promedios m√≥viles\nenergia_decompo=decompose(energia2)\nplot(energia_decompo)\n\n\n\n\nFigura¬†2.6: Gr√°fico de la serie de tiempo de la energ√≠a sin tendencia estimada con promedios m√≥viles.\n\n\n\n\n\n\n2.2.3 Tendencia con diferenciaci√≥n\nEn la Figura¬†2.7 se presentan los gr√°ficos de las series sin tendencia, estimada con regresi√≥n lineal y con diferenciaci√≥n respectivamente, se puede notar que la serie sin tendencia estimada con diferenciaci√≥n impide ver los ciclos que se ven en la serie original.\n\ntsibble_energia&lt;-as_tsibble(energia2)\npar(mar = c(2,2,2,2))\npar(mfrow=c(2,1))\n\nplot(resid(fit_e), type=\"l\", main=\"Sin tendencia\") \nplot(diff(energia2), type=\"l\", main=\"Primera Diferencia\") \n\n\n\n\nFigura¬†2.7: Gr√°fico de la serie de tiempo de la energ√≠a sin tendencia estimada con regresi√≥n lineal y diferenciaci√≥n.\n\n\n\n\n\n\n2.2.4 Comparaci√≥n de los ACF\nEn la Figura¬†2.8 se puede notar un descenso r√°pido hacia 0 para las series original y sin tendencia estimada con regresi√≥n lineal, mientras que para la serie sin tendencia estimada con diferenciaci√≥n, se puede apreciar mejor el ciclo estacional de aproximadamente 7 d√≠as.\n\n# Gr√°ficos de los ACF\npar(mar = c(3,2,3,2))\npar(mfrow=c(3,1))\nacf(energia2, 60, main=\"ACF energia\")\nacf(resid(fit_e), 60, main=\"ACF Sin tendencia\") \nacf(diff(energia2), 60, main=\"ACF Primera Diferencia\")\n\n\n\n\nFigura¬†2.8: Gr√°ficos de autocorrelaci√≥n para la serie original, sin tendencia estimada con regresi√≥n lineal y con la primera diferencia."
  },
  {
    "objectID": "Descriptivo Energia.html#estimaci√≥n-de-la-estacionalidad",
    "href": "Descriptivo Energia.html#estimaci√≥n-de-la-estacionalidad",
    "title": "2¬† An√°lisis del consumo de energ√≠a de la empresa PJM",
    "section": "2.4 Estimaci√≥n de la estacionalidad",
    "text": "2.4 Estimaci√≥n de la estacionalidad\n\n2.4.1 Detecci√≥n de estacionalidad\n\nlineal_1&lt;-cbind(as.matrix(ElimiTendenerg),as.character(energia$fecha))\nlineal_1&lt;-as.data.frame(lineal_1)\nnames(lineal_1)&lt;-c(\"Energia\",\"fecha\")\n\nlineal_1$Energia&lt;-as.numeric(lineal_1$Energia)\nlineal_1$fecha&lt;-as.Date(lineal_1$fecha)\n\ndf_lineal=data.frame(Energia=lineal_1$Energia,fecha=lineal_1$fecha)\ntbl_lineal=tibble(df_lineal)\ntbl_lineal_format_fecha=tbl_lineal\ntsbl_lineal=as_tsibble(tbl_lineal_format_fecha,index=fecha)\n\nEn la Figura¬†2.10 se presenta el gr√°fico de subseries diarias para la serie original, se puede ver que hay estacionalidad ya que el valor medio del d√≠a domingo por ejemplo, es menor al del resto de d√≠as.\n\n# Gr√°fica de subseries semanal con datos originales\ngg_subseries(tsbl_lineal,y=Energia,period=7)\n\n\n\n\nFigura¬†2.10: Gr√°fica de subseries diarias.\n\n\n\n\nEn la Figura¬†2.11 se presenta el gr√°fico de subseries mensuales para la serie original, se puede ver que no hay ciclos estacionales mensuales, ya que todos tienen la misma media. Sin embargo, esto puede deberse a la presencia de la m√∫lriple estacionalidad.\n\n# Gr√°fica de subseries anual con datos originales\ngg_subseries(tsbl_lineal,y=Energia,period=12)\n\n\n\n\nFigura¬†2.11: Gr√°fica de subseries anuales.\n\n\n\n\n\nenergia_df&lt;-cbind(as.matrix(ElimiTendenerg),as.character(energia$fecha))\nenergia_df&lt;-as.data.frame(energia_df)\nnames(energia_df)&lt;-c(\"Energia\",\"Fecha\")\n\nenergia_df$Fecha&lt;-as.Date(energia_df$Fecha)\nenergia_df$time = as.POSIXct(energia_df$Fecha, \"%Y-%m-%d\")\nenergia_df$weekday &lt;- wday(energia_df$time, label = TRUE, abbr = TRUE)\nenergia_df$month &lt;- factor(month.abb[month(energia_df$time)], levels =   month.abb)\n\n# Agrupamos por mes y d√≠a\nenergia_df$Energia&lt;-as.numeric(energia_df$Energia)\nenergia_mensual &lt;- energia_df %&gt;%\n  dplyr::filter(weekday == \"dom\\\\.\" | weekday == \"mar\\\\.\" ) %&gt;% # martes se parece al comportamiento de lunes-viernes, domingo se parece a sabado\n  dplyr::group_by(weekday, month) %&gt;%\n  dplyr::summarise(mean = mean(Energia, na.rm = TRUE),\n                   sd = sd(Energia, na.rm = TRUE))\n\n# Grafico consumo (diferenciado) de energia mensual por dia\nplot_ly(data = energia_mensual, x = ~ month, y = ~ mean, type =\n          \"bar\",color = ~ weekday) %&gt;%\n  layout(title = \"Promedio diario de energ√≠a por d√≠a de la semana\",\n         yaxis = list(title = \"Media\"),\n         xaxis = list(title = \"Mes\"))\n\n\n\n\n\n\n\n2.4.2 Periodograma\nEn la Figura¬†2.12 se presenta el periodograma para la serie sin tendencia lineal, el valor del periodo donde se maximiza el periodograma nuevamente es \\(182.86\\), es decir, aproximadamente, el ciclo es de medio a√±o.\n\n# Periodograma sin tendencia lineal\nspectrum(as.numeric(ElimiTendenerg),log='no')\n\nPeriodogramaEnergia2_lineal=spectrum(as.numeric(ElimiTendenerg),log='no')\nubicacionlogenergia=which.max(PeriodogramaEnergia2_lineal$spec)\n\nsprintf(\"El valor de la frecuencia donde se maximiza el periodograma para la serie es: %s\",PeriodogramaEnergia2_lineal$freq[ubicacionlogenergia])\n\n[1] \"El valor de la frecuencia donde se maximiza el periodograma para la serie es: 0.00546875\"\n\nsprintf(\"El periodo correspondiente es aproximadamente: %s\",1/PeriodogramaEnergia2_lineal$freq[ubicacionlogenergia])\n\n[1] \"El periodo correspondiente es aproximadamente: 182.857142857143\"\n\n\n\n\n\nFigura¬†2.12: Periodograma para la serie sin tendencia lineal.\n\n\n\n\n\n2.4.2.1 Para la serie sin tendencia usando diferenciaci√≥n\nEn la Figura¬†2.13 se presenta el periodograma para la serie sin tendencia estimada usando diferenciaci√≥n, el valor del periodo donde se maximiza el periodograma es \\(3.5\\), es decir, aproximadamente, el ciclo es de tres d√≠as.\n\n# Periodograma diferenciaci√≥n\nspectrum(as.numeric(diff(energia2)),log='no')\n\nPeriodogramaEnergia2_dif=spectrum(as.numeric(diff(energia2)),log='no')\nubicacionlogenergia=which.max(PeriodogramaEnergia2_dif$spec)\n\nsprintf(\"El valor de la frecuencia donde se maximiza el periodograma para la serie es: %s\",PeriodogramaEnergia2_dif$freq[ubicacionlogenergia])\n\n[1] \"El valor de la frecuencia donde se maximiza el periodograma para la serie es: 0.2857421875\"\n\nsprintf(\"El periodo correspondiente es aproximadamente: %s\",1/PeriodogramaEnergia2_dif$freq[ubicacionlogenergia])\n\n[1] \"El periodo correspondiente es aproximadamente: 3.49965823650034\"\n\n\n\n\n\nFigura¬†2.13: Periodograma para la serie sin tendencia usando diferenciaci√≥n.\n\n\n\n\n\n\n\n2.4.3 Estimaci√≥n\nAhora procederemos a estimar el ciclo estacional que se observa en esta serie de tiempo, es importante resaltar que con ayuda de los graficos exploratorios y el periodograma se observo que el periodo de la componente estacional es \\(s=12\\), por lo tanto utilizaremos en primer lugar componentes de fourier, esto teniendo en cuenta que se aprecia que la componente estacional sigue un comportamiento deterministico y posiblemente sinosoidal. Teniendo lo anterior en cuenta el modelo viene dado por: \\[\\begin{align*} x_t&= ‚àë_{i=1}^k a_icos(kùúît)+b_isen(kùúît) + w_t \\\\ \\end{align*}\\] Donde \\(k\\) corresponder√° al orden de la expansi√≥n en series de Fourier y los coeficientes \\(a_i\\) y \\(b_i\\) con \\(i=1,...,k\\) ser√°n estimados a trav√©s del m√©todo de m√≠nimos cuadrados. El c√°lculo de esta componente se muestra a continuaci√≥n considerando un orden \\(k=3\\).\n\n# Frecuencia angular w=2*pi/s\nfrec_ang=(2*pi/182)\nfrec_ang2=(2*pi/7)\n\nenergia_copia&lt;-cbind(as.matrix(ElimiTendenerg),as.character(energia$fecha))\nenergia_copia&lt;-as.data.frame(energia_copia)\nnames(energia_copia)&lt;-c(\"Energia\",\"fecha\")\n\nenergia_copia$fecha&lt;-as.Date(energia_copia$fecha)\n\n#Fourier k=1 \nenergia_copia$sin = sin(c(1:5054)*(1*frec_ang))\nenergia_copia$cos = cos(c(1:5054)*(1*frec_ang))\n\n#Fourier k=2 \nenergia_copia$sin2 = sin(c(1:5054)*(2*frec_ang))\nenergia_copia$cos2 = cos(c(1:5054)*(2*frec_ang))\n\n#Fourier k=3 \nenergia_copia$sin3 = sin(c(1:5054)*(3*frec_ang))\nenergia_copia$cos3 = cos(c(1:5054)*(3*frec_ang))\n\n\n#Fourier k=1 \nenergia_copia$sin4 = sin(c(1:5054)*(1*frec_ang2))\nenergia_copia$cos4 = cos(c(1:5054)*(1*frec_ang2))\n\n#Fourier k=2 \nenergia_copia$sin5 = sin(c(1:5054)*(2*frec_ang2))\nenergia_copia$cos5 = cos(c(1:5054)*(2*frec_ang2))\n\n#Fourier k=3 \nenergia_copia$sin6 = sin(c(1:5054)*(3*frec_ang2))\nenergia_copia$cos6 = cos(c(1:5054)*(3*frec_ang2))\n\nlinmodel_ciclo&lt;-lm(Energia~1+sin+cos+sin2+cos2+sin3+cos3+sin4+cos4+sin5+cos5+sin6+cos6,data=energia_copia)\n\nresults_ciclo=linmodel_ciclo$fitted.values\nresults_ciclo&lt;-as.data.frame(results_ciclo)\nresults_ciclo_ts&lt;-ts(results_ciclo,start=c(2004,10,01),frequency=365.25)\n\nplot(ElimiTendenerg, main=\"Serie de tiempo de la energ√≠a diaria de una empresa estadounidense\",\n     cex.main=1.3,\n     xlab=\"Tiempo \",\n     ylab=\"Energ√≠a consumida\",\n     cex.lab=0.4)\nlines(results_ciclo_ts,col=\"red\")\n\n\n\nplot(ElimiTendenerg, main=\"Serie de tiempo de la energ√≠a diaria de una empresa estadounidense\",\n     cex.main=1.3,\n     xlab=\"Tiempo \",\n     ylab=\"Energ√≠a consumida\",\n     cex.lab=0.4,\n     xlim=c(2004,2007))\nlines(results_ciclo_ts,col=\"red\",xlim=c(2004,2007))\n\n\n\n\nEn la ?fig-energestacionalidad se presenta la serie original con la estimaci√≥n de la componente estacional via componentes de Fourier y la serie sin estacionalidad. Se puede notar que las componentes de Fourier logran captar bien es c√≠clo estacional que tiene la serie. Se toma una componente de Fourier, ya que no hay una diferencia visible al utilizar 2 y 3.\n\nenergia_estacionarios&lt;-ElimiTendenerg-results_ciclo_ts\nsaveRDS(energia_estacionarios, file=\"energia_estacionarios.RDS\")\nplot(ElimiTendenerg-results_ciclo_ts)\nplot(ElimiTendenerg-results_ciclo_ts,xlim=c(2004,2007))\n\n\n\n\nFigura¬†2.14: Serie original con estamaci√≥n de la componente estacional y serie sin estacionalidad.\n\n\n\n\n\n\n\nFigura¬†2.15: Serie original con estamaci√≥n de la componente estacional y serie sin estacionalidad.\n\n\n\n\nA continuaci√≥n, presentaremos el modelo de √°rboles y ell modelo de redes neuronales multicapa paraa esta serie de tiempo, disponible aqu√≠."
  },
  {
    "objectID": "Descriptivo Energia.html#estimaci√≥n-de-la-tendencia",
    "href": "Descriptivo Energia.html#estimaci√≥n-de-la-tendencia",
    "title": "2¬† An√°lisis del consumo de energ√≠a de la empresa PJM",
    "section": "2.2 Estimaci√≥n de la tendencia",
    "text": "2.2 Estimaci√≥n de la tendencia\nComo se observa en la gr√°fica de la serie de tiempo no es necesario realizar una estimaci√≥n de la tendencia para continuar con el an√°lisis descriptivo, sin embargo, se hace una estimaci√≥n preliminar usando varios m√©todos, con el fin de comprobar que la serie sin tendencia no var√≠a mucho.\n\n2.2.1 Tendencia lineal\n\n# Creaci√≥n del objeto tibble\nenergia_1=energia %&gt;% map_df(rev)\nFechas=as.Date(energia_1$fecha)\nenergia_xts=xts(x = energia_1$Energia,frequency = 365.25,order.by = Fechas)\n\n# Creaci√≥n objeto tssible a partir del objeto tibble\ndf_energia=data.frame(Energia=energia_1$Energia,fecha=energia_1$fecha)\ntbl_energia=tibble(df_energia)\ntbl_energia_format_fecha=tbl_energia\ntsbl_energia=as_tsibble(tbl_energia_format_fecha,index=fecha)\n\nEn la siguiente salida se presenta el ajuste de una regresi√≥n lineal para estimar la tendencia. El \\(R^2\\) ind√≠ca qu√© tan bien se ajusta la recta a los datos, en este caso tiene un valor de \\(0.058\\), por lo que sugiere que no hay tendencia lineal.\n\n# An√°lisis de tendencia con regresion simple\nsummary(fit_e&lt;-lm(energia2~time(energia2),na.action=NULL))\n\n\nCall:\nlm(formula = energia2 ~ time(energia2), na.action = NULL)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-137653  -34064   -5533   31129  179275 \n\nCoefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    6128528.2   325172.5   18.85   &lt;2e-16 ***\ntime(energia2)   -2862.7      161.7  -17.70   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 45920 on 5052 degrees of freedom\nMultiple R-squared:  0.05841,   Adjusted R-squared:  0.05823 \nF-statistic: 313.4 on 1 and 5052 DF,  p-value: &lt; 2.2e-16\n\n\nEn la Figura¬†2.5 se presenta la serie de tiempo de la energ√≠a con la estimaci√≥n lineal de la tendencia.\n\nplot(energia2, main=\"Serie de tiempo de la energ√≠a diaria de una empresa estadounidense\",\n     cex.main=1,\n     xlab=\"Tiempo \",\n     ylab=\"Energ√≠a consumida\",\n     cex.lab=0.4)\nabline(fit_e,col=\"darkcyan\",lwd=2)\n\n\n\n\nFigura¬†2.5: Gr√°fico de la serie de tiempo de la energ√≠a con la estimaci√≥n lineal de la tendencia.\n\n\n\n\nPosteriormente, se procede a eliminar la tendencia lineal, como se puede ver en la Figura¬†2.6 .\n\n# Eliminaci√≥n de la tendencia con la predicci√≥n la recta\nElimiTendenerg&lt;-energia2-predict(fit_e)\nplot(ElimiTendenerg,main=\"Serie energ√≠a sin tendencia\",\n     cex.main=1.3,\n     xlab=\"Tiempo\",\n     ylab=\"Consumo de energ√≠a\",\n     cex.lab=0.4)\n\n\n\n\nFigura¬†2.6: Gr√°fico de la serie de tiempo de la energ√≠a sin tendencia estimada con regresi√≥n lineal.\n\n\n\n\n\n\n2.2.2 Tendencia con promedios m√≥viles\nEn la Figura¬†2.7 , se muestra un ajuste de la tendencia con promedios m√≥viles, como se puede ver, aparentemente hay una sobrestimaci√≥n de la tendencia, ya que muestra comportamientos que no son tan visibles en la serie de tiempo original.\n\n# Descomposici√≥n filtro de promedios m√≥viles\nenergia_decompo=decompose(energia2)\nplot(energia_decompo)\n\n\n\n\nFigura¬†2.7: Gr√°fico de la serie de tiempo de la energ√≠a sin tendencia estimada con promedios m√≥viles.\n\n\n\n\n\n\n2.2.3 Tendencia con diferenciaci√≥n\nEn la Figura¬†2.8 se presentan los gr√°ficos de las series sin tendencia, estimada con regresi√≥n lineal y con diferenciaci√≥n respectivamente, se puede notar que la serie sin tendencia estimada con diferenciaci√≥n impide ver los ciclos que se ven en la serie original.\n\ntsibble_energia&lt;-as_tsibble(energia2)\npar(mar = c(2,2,2,2))\npar(mfrow=c(2,1))\n\nplot(resid(fit_e), type=\"l\", main=\"Sin tendencia lineal\") \nplot(diff(energia2), type=\"l\", main=\"Primera Diferencia\") \n\n\n\n\nFigura¬†2.8: Gr√°fico de la serie de tiempo de la energ√≠a sin tendencia estimada con regresi√≥n lineal y diferenciaci√≥n.\n\n\n\n\n\n\n2.2.4 Comparaci√≥n de los ACF\nEn la Figura¬†2.9 se puede notar un descenso r√°pido hacia 0 para las series original y sin tendencia estimada con regresi√≥n lineal, mientras que para la serie sin tendencia estimada con diferenciaci√≥n, se puede apreciar mejor el ciclo estacional de aproximadamente 7 d√≠as.\n\n# Gr√°ficos de los ACF\npar(mar = c(3,2,3,2))\npar(mfrow=c(3,1))\nacf(energia2, 60, main=\"ACF energia\")\nacf(resid(fit_e), 60, main=\"ACF Sin tendencia\") \nacf(diff(energia2), 60, main=\"ACF Primera Diferencia\")\n\n\n\n\nFigura¬†2.9: Gr√°ficos de autocorrelaci√≥n para la serie original, sin tendencia estimada con regresi√≥n lineal y con la primera diferencia.\n\n\n\n\nSi bien se estima la tendencia con diferentes m√©todos, se decide trabajar con la serie sin tendencia l√≠neal."
  },
  {
    "objectID": "Descriptivo Dian.html#tendencia-estimaci√≥n-y-eliminaci√≥n",
    "href": "Descriptivo Dian.html#tendencia-estimaci√≥n-y-eliminaci√≥n",
    "title": "2¬† An√°lisis descriptivo del recaudo de impuestos internos por la DIAN",
    "section": "2.2 Tendencia Estimaci√≥n y eliminaci√≥n",
    "text": "2.2 Tendencia Estimaci√≥n y eliminaci√≥n\nLuego de estabilizar la varianza marginal de nuestra serie, procederemos a estimar la tendencia y a eliminarla. Para estimar dicha tendencia inicaremos utilizando una tendencia lineal deterministica y posteriormente restaremos dicha tendencia estimada a los datos de nuestra serie, de este modo se tiene lo siguiente:\n\nsummary(fit<-lm(ldian2~time(ldian2),na.action=NULL))\n\n\nCall:\nlm(formula = ldian2 ~ time(ldian2), na.action = NULL)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.6587 -0.2338  0.0349  0.2164  0.8567 \n\nCoefficients:\n               Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -188.74811    5.53318  -34.11   <2e-16 ***\ntime(ldian2)    0.10150    0.00275   36.90   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3133 on 280 degrees of freedom\nMultiple R-squared:  0.8295,    Adjusted R-squared:  0.8289 \nF-statistic:  1362 on 1 and 280 DF,  p-value: < 2.2e-16\n\nplot(ldian2,ylab=\"Recaudo interno\") \nabline(fit,col=\"darkcyan\",lwd=2)\n\n\n\n\nPreliminarmente es posible ver que la recta se ajusta de un buen modo a nuestra serie de tiempo, puesto que la tendencia de nuestra serie es creciente, ahora procederemos a observar la serie de tiempo al eliminar la tendencia utilizando este metodo y tenemos lo siguiente:\n\nElimiTenddian<-ldian2-predict(fit)\nplot(ElimiTenddian,main=\"Serie Dian sin tendencia y con varianza estable\",\n     cex.main=1.3,\n     xlab=\"Tiempo\",\n     ylab=\"Recaudo interno\",\n     cex.lab=0.4)\n\n\n\n\nEs posible observar que nuestra serie de tiempo cambio considerablemente, puesto que la escala de los valores se disminujo bastante y adem√°s los datos oscilan al rededor del 0, lo cual nos indica que nuestra serie no presenta tendencia\n\nacf(ElimiTenddian,lag.max=179,main=\"Acf Serie Dian sin tendencia\")\n\n\n\n\nNotese que el gr√°fico de autocorrelaci√≥n, nos indica preliminarmente la presencia de posibles componente estacionales, pero esto lo analizaremos un poco m√°s en detalle m√°s adelante.\nPero este no es el unico modo de realizar la estimaci√≥n de la tendencia, tambien podemos utilizar herramientas no parametricas, pero como no hemos identificado la componente estacional, estas nos daran una estimaci√≥n preliminar de la tendencia. La primera de ellas que vamos a utilizar es la descomposici√≥n via filtros de promedios moviles, que se presenta a continuaci√≥n:\n\ndian_decompo=decompose(ldian2)\nplot(dian_decompo)\n\n\n\n#dian_decompo$trend\n\nNotese que la tendencia estimada via filtros de promedio moviles es aproximadamente lineal, lo cual respalda la idea de utilizar la forma deterministica de estimar la varianza, adem√°s parece estimar de mdodo correcto la componente estacional y en la componente residual se observan algunos patrones estacionales.\nAhora procederemos a utilizar la descomposci√≥n STL, para hacer un an√°lisis similar.\n\nlibrary(feasts)\nlibrary(fable)\n### Gr√°fico ##\ntsibble_dian<-as_tsibble(ldian2)\nstr(tsibble_dian)\n\ntbl_ts [282 √ó 2] (S3: tbl_ts/tbl_df/tbl/data.frame)\n $ index: mth [1:282] 2000 ene., 2000 feb., 2000 mar., 2000 abr., 2000 may., 200...\n $ value: num [1:282] 14.2 13.9 14 14.1 14.1 ...\n - attr(*, \"key\")= tibble [1 √ó 1] (S3: tbl_df/tbl/data.frame)\n  ..$ .rows: list<int> [1:1] \n  .. ..$ : int [1:282] 1 2 3 4 5 6 7 8 9 10 ...\n  .. ..@ ptype: int(0) \n - attr(*, \"index\")= chr \"index\"\n  ..- attr(*, \"ordered\")= logi TRUE\n - attr(*, \"index2\")= chr \"index\"\n - attr(*, \"interval\")= interval [1:1] 1M\n  ..@ .regular: logi TRUE\n\ntsibble_dian %>%\n  model(\n    STL(value ~ trend() +\n          season(window = \"periodic\"),\n        robust = TRUE)) %>%\n  components() %>%\n  autoplot()\n\n\n\n#tsibble_dian_notendstl<-tsibble_dian$Log\n\nNotese que el gr√°fico anterior es bastante similar al obtenido utilizando filtro de promedios moviles y podemos realizar una interpretaci√≥n bastante similar, Tambien es posible eliminar la tendencia utilizando diferenciaci√≥n, pero se debe tener en cuenta que la diferenciaci√≥n tambien puede eliminar la componente estacional que se tenga presente en la serie de tiempo, a continuaci√≥n se muestra la manera en que se realiz√≥ la eliminaci√≥n de la tendencia utilizando la diferenciaci√≥n y su comparaci√≥n con el primer metodo para eliminar tendencia utilizado.\n\npar(mar = c(2,2,2,2))\nfitdian = lm(ldian2~time(ldian2), na.action=NULL) \npar(mfrow=c(2,1))\nplot(resid(fitdian), type=\"l\", main=\"sin tendencia\") \nplot(diff(ldian2), type=\"l\", main=\"Primera Diferencia\") #Primera diferencia ordinaria\n\n\n\n\nNotese que cuando eliminamos la tendencia utilizando la diferenciaci√≥n se observa un poco m√°s centrada en comparaci√≥n a cuando utilizamos la regresi√≥n lineal ajustada, esto puede ser producto de la posible eliminaci√≥n de la componente estacional producto de la utilizaci√≥n de la diferenciaci√≥n Revisar bien esta interpretacion con las muchachas\nEn el siguiente grafico se compara las funciones de autocorrelaci√≥n obtenidas para la series cuando eliminamos la tendencia utilizando lm y utilizando diferenciaci√≥n, junto con la funci√≥n de autocorrelaci√≥n para la serie de tiempo con varianza marginal estable.\n\npar(mar = c(3,2,3,2))\npar(mfrow=c(3,1)) # plot ACFs\nacf(ldian2, 60, main=\"ACF Dian objeto ts varianza estable por boxcox\")\nacf(resid(fitdian), 60, main=\"ACF Sin tendencia (resid(fitdian))\") \nacf(diff(ldian2), 60, main=\"ACF Primera Diferencia\")\n\n\n\n\nFalta interpretaci√≥n WAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA"
  },
  {
    "objectID": "Descriptivo Dian.html#detecci√≥n-de-estacionalidad",
    "href": "Descriptivo Dian.html#detecci√≥n-de-estacionalidad",
    "title": "2¬† An√°lisis descriptivo del recaudo de impuestos internos por la DIAN",
    "section": "2.3 Detecci√≥n de estacionalidad",
    "text": "2.3 Detecci√≥n de estacionalidad\nLuego de estabilizar la varianza marginal y de tratar la tendencia, procedemos a observar si existe presencia de posibles ciclos o ciclos estacionales, para dicha tarea vamos a emplear multiples metodos descriptivos que nos permiten obtener informaci√≥n sobre esta componente. Iniciaremos por observar el grafico de retardos, el cual viene dado a continuaci√≥n:\n\nts_info(ElimiTenddian)\n\n The ElimiTenddian series is a ts object with 1 variable and 282 observations\n Frequency: 12 \n Start time: 2000 1 \n End time: 2023 6 \n\npar(mar = c(3,2,3,2))\nastsa::lag1.plot(ElimiTenddian, 12,corr=F)\n\n\n\nts_lags(ElimiTenddian,lags=1:12)\n\n\n\n\n\nEl gr√°fico de retardos nos indica de manera descriptiva la posible relaci√≥n existente entre un tiempo y algunos de sus retardos, para este caso en particular se toman 12 retardos (esto teniendo en cuenta la frecuencia mensual de la serie de tiempo), en este caso es posible observar que existe una clara relaci√≥n lineal y directa con el rezago 12, los dem√°s rezagos no parecen ser del todo significativos. Notese que los dos graficos anteriores nos dan una informaci√≥n bastante similar.\nAhora observemos el gr√°fico de subseries, el cual toma los valores por cada mes de cada uno de los a√±os dentro la serie, como sabemos buscamos obsevar si en el historico encontramos dieferentes valores medio mes tras mes, de este modo tenemos lo siguiente:\n\nrequire(feasts)\ndian2_tsbl_notend=as_tsibble(ElimiTenddian)\ndian2_tsbl_notend%>%gg_subseries(value)\n\n\n\n\nEs posible observar que la media en cada uno de los meses es distinta, esto es un claro indicio de la presencia de una componente ciclica estacional o ciclica, a contibuaci√≥n se presentan algunas otras graficas descriptivas para observar la presencia de un ciclo estaciona.\n\ndian2sint_df <- data.frame(year = floor(time(ElimiTenddian)), month = cycle(ElimiTenddian),ElimiTenddian = as.numeric(ElimiTenddian))\ndian2sint_df$month <- factor(month.abb[dian2sint_df$month], levels = month.abb)\ndian2sint_summary <- dian2sint_df %>%group_by(month) %>%summarise(mean= mean(ElimiTenddian),sd = sd(ElimiTenddian))\ndian2sint_summary\n\n# A tibble: 12 √ó 3\n   month    mean     sd\n   <fct>   <dbl>  <dbl>\n 1 Jan    0.320  0.150 \n 2 Feb   -0.230  0.206 \n 3 Mar   -0.0446 0.0880\n 4 Apr    0.244  0.311 \n 5 May    0.196  0.226 \n 6 Jun    0.199  0.259 \n 7 Jul    0.0320 0.123 \n 8 Aug   -0.230  0.255 \n 9 Sep    0.240  0.187 \n10 Oct   -0.386  0.128 \n11 Nov    0.0676 0.0882\n12 Dec   -0.439  0.0985\n\nplot_ly (data = dian2sint_summary, x = ~ month, y = ~ mean, type = \"bar\", name   = \"Mean\") %>%\n  layout (title = \"dian2sint - Monthly Average\", yaxis =list(title = \"Mean\",   range = c(min(dian2sint_summary$mean), max(dian2sint_summary$mean))))\n\n\n\n\n\nEn el anterior gr√°fico se observa el valor medio tomado por cada uno de los meses, es posible observar que tiene un comportamiento parecido al grafico de subseries y de manera analoga nos muestra que exite una componente estacional.\nA continuaci√≥n se muestran los mapas de calor para la serie Dian con varianza maeginal estable y tendencia eliminada por el metodo de diferenciacion y lineal.\n\nTSstudio::ts_heatmap(ElimiTenddian,title = \"Mapa de Calor - Impuestos Dian sin tendencia\")\n\n\n\n\nTSstudio::ts_heatmap(diff(ldian2),title = \"Mapa de Calor - Impuestos Dian sin tendencia\")\n\n\n\n\n\nAmbos mapas nos dan una informaci√≥n similar, en los cuales es posible observar que en los meses de noviembre, enero, junio, mayo y abril se tienen una mayor cantidad de recaudo de impuestos, mientras que en diciembre,octubre, agosto, marzo y febrero tienen un menor valor de recaudo de impuestos a√±o tras a√±o, nuevamente este gr√°fico nos ayuda a comprender la existencia de un cliclo estacional que posiblemente tenga un periodo de 12 meses.\n\n2.3.1 Periodograma\nCuando hablamos de una componente estacional dentro de nuestra serie de tiempo, tambien necesitamos hablar de su periodo y de su frecuencia, para esto utilizaremos el periodograma.\n\nspectrum(as.numeric(ElimiTenddian),log='no')\nabline(v=0.5, lty=2,col=\"red\")\n\n\n\nspectrum(as.numeric(ElimiTenddian),log='no',span=5)\n\n\n\nspectrum(as.numeric(ElimiTenddian),log='no',span=c(5,5))\n\n\n\nspectrum(as.numeric(ElimiTenddian),log='no',span=c(2,2))\n\n\n\n\nNotese que en los graficos anteriores se tienen diferentes valores de suavizamiento para nuestro periodograma, pues aunque en este caso no es dificil observar los puntos donde se tiene un pico, el suavizamiento puede ayudarnos a observar de mdood m√°s simple los picos que son verdaderamente significativos.\n\nPeriodgramadldian2_sintendencia=spectrum(as.numeric(ElimiTenddian),log='no')\n\n\n\nubicacionlogdian=which.max(Periodgramadldian2_sintendencia$spec)\nsprintf(\"El valor de la frecuencia donde se m√°ximiza el periodograma para la serie es: %s\",Periodgramadldian2_sintendencia$freq[ubicacionlogdian])\n\n[1] \"El valor de la frecuencia donde se m√°ximiza el periodograma para la serie es: 0.5\"\n\nsprintf(\"El periodo correspondiente es aproximadamente: %s\",1/Periodgramadldian2_sintendencia$freq[ubicacionlogdian])\n\n[1] \"El periodo correspondiente es aproximadamente: 2\"\n\n\nNotese que seg√∫n la salida obtenida, la frecuencia maxima se alcanza en 0.5 (es decir en 6/12=0.5) y se obtuvo que el periodo es 2, esto quiere decir que el ciclo se repite cada dos meses, pero notese que este es un multiplo no entero de 12, por lotanto en realidad se tiene que el periodo de la componente estacional serie de tipo anual (12 meses) Mirar esta interpretaci√≥n con las muchachas y preguntar al profe si esta correcto."
  },
  {
    "objectID": "Descriptivo Dian.html#desestacionalizar-o-eliminaci√≥n-de-la-componente-estacional",
    "href": "Descriptivo Dian.html#desestacionalizar-o-eliminaci√≥n-de-la-componente-estacional",
    "title": "2¬† An√°lisis descriptivo del recaudo de impuestos internos por la DIAN",
    "section": "2.4 Desestacionalizar o eliminaci√≥n de la componente estacional",
    "text": "2.4 Desestacionalizar o eliminaci√≥n de la componente estacional"
  },
  {
    "objectID": "Descriptivo Dian (2).html#estabilizaci√≥n-de-la-varianza-marginal",
    "href": "Descriptivo Dian (2).html#estabilizaci√≥n-de-la-varianza-marginal",
    "title": "1¬† An√°lisis descriptivo del recaudo de impuestos internos por la DIAN",
    "section": "1.1 Estabilizaci√≥n de la varianza marginal",
    "text": "1.1 Estabilizaci√≥n de la varianza marginal\nTeniendo en cuenta lo observado utilizando el gr√°fico de la serie de tiempo, se puede evidenciar una heteroscedasticidad marginal la cual debemos corregir, para esto utilizaremos la transformaci√≥n de Box-cox, la cual est√° dada por la siguiente f√≥rmula. \\[\\begin{equation}\n    f_{\\lambda}(u_{t})= \\begin{cases}\n        \\lambda^{-1}(u^{\\lambda}_{t}-1), &  \\text{si  $u_{t} \\geq 0$, para $\\lambda&gt;0$,}\\\\\n        \\ln(u_{t}), &\\text{ si $u_{t}&gt;0$, para $\\lambda=0$}.\n    \\end{cases}\n\\end{equation}\\]\nDonde el \\(Œª\\) apropiado debe ser estimado. N√≥tese que esta transformaci√≥n es posible, puesto que no se tienen valores negativos, de este modo se tiene seg√∫n la Figura¬†1.1 que:\n\nMASS::boxcox(lm(dian2 ~ 1),seq(-5, 5, length = 50)) ##Notese que no acputra al 1\nforecast::BoxCox.lambda(dian2, method =\"loglik\",\n                        lower = -1, upper = 3)#Entrega el valor de lambda (0.1).\n\n[1] 0.1\n\n\n\n\n\nFigura¬†1.1: Gr√°fico del valor lambda que maximiza la logverosmilitud.\n\n\n\n\nCon el anterior gr√°fico y salida podemos observar que el valor que maximiza la log-verosimilitud es 0.1, pero este valor es bastante cercano a 0, por lo tanto, lo aproximaremos a 0 para as√≠ poder utilizar la transformaci√≥n logaritmo, n√≥tese que el intervalo de confianza no captura al 1 en consecuencia puede ser conveniente realizar la transformaci√≥n. En los gr√°ficos de Figura¬†1.2 y Figura¬†1.3 analizaremos si dicha transformaci√≥n logra estabilizar la varianza marginal de nuestros datos.\n\nplot(forecast::BoxCox(dian2,lambda=0.1))\n\n\n\n\nFigura¬†1.2: Grafico de la serie con varianza estable utilizando lambda=0.1.\n\n\n\n\n\npar(mar = c(1,1,1,1))\nldian2=log(dian2)\nMASS::boxcox(lm(ldian2 ~ 1),seq(-5, 5, length = 50)) #Si captura al 1\n\n\n\n\nFigura¬†1.3: Grafico de la serie con varianza estable utilizando el logaritmo.\n\n\n\n\nN√≥tese que el intervalo de confianza de la transformaci√≥n Box-cox logra capturar el valor de 1, lo cual nos indica que no es necesario transformar los datos nuevamente o buscar otro valor para \\(\\lambda\\), adem√°s la transformaci√≥n ayudo de buena manera a estabilizar la varianza marginal de nuestra serie de tiempo.\nEn el gr√°fico Figura¬†1.4 y Figura¬†1.5 mostramos la serie de recaudo de la DIAN con y sin la transformaci√≥n logaritmo y es posible observar que la escala disminuyey que a su vez se observan algunos cambios considerables en la forma de la serie, lo cual es un buen indicativo de la relevancia de realizar la transformaci√≥n.\n\n#par(mfrow=c(2,1))\nplot(dian2,main=\"Serie Dian sin Transformar\")\n\n\n\n\nFigura¬†1.4: Serie DIAN sin transformar los datos utilizando el logaritmo.\n\n\n\n\n\nplot(ldian2,main=\"Series Dian con Transformaci√≥n BoxCox\")\n\n\n\n\nFigura¬†1.5: Serie DIAN con transformaci√≥n de los datos utilizando el logaritmo.\n\n\n\n\nTeniendo lo anterior en cuenta, presentaremos un gr√°fico (Figura¬†1.6) de la serie sin tendencia un poco m√°s interactivo e informativo, con el fin de lograr conocer los distintos valores en cada una de las fechas.\n\nclass(ldian2)\n\n[1] \"ts\"\n\ndian3&lt;-window(ldian2, start = c(2000,1))\nts_plot(dian3,title=\"Serie de tiempo del recaudo mensual interno\",\n        Ytitle=\"Recaudo interno\",\n        Xtitle=\"Tiempo\",\n        Xgrid=TRUE,\n        Ygrid=TRUE)\n\n\n\n\nFigura¬†1.6: Gr√°fico de la serie DIAN con los datos transformados."
  },
  {
    "objectID": "Descriptivo Dian (2).html#tendencia-estimaci√≥n-y-eliminaci√≥n",
    "href": "Descriptivo Dian (2).html#tendencia-estimaci√≥n-y-eliminaci√≥n",
    "title": "1¬† An√°lisis descriptivo del recaudo de impuestos internos por la DIAN",
    "section": "1.2 Tendencia Estimaci√≥n y eliminaci√≥n",
    "text": "1.2 Tendencia Estimaci√≥n y eliminaci√≥n\nLuego de estabilizar la varianza marginal de nuestra serie, procederemos a estimar la tendencia y a eliminarla. Para estimar dicha tendencia iniciaremos utilizando una estimaci√≥n lineal determin√≠stica de la tendencia y posteriormente restaremos la tendencia estimada a los datos de nuestra serie. EL ajuste de la recta se presenta en la Figura¬†1.7:\n\nsummary(fit&lt;-lm(ldian2~time(ldian2),na.action=NULL))\n\n\nCall:\nlm(formula = ldian2 ~ time(ldian2), na.action = NULL)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.6587 -0.2338  0.0349  0.2164  0.8567 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  -188.74811    5.53318  -34.11   &lt;2e-16 ***\ntime(ldian2)    0.10150    0.00275   36.90   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3133 on 280 degrees of freedom\nMultiple R-squared:  0.8295,    Adjusted R-squared:  0.8289 \nF-statistic:  1362 on 1 and 280 DF,  p-value: &lt; 2.2e-16\n\nplot(ldian2,ylab=\"Recaudo interno\") \nabline(fit,col=\"darkcyan\",lwd=2)\n\n\n\n\nFigura¬†1.7: Estimaci√≥n de la tendencia de manera deterministica.\n\n\n\n\nPreliminarmente, es posible ver que la recta se ajusta de un buen modo a nuestra serie de tiempo, puesto que la tendencia de nuestra serie es monotona creciente, ahora procederemos a observar la serie de tiempo al eliminar la tendencia utilizando este m√©todo, esto se observa en la gr√°fica Figura¬†1.8:\n\nElimiTenddian&lt;-ldian2-predict(fit)\nplot(ElimiTenddian,main=\"Serie Dian sin tendencia y con varianza estable\",\n     cex.main=1.3,\n     xlab=\"Tiempo\",\n     ylab=\"Recaudo interno\",\n     cex.lab=0.4)\n\n\n\n\nFigura¬†1.8: Serie DIANsin tendencia.\n\n\n\n\nEs posible observar que nuestra serie de tiempo cambio considerablemente, puesto que la escala de los valores se disminuy√≥ bastante y adem√°s los datos oscilan al rededor del 0, pero aun es posible observar una posible tendencia en nuestros datos, por lo tanto procedemos a analizar otras formas de eliminar la tendencia.\n\nacf(ElimiTenddian,lag.max=179,main=\"Acf Serie Dian sin tendencia\")\n\n\n\n\nFigura¬†1.9: Gr√°fico acf series DIAN sin tendencia.\n\n\n\n\nN√≥tese que el gr√°fico de autocorrelaci√≥n (Figura¬†1.9), nos indica preliminarmente la presencia de posibles componentes estacionales, pero esto lo analizaremos en detalle m√°s adelante.\nPero este no es el √∫nico modo de realizar la estimaci√≥n de la tendencia, tambi√©n podemos utilizar herramientas no param√©tricas, pero como no hemos identificado la componente estacional, estas nos dar√°n una estimaci√≥n preliminar de la tendencia. La primera de ellas que vamos a utilizar es la descomposici√≥n v√≠a filtros de promedios m√≥viles, que se presenta a continuaci√≥n (Figura¬†1.10):\n\ndian_decompo=decompose(ldian2)\nplot(dian_decompo)\n#dian_decompo$trend\n\n\n\n\nFigura¬†1.10: Descomposici√≥n via filtros de promedio moviles.\n\n\n\n\nN√≥tese que parece estimar de modo correcto la componente estacional y en la componente residual se observan algunos patrones estacionales, al an√°lizar la tendencia de este modo, podemos ver que aunque parece bastante lineal existen algunos lugares donde se ajusta mejor a ciertos comportamientos de la serie, por lo tanto podria ser viable utilizar esta tecnica para explorar la componente de tendencia.\nAhora procederemos a utilizar la descomposici√≥n STL, para hacer un an√°lisis similar(Figura¬†1.11).\n\nlibrary(feasts)\nlibrary(fable)\n### Gr√°fico ##\ntsibble_dian&lt;-as_tsibble(ldian2)\nstr(tsibble_dian)\n\ntbl_ts [282 √ó 2] (S3: tbl_ts/tbl_df/tbl/data.frame)\n $ index: mth [1:282] 2000 ene., 2000 feb., 2000 mar., 2000 abr., 2000 may., 200...\n $ value: num [1:282] 14.2 13.9 14 14.1 14.1 ...\n - attr(*, \"key\")= tibble [1 √ó 1] (S3: tbl_df/tbl/data.frame)\n  ..$ .rows: list&lt;int&gt; [1:1] \n  .. ..$ : int [1:282] 1 2 3 4 5 6 7 8 9 10 ...\n  .. ..@ ptype: int(0) \n - attr(*, \"index\")= chr \"index\"\n  ..- attr(*, \"ordered\")= logi TRUE\n - attr(*, \"index2\")= chr \"index\"\n - attr(*, \"interval\")= interval [1:1] 1M\n  ..@ .regular: logi TRUE\n\ntsibble_dian %&gt;%\n  model(\n    STL(value ~ trend() +\n          season(window = \"periodic\"),\n        robust = TRUE)) %&gt;%\n  components() %&gt;%\n  autoplot()\n\n\n\n\nFigura¬†1.11: Descomposici√≥n via STL.\n\n\n\n\n\n### Eliminando la tendencia por STL\nmodelo_stl &lt;- tsibble_dian %&gt;%\n  model(\n    STL(value ~ trend() +\n          season(window = \"periodic\"),\n        robust = TRUE)\n  ) %&gt;%\n  components()\n\n\nElimiTenddian_STL&lt;-ldian2-modelo_stl$trend\nplot(ElimiTenddian_STL,main=\"Serie Dian sin tendencia y con varianza estable (STL)\",\n     cex.main=1.3,\n     xlab=\"Tiempo\",\n     ylab=\"Recaudo interno\",\n     cex.lab=0.4)\n\n\n\n\nFigura¬†1.12: Desrie DIAN sin tendencia via STL.\n\n\n\n\nEs posible observar que el gr√°fico anterior (Figura¬†1.12) es bastante similar al obtenido utilizando filtro de promedios m√≥viles (Figura¬†1.10) y podemos realizar una interpretaci√≥n bastante similar, para continuar con nuestro an√°lisis procederemos a continuar utilizando la eliminaci√≥n de la tendencia via descomposici√≥n STL, pues es aquella que presenta un mejor desempe√±o,tambi√©n es posible eliminar la tendencia utilizando diferenciaci√≥n, pero se debe tener en cuenta que la diferenciaci√≥n puede eliminar la componente estacional que se tenga presente en la serie de tiempo, a continuaci√≥n se muestra la manera en que se realiz√≥ la eliminaci√≥n de la tendencia utilizando la diferenciaci√≥n y su comparaci√≥n con el m√©todo STL para eliminar tendencia utilizado en este trabajo (Figura¬†1.13).\n\npar(mar = c(2,2,2,2))\nfitdian = lm(ldian2~time(ldian2), na.action=NULL) \npar(mfrow=c(2,1))\nplot(ElimiTenddian_STL, type=\"l\", main=\"Sin tendencia via STL\") \nplot(diff(ldian2), type=\"l\", main=\"Primera Diferencia\") #Primera diferencia ordinaria\n\n\n\n\nFigura¬†1.13: Serie DIAN sin tendencia via STL vs diferenciaci√≥n.\n\n\n\n\nPodemos observar que a simple vista no hay diferencias muy importantes en cada una de las graficas, puesto que ambas se centran en 0 y parecen tener un comportamiento parecido.\nEn el siguiente gr√°fico (Figura¬†1.14) se compara las funciones de autocorrelaci√≥n obtenidas para la serie cuando eliminamos la tendencia utilizando descomposici√≥n STL y utilizando diferenciaci√≥n, junto con la funci√≥n de autocorrelaci√≥n para la serie de tiempo con tendencia.\n\npar(mar = c(3,2,3,2))\npar(mfrow=c(3,1)) # plot ACFs\nacf(ldian2, 60, main=\"ACF Dian con tendencia.\")\nacf(ElimiTenddian_STL, 60, main=\"ACF Sin tendencia STL.\") \nacf(diff(ldian2), 60, main=\"ACF Primera Diferencia.\")\n\n\n\n\nFigura¬†1.14: Comparacion de los gr√°ficos acf.\n\n\n\n\nEn el anterior gr√°fico (Figura¬†1.14), podemos observar que al eliminar la tendencia, el gr√°fico ACF baja mucho m√°s r√°pido en las series de tiempo donde se elimin√≥ la tendencia (por el m√©todo STL, como por el m√©todo de diferenciaci√≥n) en comparaci√≥n con la serie a la cual solo se le ajust√≥ la varianza marginal, pero tanto en la serie diferenciada como en la serie eliminada por STL, se observa la presencia de una alta correlaci√≥n en rezagos de tama√±o 12, lo cual es un indicio de la presencia de una componente estacional."
  },
  {
    "objectID": "Descriptivo Dian (2).html#detecci√≥n-de-estacionalidad",
    "href": "Descriptivo Dian (2).html#detecci√≥n-de-estacionalidad",
    "title": "1¬† An√°lisis descriptivo del recaudo de impuestos internos por la DIAN",
    "section": "1.3 Detecci√≥n de estacionalidad",
    "text": "1.3 Detecci√≥n de estacionalidad\nLuego de estabilizar la varianza marginal y de tratar la tendencia, procedemos a observar si existe presencia de posibles ciclos o ciclos estacionales, para dicha tarea vamos a emplear m√∫ltiples m√©todos descriptivos que nos permiten obtener informaci√≥n sobre esta componente. Iniciaremos por observar el gr√°fico de retardos, el cual viene dado a continuaci√≥n:\n\nts_info(ElimiTenddian_STL)\n\n The ElimiTenddian_STL series is a ts object with 1 variable and 282 observations\n Frequency: 12 \n Start time: 2000 1 \n End time: 2023 6 \n\npar(mar = c(3,2,3,2))\nastsa::lag1.plot(ElimiTenddian_STL, 12,corr=F)\n\n\n\n\nFigura¬†1.15: Gr√°fico de retardos.\n\n\n\n\n\nts_lags(ElimiTenddian_STL,lags=1:12)\n\n\n\n\nFigura¬†1.16: Gr√°fico de retardos.\n\n\n\nEl gr√°fico de retardos dado en Figura¬†1.15 y Figura¬†1.16, nos indican de manera descriptiva la posible relaci√≥n existente entre un tiempo y algunos de sus retardos, para este caso en particular se toman 12 retardos (esto teniendo en cuenta la frecuencia mensual de la serie de tiempo), en este caso es posible observar que existe una clara relaci√≥n lineal y directa con el rezago 12, los dem√°s rezagos no parecen ser del todo significativos. N√≥tese que los dos gr√°ficos anteriores nos dan una informaci√≥n bastante similar.\nAhora observemos el gr√°fico de sub series (Figura¬†1.17), el cual toma los valores por cada mes de cada uno de los a√±os dentro de la serie, como sabemos, se busca observar si en el hist√≥rico encontramos diferentes valores medios, mes tras mes, de este modo tenemos lo siguiente:\n\nrequire(feasts)\ndian2_tsbl_notend=as_tsibble(ElimiTenddian_STL)\ndian2_tsbl_notend%&gt;%gg_subseries(value)\n\n\n\n\nFigura¬†1.17: Gr√°fico de subseries.\n\n\n\n\nAl analizar el gr√°fico de sub series (Figura¬†1.17) es posible observar que la media en cada uno de los meses es distinta y no oscilan al rededor de un mismo valor, tomando su valor m√°ximo en los meses de enero, disminuyendo luego en los meses de febrero y marzo, luego vuelve a aumentar y a mantenerse estable durante los meses de abril, mayo y junio. Esto es un claro indicio de la presencia de una componente c√≠clica estacional o c√≠clica. A continuaci√≥n se presentan algunas otras gr√°ficas descriptivas para observar la presencia de un ciclo estaciona.\n\ndian2sint_df &lt;- data.frame(year = floor(time(ElimiTenddian_STL)), month = cycle(ElimiTenddian_STL),ElimiTenddian_STL = as.numeric(ElimiTenddian_STL))\ndian2sint_df$month &lt;- factor(month.abb[dian2sint_df$month], levels = month.abb)\ndian2sint_summary &lt;- dian2sint_df %&gt;%group_by(month) %&gt;%summarise(mean= mean(ElimiTenddian_STL),sd = sd(ElimiTenddian_STL))\ndian2sint_summary\n\n# A tibble: 12 √ó 3\n   month    mean     sd\n   &lt;fct&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n 1 Jan    0.341  0.0923\n 2 Feb   -0.211  0.177 \n 3 Mar   -0.0279 0.0540\n 4 Apr    0.259  0.248 \n 5 May    0.209  0.139 \n 6 Jun    0.210  0.175 \n 7 Jul    0.0473 0.0589\n 8 Aug   -0.216  0.226 \n 9 Sep    0.254  0.123 \n10 Oct   -0.374  0.104 \n11 Nov    0.0777 0.0591\n12 Dec   -0.431  0.102 \n\nplot_ly (data = dian2sint_summary, x = ~ month, y = ~ mean, type = \"bar\", name   = \"Mean\") %&gt;%\n  layout (title = \"dian2sint - Monthly Average\", yaxis =list(title = \"Mean\",   range = c(min(dian2sint_summary$mean), max(dian2sint_summary$mean))))\n\n\n\n\nFigura¬†1.18: Promedio mensual.\n\n\n\nEn el anterior gr√°fico (Figura¬†1.18) se observa el valor medio tomado por cada uno de los meses, es posible observar que tiene un comportamiento parecido al gr√°fico de sub series y de manera an√°loga nos muestra que existe una componente estacional.\nA continuaci√≥n se muestran los mapas de calor para la serie DIAN con varianza marginal estable y tendencia eliminada por el m√©todo de descomposici√≥n STL y el metodo de diferenciacio STL.\n\nTSstudio::ts_heatmap(ElimiTenddian_STL,title = \"Mapa de Calor - Impuestos Dian sin tendencia (STL)\")\n\n\n\n\nFigura¬†1.19: Graficos de calor serie DIAN sin tendencia por STLn.\n\n\n\n\nTSstudio::ts_heatmap(diff(ldian2),title = \"Mapa de Calor - Impuestos Dian sin tendencia (dif)\")\n\n\n\n\nFigura¬†1.20: Graficos de calor serie DIAN sin tendencia por diferenciaci√≥n.\n\n\n\nAmbos mapas (Figura¬†1.19 y Figura¬†1.20) nos dan una informaci√≥n similar, en los cuales es posible observar que en los meses de noviembre, enero, junio, mayo y abril se tienen una mayor cantidad de recaudo de impuestos, mientras que en diciembre, octubre, agosto, marzo y febrero tienen un menor valor de recaudo de impuestos a√±o tras a√±o, pero se observa un valor grande en mayo del 2007, nuevamente este gr√°fico nos ayuda a comprender la existencia de un ciclo estacional que posiblemente tenga un periodo de 12 meses. Es importante resaltar que el tener un valor medio alto en el mes de enero puede deberse al pago del impuesto predial en los primeros meses del a√±o.\nCuando hablamos de una componente estacional dentro de nuestra serie de tiempo, tambi√©n necesitamos hablar de su periodo y de su frecuencia, para esto utilizaremos el periodograma.\n\nspectrum(as.numeric(ElimiTenddian_STL),log='no')\nabline(v=0.5, lty=2,col=\"red\")\n\n\n\n\nFigura¬†1.21: Peridograma serie DIAN.\n\n\n\n\n\nspectrum(as.numeric(ElimiTenddian_STL),log='no',span=5)\n\n\n\n\nFigura¬†1.22: Peridograma serie DIAN.\n\n\n\n\n\nspectrum(as.numeric(ElimiTenddian_STL),log='no',span=c(5,5))\n\n\n\n\nFigura¬†1.23: Peridograma serie DIAN.\n\n\n\n\n\nspectrum(as.numeric(ElimiTenddian_STL),log='no',span=c(2,2))\n\n\n\n\nFigura¬†1.24: Peridograma serie DIAN.\n\n\n\n\nAl observar los gr√°ficos anteriores (Figura¬†1.21,Figura¬†1.22,Figura¬†1.23,Figura¬†1.24), es posible observar que se tienen diferentes valores de suavizamiento para nuestro periodograma, pues aunque en este caso no es dif√≠cil observar los puntos donde se tiene un pico, el suavizamiento puede ayudarnos a observar de modo m√°s simple los picos que son verdaderamente significativos.\n\nPeriodgramadldian2_sintendencia=spectrum(as.numeric(ElimiTenddian_STL),log='no')\nubicacionlogdian=which.max(Periodgramadldian2_sintendencia$spec)\nsprintf(\"El valor de la frecuencia donde se m√°ximiza el periodograma para la serie es: %s\",Periodgramadldian2_sintendencia$freq[ubicacionlogdian])\n\n[1] \"El valor de la frecuencia donde se m√°ximiza el periodograma para la serie es: 0.5\"\n\nsprintf(\"El periodo correspondiente es aproximadamente: %s\",1/Periodgramadldian2_sintendencia$freq[ubicacionlogdian])\n\n[1] \"El periodo correspondiente es aproximadamente: 2\"\n\n\n\n\n\nFigura¬†1.25: Periodograma serie DIAN.\n\n\n\n\nN√≥tese que seg√∫n la salida obtenida, la frecuencia m√°xima se alcanza en 0.5 (es decir, en 6/12=0.5) y se obtuvo que el periodo es 2, esto quiere decir que el ciclo se repite cada dos meses, pero se tiene que 12 es un m√∫ltiplo de 2, por lo tanto, en realidad se tiene que el periodo de la componente estacional seria de tipo anual (12 meses)"
  },
  {
    "objectID": "Descriptivo Dian (2).html#desestacionalizar-o-eliminaci√≥n-de-la-componente-estacional",
    "href": "Descriptivo Dian (2).html#desestacionalizar-o-eliminaci√≥n-de-la-componente-estacional",
    "title": "1¬† An√°lisis descriptivo del recaudo de impuestos internos por la DIAN",
    "section": "1.4 Desestacionalizar o eliminaci√≥n de la componente estacional",
    "text": "1.4 Desestacionalizar o eliminaci√≥n de la componente estacional\nCon el fin de realizar un correcto an√°lisis de la serie de tiempo en la cual no se tenga la interferencia de la estacionalidad, sino observar los verdaderos cambios de la serie de tiempo, procedemos a realizar la estimaci√≥n de la estacionalidad utilizando componentes de Fourier. En este caso se van a utilizar 3 componentes de fourier teniendo en cuenta lo observado en el an√°lisis realizado en el notebook de phyton.\n\n# Frecuencia angular w=2*pi/s\nfrec_ang=(2*pi/12)\n\ndian_copia=ElimiTenddian_STL\n\n#Fourier k=1 \ndian_copia$sin = sin(c(1:282)*(1*frec_ang))\n\nWarning in dian_copia$sin = sin(c(1:282) * (1 * frec_ang)): Realizando coercion\nde LHD a una lista\n\ndian_copia$cos = cos(c(1:282)*(1*frec_ang))\n\n#Fourier k=2 \ndian_copia$sin2 = sin(c(1:282)*(2*frec_ang))\ndian_copia$cos2 = cos(c(1:282)*(2*frec_ang))\n\n#Fourier k=3 \ndian_copia$sin3 = sin(c(1:282)*(3*frec_ang))\ndian_copia$cos3 = cos(c(1:282)*(3*frec_ang))\n#Fourier k=4\ndian_copia$sin4 = sin(c(1:282)*(4*frec_ang))\ndian_copia$cos4 = cos(c(1:282)*(4*frec_ang))\n\nlinmodel_ciclo_dian&lt;-lm(ElimiTenddian_STL~sin+cos+sin2+cos2\n                        +sin3+cos3+sin4+cos4,data=dian_copia)\nsummary(linmodel_ciclo_dian)\n\n\nCall:\nlm(formula = ElimiTenddian_STL ~ sin + cos + sin2 + cos2 + sin3 + \n    cos3 + sin4 + cos4, data = dian_copia)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.69466 -0.19457  0.01923  0.18382  0.59214 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.012058   0.014905   0.809 0.419221    \nsin          0.080869   0.021079   3.837 0.000155 ***\ncos         -0.134775   0.021079  -6.394 6.98e-10 ***\nsin2        -0.029576   0.021079  -1.403 0.161708    \ncos2         0.027994   0.021078   1.328 0.185257    \nsin3         0.118666   0.021079   5.630 4.48e-08 ***\ncos3        -0.001016   0.021079  -0.048 0.961610    \nsin4         0.062665   0.021076   2.973 0.003209 ** \ncos4        -0.009892   0.021077  -0.469 0.639222    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2502 on 273 degrees of freedom\nMultiple R-squared:  0.2691,    Adjusted R-squared:  0.2477 \nF-statistic: 12.56 on 8 and 273 DF,  p-value: 2.388e-15\n\nresults_ciclo_dian=linmodel_ciclo_dian$fitted.values\nresults_ciclo_dian&lt;-as.data.frame(results_ciclo_dian)\nresults_ciclo_ts&lt;-ts(results_ciclo_dian,start=c(2000,01),frequency=12)\n\n\n# Series original\nplot(ElimiTenddian_STL, main=\"Serie de tiempo de recaudo de impuestos DIAN\",\n     cex.main=1.3,\n     xlab=\"Tiempo \",\n     ylab=\"Recaudo\",\n     cex.lab=0.4)\n\n# Estimaci√≥n de la estacionalidad\nlines(results_ciclo_ts,col=\"red\")\n\n\n\n# Serie sin estacionalidad\nplot(ElimiTenddian_STL-results_ciclo_ts)\n\n\n\n\n\nacf(as.numeric(ElimiTenddian_STL-results_ciclo_ts))"
  },
  {
    "objectID": "Descriptivo Energia.html#gr√°ficas-de-retardos-e-√≠ndice-ami",
    "href": "Descriptivo Energia.html#gr√°ficas-de-retardos-e-√≠ndice-ami",
    "title": "2¬† An√°lisis del consumo de energ√≠a de la empresa PJM",
    "section": "2.3 Gr√°ficas de retardos e √≠ndice AMI",
    "text": "2.3 Gr√°ficas de retardos e √≠ndice AMI\n\npar(mar = c(3, 2, 3, 2))\nastsa::lag1.plot(ElimiTendenerg, 7,corr=F)\n\n\n\n\n\ntseriesChaos::mutual(ElimiTendenerg, partitions = 50, lag.max = 10, plot=TRUE) # AMI serie sin tendencia lineal\n\n\n\n\nEs posible ver que el primer rezago reduce el estado de incertidumbre para la observaci√≥n en el tiempo \\(t\\)."
  },
  {
    "objectID": "Entrega 2 bonito.html",
    "href": "Entrega 2 bonito.html",
    "title": "3¬† Entrega 2",
    "section": "",
    "text": "4 Ajuste de modelos para serie de Energ√≠a\nComo vimos en la secci√≥n anterior. Para la serie de energ√≠a no fue necesario estabilizar la varianza, sin embargo, esta presenta tanto tendencia como multiple estacionalidad (\\(7\\) y \\(365.25\\))\nUna vez realizado el an√°lisis descriptivo de la serie de energ√≠a, se da inicio al modelamiento de la misma. Este se har√° por medio de 3 modelos:\nEstos modelos ser√°n contrastados con base en su capacidad predictiva para seleccionar el mejor y realizar prediciones con √©l acerca del consumo diario de energia de la empresa PJM para fechas poseriores al a√±o 2018.\n# Librer√≠as necesarias\nlibrary(TSstudio)\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(lubridate)\nlibrary(astsa)\nlibrary(feasts)\nlibrary(fable)\nlibrary(timetk)\nlibrary(tsibble)\nlibrary(zoo)\nlibrary(xts)\nlibrary(readxl)\nlibrary(tidyverse)\nlibrary(nonlinearTseries)\nlibrary(tseriesChaos) \nlibrary(forecast)\nlibrary(plotly)\nlibrary(dplyr)\nlibrary(parsnip)\nlibrary(rsample)\nlibrary(timetk)\nlibrary(modeltime)\nlibrary(tsibble)\nlibrary(tidymodels)\nlibrary(greybox)\nlibrary(TSA)\nlibrary(urca)\nlibrary(lmtest)\nlibrary(uroot)\nlibrary(fUnitRoots)\nlibrary(sarima)\nlibrary(TSA)\nrequire(\"PolynomF\")\nrequire(\"forecast\")"
  },
  {
    "objectID": "Entrega 2 bonito.html#suavizamiento-exponencial",
    "href": "Entrega 2 bonito.html#suavizamiento-exponencial",
    "title": "3¬† Ajuste de modelos para serie de Energ√≠a",
    "section": "3.1 Suavizamiento Exponencial",
    "text": "3.1 Suavizamiento Exponencial\n\n3.1.0.0.1 Carga de la base de datos\n\n# Carga de la base de datos\nAEP_hourly&lt;-read.csv(\"AEP_hourly.csv\")\nAEP_hourly$Datetime&lt;-as.POSIXct(AEP_hourly$Datetime, format = \"%Y-%m-%d %H:%M:%S\")\nAEP_hourly$fecha&lt;-as.Date(AEP_hourly$Datetime)\n\nenergia &lt;- AEP_hourly %&gt;%\n  group_by(fecha) %&gt;%\n  summarise(Energia = sum(AEP_MW))\nenergia&lt;-energia[-5055,]\nenergia2&lt;-ts(energia$Energia,start=c(2004,10,01),frequency=365.25)\n\n\n# Creaci√≥n del objeto msts indicando las dos estacionalidades\nly &lt;- msts(energia$Energia,start=c(2004,10,01), seasonal.periods=c(7,365.25))\n\n#HW_ly=stats::HoltWinters(ly,seasonal=\"additive\") # parece que s√≠ funciona\n\n# Predicciones\n#forecast::forecast(HW_ly,h=7,level =0.95)\n#plot(forecast::forecast(HW_ly,h=7,level =0.95))\n\n\n\n3.1.0.1 Separaci√≥n datos de entrenamiento y prueba\nSe hizo una divisi√≥n de los datos originales, el \\(85\\%\\) para datos de entrenamiento y el \\(15\\%\\) restante para datoos de prueba.\n\n# Separar train y test\n\nh=1 # Haremos predicciones 1-paso hacia delante\n\n# Datos entrenamiento\nntrain=trunc(length(ly)*0.85) # 4295 datos\ntrain=window(ly,end=time(ly)[ntrain])\n\n# Datos prueba\ntest=window(ly,start=time(ly)[ntrain]+1/365.25)\nntest=length(test) # 729 datos\n\n# fchstepahe: Vector para guardar las predicciones h-pasos adelante\nfchstepahe=matrix(0,nrow=ntest,ncol=h) \n\n# verval: Vector con los verdaderos valores de la serie en el conjunto de prueba con los que se comparar√°n los pron√≥sticos\nverval=test[1:ntest]\n\n\n\n3.1.0.2 Ajuste del modelo\nEn el modelo por medio de suavizamiento exponencial tambi√©n se considera una descomposici√≥n de la serie de forma aditiva. Las componentes de tenendecia y la estacionalidad se estiman por medio de una estad√≠stica EWMA (promedio movil ponderado exponencialmente), d√°ndole m√°s peso a las observaciones m√°s cercanas en cada tiempo.\nAdem√°s, para este caso, se descompone la componente de tendencia en nivel y pendiente, y se estima un par√°metro de la componente estacional. Las estimaciones se hallan de la siguiente manera:\n\\[\\begin{align*}\n\\text{Componente de nivel: } & a_t=Œ±(x_t-S_{t-p})+(1‚àíŒ±)(a_{t‚àí1}+b_{t‚àí1})\\\\\n\\text{Componente de pendiente: } & b_t=Œ≤(a_t‚àía_{t‚àí1})+(1‚àíŒ≤)b_{t‚àí1} \\\\\n\\text{Componente estacional: } & S_t=\\gamma(x_t‚àía_t)+(1‚àíŒ≥)S_{t‚àíp} \\\\\n\\end{align*}\\]\nPara encontrar los par√°metros de suavizamiento \\(\\alpha\\), \\(\\beta\\) y \\(\\gamma\\) usamos una grilla con valores desde \\(0.001\\) hasta \\(0.999\\) de a \\(0.1\\) para cada par√°metro.\n\nrequire(utils)\n\n# Propuestas para cada par√°metro\nsuav_inputs=cbind(seq(0.001,0.999,0.1),seq(0.001,0.999,0.1),seq(0.001,0.999,0.1))\ncolnames(suav_inputs)&lt;-c(\"alpha\",\"beta\",\"gamma\")\nsuav_inputs_tbl=tibble::as_tibble(suav_inputs)\n\n# Creaci√≥n de la grilla\ngrilla_suav=expand.grid(alpha=suav_inputs_tbl$alpha,beta=suav_inputs_tbl$beta,gamma=suav_inputs_tbl$gamma)\n\n# Matriz para almacenar los errores\nerrores&lt;-matrix(NA, nrow=1000,ncol=3) \n\n# B√∫squeda de alpha, beta y gamma con rolling, queremos que minimice ECM\nfor(i in 1:1000){\n  ourCallETS &lt;- \"forecast::forecast(stats::HoltWinters(x=data,alpha=grilla_suav[i,1],beta=grilla_suav[i,2],gamma=grilla_suav[i,3]),h=h,level=95)\"\n  ourValueETS &lt;- c(\"mean\",\"lower\",\"upper\")\n  origins=ntest   # N√∫mero de rolling windows\n  Valoresretornados1 &lt;- ro(ly, h=h, origins=origins, call=ourCallETS, value=ourValueETS,ci=FALSE,co=FALSE)\n  t(Valoresretornados1$holdout) # Permiten verificar los verdaderos valores h-pasos adelante. \n  t(Valoresretornados1$mean)\n  errores[i,]&lt;-sqrt(apply((Valoresretornados1$holdout -Valoresretornados1$mean)^2,1,mean,na.rm=TRUE)) # Se calcula la ra√≠z del error cuadr√°tico medio de predicci√≥n\n}\n\n# Error medio absoluto escalado\nerrores&lt;-na.omit(errores) \nmin(errores[,1]) # RECM= 47201.82\nwhich(errores[,1] == min(errores[,1])) # 885\ngrilla_suav[885,] # alpha=0.701, beta=0.701, gamma=0.501\n\n\n\n[1] 47201.82\n\n\nDe modo que el modelo final para suavizamiento exponencial es\n\\[\\begin{align*}\n\\text{Componente de nivel: } & a_t=0.701(x_t-S_{t-p})+(1‚àí0.701)(a_{t‚àí1}+b_{t‚àí1})\\\\\n\\text{Componente de pendiente: } & b_t=0.701(a_t‚àía_{t‚àí1})+(1‚àí0.701)b_{t‚àí1} \\\\\n\\text{Componente estacional: } & S_t=0.7501(x_t‚àía_t)+(1‚àí0.501)S_{t‚àíp} \\\\\n\\end{align*}\\]\n\n\n3.1.0.3 Evaluar los supuestos\nAunque en suavizamiento exponencial no se hacen supuestos sobre los residuales, a√∫n as√≠ hicimos las pruebas para ver si los residuales ten√≠an un comportamiento similar a ruido blanco.\n\n# Verificaci√≥n de supuestos\nHW_train_grilla=stats::HoltWinters(train,seasonal=\"additive\",alpha=0.701,beta=0.701,gamma=0.501) # con los par√°metros que dieron mejor en la grilla\n\n# Residuales\nres &lt;- ly-HW_train_grilla$fitted[,1]\nplot(res)\n\n\n\n\n\n3.1.0.3.0.1 No autocorrelaci√≥n\nLuego de ser modelados con el suavizamiento exponencial, parece que a√∫n queda correlaci√≥n por explicar\n\n# ACF\nacf(as.numeric(res)) # No deber√≠an estar fuera de las bandas\n\n\n\n#acf(res^2)\n\n\n\n3.1.0.3.0.2 No autocorrelaci√≥n parcial\n\n# PACF\npacf(as.numeric(res)) # No deber√≠an estar fuera de las bandas\n\n\n\n\n\n\n3.1.0.3.0.3 Test de normalidad\nParece que no hay normalidad en los residuales\n\n# Test de normalidad\n## NO queremos rechazar H0 pero pues no es tan grave\ntseries::jarque.bera.test(res) # Dice que no son normales\n\n\n    Jarque Bera Test\n\ndata:  res\nX-squared = 49.017, df = 2, p-value = 2.27e-11\n\n\n\n\n3.1.0.3.0.4 Test de autocorrelaci√≥n\nLuego de ser modelados con el suavizamiento exponencial, parece que los residuales est√°n correlacionados\n\n# Test de autocorrelacion \n## No quieremos rechazar H0\nBox.test(res, lag =20 , type = \"Ljung-Box\", fitdf = 2) # No puedo Rechazar la hip√≥tesis de no autocorrelaci√≥n!\n\n\n    Box-Ljung test\n\ndata:  res\nX-squared = 6590.4, df = 18, p-value &lt; 2.2e-16\n\n\n\n\n3.1.0.3.0.5 Estabilizaci√≥n de la varianza\nCREO QUE ESTO ES MEJOR NO PONERLO PQ NO S√â SI SIRVA PARA SUAVIZAMIENTO\n\n# Estadisticas CUSUM\n## Mide la estabilidad en los par√°metros del modelo\ncum=cumsum(res)/sd(res)\nN=length(res)\ncumq=cumsum(res^2)/sum(res^2)\nAf=0.948 ###Cuantil del 95% para la estad?stica cusum\nco=0.01717####Valor del cuantil aproximado para cusumsq para n/2\nLS=Af*sqrt(N)+2*Af*c(1:length(res))/sqrt(N)\nLI=-LS\nLQS=co+(1:length(res))/N\nLQI=-co+(1:length(res))/N\nplot(cum,type=\"l\",ylim=c(min(LI),max(LS)),xlab=\"t\",ylab=\"\",main=\"CUSUM\")\nlines(LS,type=\"S\",col=\"red\")\nlines(LI,type=\"S\",col=\"red\")\n\n\n\n# Estad√≠sticas CUSUMSQ\n## Mide la estabilidad en la varianza del modelo\nplot(cumq,type=\"l\",xlab=\"t\",ylab=\"\",main=\"CUSUMSQ\")                      \nlines(LQS,type=\"S\",col=\"red\")                                           \nlines(LQI,type=\"S\",col=\"red\")\n\n\n\n\n\n\n\n3.1.0.4 Predicciones sobre datos de prueba\n\nverval_ts&lt;-ts(verval,start=time(ly)[ntrain]+1/365.25,frequency=365.25)\nfchstepahe_ts&lt;-ts(fchstepahe,start=time(ly)[ntrain]+1/365.25,frequency=365.25)\n\nplot(verval_ts, col = \"blue\", ylab = \"Energ√≠a\", xlab = \"Tiempo\")\nlines(fchstepahe_ts, col = \"red\")\nlegend(\"topright\", legend = c(\"Reales\", \"Predicciones\"), col = c(\"blue\", \"red\"), lty = 1)"
  },
  {
    "objectID": "Entrega 2 bonito.html#proceso-arma",
    "href": "Entrega 2 bonito.html#proceso-arma",
    "title": "3¬† Ajuste de modelos para serie de Energ√≠a",
    "section": "3.2 Proceso ARMA",
    "text": "3.2 Proceso ARMA\n\n3.2.0.1 Carga de la base de datos\nPara ajustar un modelo de la familia ARMA(p,q) es necesario que los datos sean estacionarios, por lo tanto, usamos los datos que resultan luego de eliminar la tendencia l√≠nealmente y eliminar la doble estacionalidad que fue modelada usando 6 componentes de Fourier (3 para \\(s=7\\) y 3 para \\(s=182\\))\n\n# Datos estacionales\ny&lt;-readRDS(\"energia_estacionarios.RDS\") # datos estacionarios\nplot(y)\n\n\n\nplot(y,xlim=c(2004,2006))\n\n\n\n\nComprobamos que son estacionarios observando la subserie semanal y la subserie mensual\n\n# Preliminares\nest_1&lt;-cbind(as.matrix(y),as.character(energia$fecha))\nest_1&lt;-as.data.frame(est_1)\nnames(est_1)&lt;-c(\"Energia\",\"fecha\")\n\nest_1$Energia&lt;-as.numeric(est_1$Energia)\nest_1$fecha&lt;-as.Date(est_1$fecha)\n\ndf_est=data.frame(Energia=est_1$Energia,fecha=est_1$fecha)\ntbl_est=tibble(df_est)\ntbl_est_format_fecha=tbl_est\ntsbl_est=as_tsibble(tbl_est_format_fecha,index=fecha)\n\n# Subserie semanal\ngg_subseries(tsbl_est,y=Energia,period=7)\n\n\n\n# Subserie mensual\ngg_subseries(tsbl_est,y=Energia,period=12)\n\n\n\n\n\n\n3.2.0.2 B√∫squeda de los hiperpar√°metros p y q\nLa b√∫squeda de los hiperpar√°metros p y q se hace v√≠a ACF y PACF\n\n# B√∫squeda de p,q v√≠a acf y pacf\n\n# B√∫squeda de q\nacf(as.numeric(y)) # Parece que q es gigante\n\n\n\n#acf(as.numeric(y),ci.type='ma') # En efecto, q es grande\n\n# B√∫squeda de p\npacf(as.numeric(y)) # p m√°ximo 3, posiblemente 5 o 6\n\n\n\n\nLuego de observar los gr√°ficos, vemos que es posible que \\(p=6\\) o menos, y \\(q\\) debe ser grand√≠simo, por razones pr√°cticas postulamos inicialmente \\(q=20\\), es razonable postular un modelo AR(6) y refinarlo, as√≠ como tambi√©n un modelo mixto ARMA(6,20) y refinarlo. No es nada razonable pensar en un \\(MA(q)\\) puro por lo que vemos que el ACF decae excesivamente lento.\n\n\n3.2.0.3 Ajuste del modelo ARMA\nInicialmente se ajust√≥ un modelo AR(6) y se refin√≥, sin embargo no se encontr√≥ un modelo autoregresivo puro que cumpliera los supuestos. Luego de una ardua b√∫squeda, finalmente encontramos un modelo mixto que cumpliera los supuestos, este es ARMA(5,8) que tambi√©n fue refinado, de modo que el modelo final es:\n\\[X_t=\\phi_1 X_{t-1}+\\phi_2 X_{t-2}+\\phi_3 X_{t-3}+Z_t+\\theta_1 Z_{t-1}+\\theta_2 Z_{t-2}+\\theta_3 Z_{t-3}+\\theta_4 Z_{t-4}+\\theta_6 Z_{t-6}\\]\n\n# Propuesta modelo ARMA\nmodelo.propuesto2=forecast::Arima(y,order=c(5,0,8),fixed=c(NA,NA,0,NA,0,NA,NA,NA,NA,0,NA,0,0,0)) # ARMA(5,8)\nlmtest::coeftest(modelo.propuesto2)\n\n\nz test of coefficients:\n\n     Estimate Std. Error  z value  Pr(&gt;|z|)    \nar1  0.278287   0.116425   2.3903   0.01684 *  \nar2  1.017041   0.143894   7.0680 1.572e-12 ***\nar4 -0.312920   0.034978  -8.9463 &lt; 2.2e-16 ***\nma1  0.819146   0.116858   7.0098 2.387e-12 ***\nma2 -0.567652   0.028526 -19.8992 &lt; 2.2e-16 ***\nma3 -0.828137   0.071508 -11.5811 &lt; 2.2e-16 ***\nma4 -0.244673   0.027497  -8.8982 &lt; 2.2e-16 ***\nma6  0.026696   0.011651   2.2913   0.02194 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n3.2.0.4 Evaluar los supuestos\nPara los modelos de la familia ARMA s√≠ se hacen supuestos sobre los residuales que deben comportarse como ruido blanco. Por lo tanto, es necesario validar los supuestos\n\n# Verificaci√≥n de supuestos ARMA\nres &lt;- modelo.propuesto2$residuals\nplot(res)\n\n\n\n\n\n3.2.0.4.0.1 No autocorrelaci√≥n\nEn general, los residuales presentan un buen comportamiento. No qued nada por explicar que no haya explicado ya el modelo.\n\n# ACF\nacf(as.numeric(res)) # No deber√≠an estar fuera de las bandas\n\n\n\n# acf(as.numeric(res^2))\n\n\n\n3.2.0.4.0.2 No autocorrelaci√≥n parcial\nEn general, los residuales presentan un buen comportamiento. No qued nada por explicar que no haya explicado ya el modelo.\n\n# PACF\npacf(as.numeric(res)) # No deber√≠an estar fuera de las bandas\n\n\n\n\n\n\n3.2.0.4.1 Test de normalidad\nParece ser que los datos NO son normales.\n\n#Test de normalidad \n## No queremos rechazar H0 pero pues no es tan grave\ntseries::jarque.bera.test(res)\n\n\n    Jarque Bera Test\n\ndata:  res\nX-squared = 2096.9, df = 2, p-value &lt; 2.2e-16\n\n\n\n\n3.2.0.4.2 Test de autocorrelaci√≥n\nCon un \\(p-value=\\) no hay suficiente evidencia estad√≠stica para rechazar la hip√≥stesis nula, es decir, los residuales NO est√°n correlacionados.\n\n#Test de autocorrelacion \n## No queremos rechazar H0 pq es la hip√≥tesis de no autocorrelaci√≥n\nBox.test(res, lag =20 , type = \"Ljung-Box\", fitdf = 2)\n\n\n    Box-Ljung test\n\ndata:  res\nX-squared = 19.468, df = 18, p-value = 0.3636\n\n\n\n\n3.2.0.4.3 Estabilizaci√≥n de la varianza\nParece que tanto los par√°metros como la varianza est√°n ‚Äúestables‚Äù.\n\n# Estadisticas CUSUM\n## Mide la estabilidad en los par√°metros del modelo\ncum=cumsum(res)/sd(res)\nN=length(res)\ncumq=cumsum(res^2)/sum(res^2)\nAf=0.948 ###Cuantil del 95% para la estad?stica cusum\nco=0.01717####Valor del cuantil aproximado para cusumsq para n/2\nLS=Af*sqrt(N)+2*Af*c(1:length(res))/sqrt(N)\nLI=-LS\nLQS=co+(1:length(res))/N\nLQI=-co+(1:length(res))/N\nplot(cum,type=\"l\",ylim=c(min(LI),max(LS)),xlab=\"t\",ylab=\"\",main=\"CUSUM\")\nlines(LS,type=\"S\",col=\"red\")\nlines(LI,type=\"S\",col=\"red\")\n\n\n\n# Estad√≠sticas CUSUMSQ\n## Mide la estabilidad en la varianza del modelo\nplot(cumq,type=\"l\",xlab=\"t\",ylab=\"\",main=\"CUSUMSQ\")                      \nlines(LQS,type=\"S\",col=\"red\")                                           \nlines(LQI,type=\"S\",col=\"red\")\n\n\n\n\n\n\n3.2.0.4.4 Rolling\nUna vez verificados los supuestos, se procede a evaluar la capacidad predictiva del modelo mixto. Para ello utilizamos rolling.\n\n# Rolling corregido\nfcmat=matrix(0,nrow=ntest,ncol=h)\nfor(i in 1:ntest){\n  x=window(y,end=time(ly)[ntrain]+(i-1)/365.25)\n  refit=Arima(x,model=modelo.propuesto2)\n  fcmat[i,]=as.numeric(forecast::forecast(refit,h=h)$mean) # Pron√≥sticos para datos estacionarios\n}\n\n\n# Para volver a la escala original\nestacionalidad&lt;-as.vector(results_ciclo_ts)\ntendencia&lt;-as.vector(predict(fit_e))\nfchstepahe&lt;-(fcmat+estacionalidad[4296:5054])+tendencia[4296:5054] # primero sumamos la estacionalidad y luego la tendencia\n\nerrores_pred = verval-fchstepahe \nECM=apply(errores_pred^2,MARGIN = 2,mean,na.rm=TRUE)\nRECM=sqrt(ECM)\nRECM # 22840.1\n\n[1] 22840.1\n\n\n\n\n\n3.2.0.5 Predicciones sobre datos de prueba\n\nfchstepahe_ts&lt;-ts(fchstepahe,start=time(ly)[ntrain]+1/365.25,frequency=365.25)\n\nplot(verval_ts, col = \"blue\", ylab = \"Energ√≠a\", xlab = \"Tiempo\")\nlines(fchstepahe_ts, col = \"red\")\nlegend(\"topright\", legend = c(\"Reales\", \"Predicciones\"), col = c(\"blue\", \"red\"), lty = 1)"
  },
  {
    "objectID": "Entrega 2 bonito.html#proceso-arima",
    "href": "Entrega 2 bonito.html#proceso-arima",
    "title": "3¬† Ajuste de modelos para serie de Energ√≠a",
    "section": "3.3 Proceso ARIMA",
    "text": "3.3 Proceso ARIMA\nPara ajustar un modelo ARIMA (aunque no es lo m√°s adecuado dado que la serie presenta componente estacional), primero se debe comprobar si la serie de tiempo presenta una ra√≠z unitaria. Teniendo en cuenta que, para la prueba de Dicker Fuller, si el \\(p-valor\\) es menor que un nivel de significancia \\(\\alpha\\) se rechaza la hipotesis nula de que la serie de tiempo presenta una ra√≠z unitaria, se tiene lo siguiente.\n\nstats::ar(energia2) # Selecciona un modelo AR usando el criterio de Akaike, sugiere tomar lags=36\n\n\nCall:\nstats::ar(x = energia2)\n\nCoefficients:\n      1        2        3        4        5        6        7        8  \n 1.0967  -0.4319   0.1631  -0.0202   0.0112   0.0217   0.1385  -0.1334  \n      9       10       11       12       13       14       15       16  \n 0.0302   0.0394  -0.0436  -0.0045   0.0394   0.1196  -0.1604   0.0593  \n     17       18       19       20       21       22       23       24  \n 0.0172  -0.0279   0.0320  -0.0221   0.1656  -0.1895   0.0736  -0.0536  \n     25       26       27       28       29       30       31       32  \n 0.0436  -0.0453   0.0435   0.1166  -0.1403   0.0378  -0.0228  -0.0066  \n     33       34       35       36  \n-0.0332   0.0232   0.1493  -0.1453  \n\nOrder selected 36  sigma^2 estimated as  329070266\n\ntseries::adf.test(energia2,k=36) # Prueba Dicker Fuller: No hay ra√≠z unitaria\n\nWarning in tseries::adf.test(energia2, k = 36): p-value smaller than printed\np-value\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  energia2\nDickey-Fuller = -8.1586, Lag order = 36, p-value = 0.01\nalternative hypothesis: stationary\n\nsummary(ur.df(energia2,type=\"trend\",lags = 36))\n\n\n############################################### \n# Augmented Dickey-Fuller Test Unit Root Test # \n############################################### \n\nTest regression trend \n\n\nCall:\nlm(formula = z.diff ~ z.lag.1 + 1 + tt + z.diff.lag)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-144842  -10683    -880   10058   98316 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   2.648e+04  3.278e+03   8.079 8.14e-16 ***\nz.lag.1      -6.722e-02  8.239e-03  -8.159 4.25e-16 ***\ntt           -5.746e-01  1.879e-01  -3.058 0.002240 ** \nz.diff.lag1   1.757e-01  1.554e-02  11.307  &lt; 2e-16 ***\nz.diff.lag2  -2.754e-01  1.569e-02 -17.549  &lt; 2e-16 ***\nz.diff.lag3  -9.995e-02  1.614e-02  -6.193 6.37e-10 ***\nz.diff.lag4  -1.297e-01  1.614e-02  -8.032 1.18e-15 ***\nz.diff.lag5  -1.096e-01  1.623e-02  -6.755 1.59e-11 ***\nz.diff.lag6  -9.557e-02  1.628e-02  -5.869 4.66e-09 ***\nz.diff.lag7   4.296e-02  1.633e-02   2.630 0.008558 ** \nz.diff.lag8  -8.916e-02  1.632e-02  -5.463 4.90e-08 ***\nz.diff.lag9  -5.914e-02  1.633e-02  -3.621 0.000297 ***\nz.diff.lag10 -1.984e-02  1.634e-02  -1.214 0.224918    \nz.diff.lag11 -6.555e-02  1.630e-02  -4.022 5.86e-05 ***\nz.diff.lag12 -6.658e-02  1.631e-02  -4.081 4.55e-05 ***\nz.diff.lag13 -2.957e-02  1.630e-02  -1.814 0.069749 .  \nz.diff.lag14  8.892e-02  1.630e-02   5.455 5.13e-08 ***\nz.diff.lag15 -7.011e-02  1.628e-02  -4.306 1.69e-05 ***\nz.diff.lag16 -1.172e-02  1.627e-02  -0.720 0.471424    \nz.diff.lag17  8.099e-03  1.623e-02   0.499 0.617737    \nz.diff.lag18 -2.567e-02  1.621e-02  -1.584 0.113336    \nz.diff.lag19  1.229e-02  1.616e-02   0.760 0.447063    \nz.diff.lag20 -1.552e-02  1.614e-02  -0.961 0.336397    \nz.diff.lag21  1.543e-01  1.610e-02   9.584  &lt; 2e-16 ***\nz.diff.lag22 -4.081e-02  1.614e-02  -2.529 0.011471 *  \nz.diff.lag23  3.898e-02  1.614e-02   2.415 0.015773 *  \nz.diff.lag24 -1.987e-02  1.609e-02  -1.235 0.217069    \nz.diff.lag25  2.709e-02  1.598e-02   1.695 0.090117 .  \nz.diff.lag26 -2.176e-02  1.588e-02  -1.371 0.170571    \nz.diff.lag27  2.413e-02  1.584e-02   1.524 0.127655    \nz.diff.lag28  1.405e-01  1.574e-02   8.923  &lt; 2e-16 ***\nz.diff.lag29 -5.265e-04  1.572e-02  -0.034 0.973277    \nz.diff.lag30  3.564e-02  1.571e-02   2.268 0.023358 *  \nz.diff.lag31  1.438e-02  1.555e-02   0.925 0.355066    \nz.diff.lag32  6.620e-03  1.535e-02   0.431 0.666276    \nz.diff.lag33 -2.859e-02  1.510e-02  -1.894 0.058303 .  \nz.diff.lag34 -4.864e-03  1.491e-02  -0.326 0.744260    \nz.diff.lag35  1.495e-01  1.411e-02  10.598  &lt; 2e-16 ***\nz.diff.lag36 -8.638e-03  1.415e-02  -0.610 0.541638    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 17980 on 4978 degrees of freedom\nMultiple R-squared:  0.5122,    Adjusted R-squared:  0.5084 \nF-statistic: 137.5 on 38 and 4978 DF,  p-value: &lt; 2.2e-16\n\n\nValue of test-statistic is: -8.1586 22.1938 33.2897 \n\nCritical values for test statistics: \n      1pct  5pct 10pct\ntau3 -3.96 -3.41 -3.12\nphi2  6.09  4.68  4.03\nphi3  8.27  6.25  5.34\n\n\nComo se puede ver, en ambos casos las pruebas muestran que la serie no presenta ra√≠ces unitarias, por lo que ajustar este modelo no es adecuado."
  },
  {
    "objectID": "Entrega 2 bonito.html#proceso-sarima",
    "href": "Entrega 2 bonito.html#proceso-sarima",
    "title": "3¬† Ajuste de modelos para serie de Energ√≠a",
    "section": "3.4 Proceso SARIMA",
    "text": "3.4 Proceso SARIMA\nDado que la serie presenta multiple estacionalidad, no es posible ajustar un modelo de la familia SARIMA."
  },
  {
    "objectID": "Descriptivo Dian (2).html",
    "href": "Descriptivo Dian (2).html",
    "title": "1¬† An√°lisis descriptivo del recaudo de impuestos internos por la DIAN",
    "section": "",
    "text": "2 Suavizamiento exponencial.\nEn el modelo por medio de suavizamiento exponencial tambi√©n se considera una descomposici√≥n de la serie de forma aditiva. Las componentes de tenendecia y la estacionalidad se estiman por medio de una estad√≠stica EWMA (promedio movil ponderado exponencialmente), d√°ndole m√°s peso a las observaciones m√°s cercanas en cada tiempo.\nAdem√°s, para este caso, se descompone la componente de tendencia en nivel y pendiente, y se estima un par√°metro de la componente estacional por mes, como lo indica el periodo hallado de 12. Las estimaciones se hallan de la siguiente manera:\n\\[\\begin{align*}\n\\text{Componente de nivel: } & a_t=Œ±(x_t-S_{t-p})+(1‚àíŒ±)(a_{t‚àí1}+b_{t‚àí1})\\\\\n\\text{Componente de pendiente: } & b_t=Œ≤(a_t‚àía_{t‚àí1})+(1‚àíŒ≤)b_{t‚àí1} \\\\\n\\text{Componente estacional: } & S_t=\\gamma(x_t‚àía_t)+(1‚àíŒ≥)S_{t‚àíp} \\\\\n\\end{align*}\\]\nPreparando los datos y tambien deividiendo el conjunto de datos para posteriormente Observar cual es el mejor modelo segun su capacidad predictiva.\nEn el siguiente aparatado se busca ajustar los modelos concernientes a la familia ARMA, esto quiere decir que se va a intentar realizar un modelamiento para un modelo AR, MA y ARMA, posteriormente se observara cual de los modelos ajustados es mejor en terminos de su capacidad predictiva comparando sus ECM.\nTeniendo en cuenta que para realizar el modelamiento utilizando ARMA es necesario que la serie de tiempo sea estacionaria, se utilizara la serie sin tendencia por medio de descomposici√≥n STL y se realizar√° el modelamiento simultaneamente eliminando la estacionalidad por medio de variables dummy y de componentes de Fourier.\nAntes de proceder con algun modelo ARIMA o SARIMA, realizaremos la prueba de raices unitarias de Dickey Fuller.\n##Aplicando la prueba de Dickey Fuller sobre la serie con varianza  estabilizada\npacf(ldian2)## SErie dian en escala logaritmica (Boxcox)\n\n\n\nar(ldian2)\n\n\nCall:\nar(x = ldian2)\n\nCoefficients:\n      1        2        3        4        5        6        7        8  \n 0.4535   0.4862  -0.0982   0.0570   0.0293  -0.1282   0.0188   0.1188  \n      9       10       11       12       13       14       15  \n-0.0002  -0.0061  -0.1034   0.6274  -0.3556  -0.2355   0.1044  \n\nOrder selected 15  sigma^2 estimated as  0.06139\n\nresultadodf_1&lt;-adf.test(ldian2,k=15)\nresultadodf_1\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  ldian2\nDickey-Fuller = -2.1889, Lag order = 15, p-value = 0.4965\nalternative hypothesis: stationary\n\nsummary(resultadodf_1)\n\n            Length Class  Mode     \nstatistic   1      -none- numeric  \nparameter   1      -none- numeric  \nalternative 1      -none- character\np.value     1      -none- numeric  \nmethod      1      -none- character\ndata.name   1      -none- character\nEn este caso se obtuvo un p-valor de 0.4965, el cual es mayor que un valor \\(\\alpha=0.05\\), lo que nos indica no se tiene evidencia estadistica suficiente para rechazar la hip√≥tesis nula de que la serie temporal tiene una ra√≠z unitaria. Ahora procederemos a realizar la diferenciaci√≥n ordinaria y luego se analizar√° si es necesario realizar una nueva diferenciaci√≥n.\n#Diferenciando la serie de tiempo \ndldian2=diff(ldian2)\nplot(dldian2)\npacf(as.numeric(dldian2),lag.max=length(dldian2)/4)\n\n\n\nacf(as.numeric(dldian2),lag.max = length(dldian2)/4)\n\n\n\nar(dldian2)\n\n\nCall:\nar(x = dldian2)\n\nCoefficients:\n      1        2        3        4        5        6        7        8  \n-0.9227  -0.4884  -0.4269  -0.3649  -0.3700  -0.4674  -0.4697  -0.4029  \n      9       10       11       12       13  \n-0.3865  -0.3352  -0.3523   0.3997   0.3078  \n\nOrder selected 13  sigma^2 estimated as  0.02836\n\nadf.test(dldian2,k=13)\n\nWarning in adf.test(dldian2, k = 13): p-value smaller than printed p-value\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  dldian2\nDickey-Fuller = -6.0912, Lag order = 13, p-value = 0.01\nalternative hypothesis: stationary\n\nsummary(ur.df(dldian2,type=\"trend\",lags = 13))\n\n\n############################################### \n# Augmented Dickey-Fuller Test Unit Root Test # \n############################################### \n\nTest regression trend \n\n\nCall:\nlm(formula = z.diff ~ z.lag.1 + 1 + tt + z.diff.lag)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.82132 -0.06071  0.00072  0.05370  0.62443 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   0.0754375  0.0245018   3.079 0.002309 ** \nz.lag.1      -6.5128269  1.0692177  -6.091 4.18e-09 ***\ntt           -0.0000857  0.0001238  -0.692 0.489328    \nz.diff.lag1   4.5409596  1.0437749   4.351 1.98e-05 ***\nz.diff.lag2   3.8961935  0.9887973   3.940 0.000106 ***\nz.diff.lag3   3.3603737  0.9054217   3.711 0.000254 ***\nz.diff.lag4   2.8633275  0.8195086   3.494 0.000562 ***\nz.diff.lag5   2.3745493  0.7321815   3.243 0.001343 ** \nz.diff.lag6   1.8058055  0.6444828   2.802 0.005476 ** \nz.diff.lag7   1.2235736  0.5555077   2.203 0.028531 *  \nz.diff.lag8   0.7043465  0.4681285   1.505 0.133684    \nz.diff.lag9   0.2005785  0.3836188   0.523 0.601534    \nz.diff.lag10 -0.2615684  0.2993684  -0.874 0.383098    \nz.diff.lag11 -0.7261802  0.2171391  -3.344 0.000951 ***\nz.diff.lag12 -0.3736073  0.1417028  -2.637 0.008897 ** \nz.diff.lag13 -0.0720133  0.0648302  -1.111 0.267718    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1522 on 251 degrees of freedom\nMultiple R-squared:  0.9738,    Adjusted R-squared:  0.9722 \nF-statistic: 620.7 on 15 and 251 DF,  p-value: &lt; 2.2e-16\n\n\nValue of test-statistic is: -6.0912 12.5025 18.7489 \n\nCritical values for test statistics: \n      1pct  5pct 10pct\ntau3 -3.98 -3.42 -3.13\nphi2  6.15  4.71  4.05\nphi3  8.34  6.30  5.36\n\nmonthplot(dldian2)\n\n\n\nspectrum(dldian2)\nAl utilizar ambos paquetes en este caso, se tiene que en ambas situaciones se obtiene un p-valor peque√±o, el cual es menor que \\(\\alpha=0.05\\), lo que quiere decir que hay evidencia estad√≠stica para afirmar que la serie temporal no tiene una ra√≠z unitaria, por lo tanto no ser√≠a necesario realizar m√°s diferenciaciones ordinarias.\nresiO= residuals(modelo_SARIMA_ref)\ncoefO= coefs2poly(modelo_SARIMA_ref)\noutliersSARIMA= locate.outliers(resiO,coefO,cval=4.5)\noutliersSARIMA\n\n   type ind     coefhat      tstat\n1    AO  50 -0.01728273  -4.608871\n2    AO  52  0.01983844   5.290414\n3    AO  76  0.02344045   6.250979\n4    AO  88 -0.04910246 -13.094393\n5    AO  89  0.03305053   8.813746\n6    AO 126 -0.02203517  -5.876224\n9    TC  26 -0.01407100  -4.540132\n10   TC  87 -0.01604647  -5.177532\n13   TC 123 -0.01402550  -4.525432\n14   TC 124 -0.02073909  -6.691616\n15   TC 125 -0.01667692  -5.380926\n\nn=length(df_train4)\nxregSARIMA = outliers.effects(outliersSARIMA,n )\nxregSARIMA\n\n       AO50 AO52 AO76 AO88 AO89 AO126         TC26         TC87        TC123\n  [1,]    0    0    0    0    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n  [2,]    0    0    0    0    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n  [3,]    0    0    0    0    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n  [4,]    0    0    0    0    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n  [5,]    0    0    0    0    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n  [6,]    0    0    0    0    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n  [7,]    0    0    0    0    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n  [8,]    0    0    0    0    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n  [9,]    0    0    0    0    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [10,]    0    0    0    0    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [11,]    0    0    0    0    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [12,]    0    0    0    0    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [13,]    0    0    0    0    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [14,]    0    0    0    0    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [15,]    0    0    0    0    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [16,]    0    0    0    0    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [17,]    0    0    0    0    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [18,]    0    0    0    0    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [19,]    0    0    0    0    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [20,]    0    0    0    0    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [21,]    0    0    0    0    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [22,]    0    0    0    0    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [23,]    0    0    0    0    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [24,]    0    0    0    0    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [25,]    0    0    0    0    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [26,]    0    0    0    0    0     0 1.000000e+00 0.000000e+00 0.000000e+00\n [27,]    0    0    0    0    0     0 7.000000e-01 0.000000e+00 0.000000e+00\n [28,]    0    0    0    0    0     0 4.900000e-01 0.000000e+00 0.000000e+00\n [29,]    0    0    0    0    0     0 3.430000e-01 0.000000e+00 0.000000e+00\n [30,]    0    0    0    0    0     0 2.401000e-01 0.000000e+00 0.000000e+00\n [31,]    0    0    0    0    0     0 1.680700e-01 0.000000e+00 0.000000e+00\n [32,]    0    0    0    0    0     0 1.176490e-01 0.000000e+00 0.000000e+00\n [33,]    0    0    0    0    0     0 8.235430e-02 0.000000e+00 0.000000e+00\n [34,]    0    0    0    0    0     0 5.764801e-02 0.000000e+00 0.000000e+00\n [35,]    0    0    0    0    0     0 4.035361e-02 0.000000e+00 0.000000e+00\n [36,]    0    0    0    0    0     0 2.824752e-02 0.000000e+00 0.000000e+00\n [37,]    0    0    0    0    0     0 1.977327e-02 0.000000e+00 0.000000e+00\n [38,]    0    0    0    0    0     0 1.384129e-02 0.000000e+00 0.000000e+00\n [39,]    0    0    0    0    0     0 9.688901e-03 0.000000e+00 0.000000e+00\n [40,]    0    0    0    0    0     0 6.782231e-03 0.000000e+00 0.000000e+00\n [41,]    0    0    0    0    0     0 4.747562e-03 0.000000e+00 0.000000e+00\n [42,]    0    0    0    0    0     0 3.323293e-03 0.000000e+00 0.000000e+00\n [43,]    0    0    0    0    0     0 2.326305e-03 0.000000e+00 0.000000e+00\n [44,]    0    0    0    0    0     0 1.628414e-03 0.000000e+00 0.000000e+00\n [45,]    0    0    0    0    0     0 1.139890e-03 0.000000e+00 0.000000e+00\n [46,]    0    0    0    0    0     0 7.979227e-04 0.000000e+00 0.000000e+00\n [47,]    0    0    0    0    0     0 5.585459e-04 0.000000e+00 0.000000e+00\n [48,]    0    0    0    0    0     0 3.909821e-04 0.000000e+00 0.000000e+00\n [49,]    0    0    0    0    0     0 2.736875e-04 0.000000e+00 0.000000e+00\n [50,]    1    0    0    0    0     0 1.915812e-04 0.000000e+00 0.000000e+00\n [51,]    0    0    0    0    0     0 1.341069e-04 0.000000e+00 0.000000e+00\n [52,]    0    1    0    0    0     0 9.387480e-05 0.000000e+00 0.000000e+00\n [53,]    0    0    0    0    0     0 6.571236e-05 0.000000e+00 0.000000e+00\n [54,]    0    0    0    0    0     0 4.599865e-05 0.000000e+00 0.000000e+00\n [55,]    0    0    0    0    0     0 3.219906e-05 0.000000e+00 0.000000e+00\n [56,]    0    0    0    0    0     0 2.253934e-05 0.000000e+00 0.000000e+00\n [57,]    0    0    0    0    0     0 1.577754e-05 0.000000e+00 0.000000e+00\n [58,]    0    0    0    0    0     0 1.104428e-05 0.000000e+00 0.000000e+00\n [59,]    0    0    0    0    0     0 7.730994e-06 0.000000e+00 0.000000e+00\n [60,]    0    0    0    0    0     0 5.411696e-06 0.000000e+00 0.000000e+00\n [61,]    0    0    0    0    0     0 3.788187e-06 0.000000e+00 0.000000e+00\n [62,]    0    0    0    0    0     0 2.651731e-06 0.000000e+00 0.000000e+00\n [63,]    0    0    0    0    0     0 1.856212e-06 0.000000e+00 0.000000e+00\n [64,]    0    0    0    0    0     0 1.299348e-06 0.000000e+00 0.000000e+00\n [65,]    0    0    0    0    0     0 9.095437e-07 0.000000e+00 0.000000e+00\n [66,]    0    0    0    0    0     0 6.366806e-07 0.000000e+00 0.000000e+00\n [67,]    0    0    0    0    0     0 4.456764e-07 0.000000e+00 0.000000e+00\n [68,]    0    0    0    0    0     0 3.119735e-07 0.000000e+00 0.000000e+00\n [69,]    0    0    0    0    0     0 2.183814e-07 0.000000e+00 0.000000e+00\n [70,]    0    0    0    0    0     0 1.528670e-07 0.000000e+00 0.000000e+00\n [71,]    0    0    0    0    0     0 1.070069e-07 0.000000e+00 0.000000e+00\n [72,]    0    0    0    0    0     0 7.490483e-08 0.000000e+00 0.000000e+00\n [73,]    0    0    0    0    0     0 5.243338e-08 0.000000e+00 0.000000e+00\n [74,]    0    0    0    0    0     0 3.670337e-08 0.000000e+00 0.000000e+00\n [75,]    0    0    0    0    0     0 2.569236e-08 0.000000e+00 0.000000e+00\n [76,]    0    0    1    0    0     0 1.798465e-08 0.000000e+00 0.000000e+00\n [77,]    0    0    0    0    0     0 1.258926e-08 0.000000e+00 0.000000e+00\n [78,]    0    0    0    0    0     0 8.812479e-09 0.000000e+00 0.000000e+00\n [79,]    0    0    0    0    0     0 6.168735e-09 0.000000e+00 0.000000e+00\n [80,]    0    0    0    0    0     0 4.318115e-09 0.000000e+00 0.000000e+00\n [81,]    0    0    0    0    0     0 3.022680e-09 0.000000e+00 0.000000e+00\n [82,]    0    0    0    0    0     0 2.115876e-09 0.000000e+00 0.000000e+00\n [83,]    0    0    0    0    0     0 1.481113e-09 0.000000e+00 0.000000e+00\n [84,]    0    0    0    0    0     0 1.036779e-09 0.000000e+00 0.000000e+00\n [85,]    0    0    0    0    0     0 7.257455e-10 0.000000e+00 0.000000e+00\n [86,]    0    0    0    0    0     0 5.080219e-10 0.000000e+00 0.000000e+00\n [87,]    0    0    0    0    0     0 3.556153e-10 1.000000e+00 0.000000e+00\n [88,]    0    0    0    1    0     0 2.489307e-10 7.000000e-01 0.000000e+00\n [89,]    0    0    0    0    1     0 1.742515e-10 4.900000e-01 0.000000e+00\n [90,]    0    0    0    0    0     0 1.219760e-10 3.430000e-01 0.000000e+00\n [91,]    0    0    0    0    0     0 8.538323e-11 2.401000e-01 0.000000e+00\n [92,]    0    0    0    0    0     0 5.976826e-11 1.680700e-01 0.000000e+00\n [93,]    0    0    0    0    0     0 4.183778e-11 1.176490e-01 0.000000e+00\n [94,]    0    0    0    0    0     0 2.928645e-11 8.235430e-02 0.000000e+00\n [95,]    0    0    0    0    0     0 2.050051e-11 5.764801e-02 0.000000e+00\n [96,]    0    0    0    0    0     0 1.435036e-11 4.035361e-02 0.000000e+00\n [97,]    0    0    0    0    0     0 1.004525e-11 2.824752e-02 0.000000e+00\n [98,]    0    0    0    0    0     0 7.031676e-12 1.977327e-02 0.000000e+00\n [99,]    0    0    0    0    0     0 4.922174e-12 1.384129e-02 0.000000e+00\n[100,]    0    0    0    0    0     0 3.445521e-12 9.688901e-03 0.000000e+00\n[101,]    0    0    0    0    0     0 2.411865e-12 6.782231e-03 0.000000e+00\n[102,]    0    0    0    0    0     0 1.688306e-12 4.747562e-03 0.000000e+00\n[103,]    0    0    0    0    0     0 1.181814e-12 3.323293e-03 0.000000e+00\n[104,]    0    0    0    0    0     0 8.272697e-13 2.326305e-03 0.000000e+00\n[105,]    0    0    0    0    0     0 5.790888e-13 1.628414e-03 0.000000e+00\n[106,]    0    0    0    0    0     0 4.053622e-13 1.139890e-03 0.000000e+00\n[107,]    0    0    0    0    0     0 2.837535e-13 7.979227e-04 0.000000e+00\n[108,]    0    0    0    0    0     0 1.986275e-13 5.585459e-04 0.000000e+00\n[109,]    0    0    0    0    0     0 1.390392e-13 3.909821e-04 0.000000e+00\n[110,]    0    0    0    0    0     0 9.732745e-14 2.736875e-04 0.000000e+00\n[111,]    0    0    0    0    0     0 6.812922e-14 1.915812e-04 0.000000e+00\n[112,]    0    0    0    0    0     0 4.769045e-14 1.341069e-04 0.000000e+00\n[113,]    0    0    0    0    0     0 3.338332e-14 9.387480e-05 0.000000e+00\n[114,]    0    0    0    0    0     0 2.336832e-14 6.571236e-05 0.000000e+00\n[115,]    0    0    0    0    0     0 1.635783e-14 4.599865e-05 0.000000e+00\n[116,]    0    0    0    0    0     0 1.145048e-14 3.219906e-05 0.000000e+00\n[117,]    0    0    0    0    0     0 8.015334e-15 2.253934e-05 0.000000e+00\n[118,]    0    0    0    0    0     0 5.610734e-15 1.577754e-05 0.000000e+00\n[119,]    0    0    0    0    0     0 3.927514e-15 1.104428e-05 0.000000e+00\n[120,]    0    0    0    0    0     0 2.749260e-15 7.730994e-06 0.000000e+00\n[121,]    0    0    0    0    0     0 1.924482e-15 5.411696e-06 0.000000e+00\n[122,]    0    0    0    0    0     0 1.347137e-15 3.788187e-06 0.000000e+00\n[123,]    0    0    0    0    0     0 9.429961e-16 2.651731e-06 1.000000e+00\n[124,]    0    0    0    0    0     0 6.600972e-16 1.856212e-06 7.000000e-01\n[125,]    0    0    0    0    0     0 4.620681e-16 1.299348e-06 4.900000e-01\n[126,]    0    0    0    0    0     1 3.234477e-16 9.095437e-07 3.430000e-01\n[127,]    0    0    0    0    0     0 2.264134e-16 6.366806e-07 2.401000e-01\n[128,]    0    0    0    0    0     0 1.584893e-16 4.456764e-07 1.680700e-01\n[129,]    0    0    0    0    0     0 1.109425e-16 3.119735e-07 1.176490e-01\n[130,]    0    0    0    0    0     0 7.765978e-17 2.183814e-07 8.235430e-02\n[131,]    0    0    0    0    0     0 5.436185e-17 1.528670e-07 5.764801e-02\n[132,]    0    0    0    0    0     0 3.805329e-17 1.070069e-07 4.035361e-02\n[133,]    0    0    0    0    0     0 2.663730e-17 7.490483e-08 2.824752e-02\n[134,]    0    0    0    0    0     0 1.864611e-17 5.243338e-08 1.977327e-02\n[135,]    0    0    0    0    0     0 1.305228e-17 3.670337e-08 1.384129e-02\n[136,]    0    0    0    0    0     0 9.136596e-18 2.569236e-08 9.688901e-03\n[137,]    0    0    0    0    0     0 6.395617e-18 1.798465e-08 6.782231e-03\n[138,]    0    0    0    0    0     0 4.476932e-18 1.258926e-08 4.747562e-03\n[139,]    0    0    0    0    0     0 3.133852e-18 8.812479e-09 3.323293e-03\n[140,]    0    0    0    0    0     0 2.193697e-18 6.168735e-09 2.326305e-03\n[141,]    0    0    0    0    0     0 1.535588e-18 4.318115e-09 1.628414e-03\n[142,]    0    0    0    0    0     0 1.074911e-18 3.022680e-09 1.139890e-03\n[143,]    0    0    0    0    0     0 7.524379e-19 2.115876e-09 7.979227e-04\n[144,]    0    0    0    0    0     0 5.267066e-19 1.481113e-09 5.585459e-04\n[145,]    0    0    0    0    0     0 3.686946e-19 1.036779e-09 3.909821e-04\n[146,]    0    0    0    0    0     0 2.580862e-19 7.257455e-10 2.736875e-04\n[147,]    0    0    0    0    0     0 1.806603e-19 5.080219e-10 1.915812e-04\n[148,]    0    0    0    0    0     0 1.264622e-19 3.556153e-10 1.341069e-04\n[149,]    0    0    0    0    0     0 8.852357e-20 2.489307e-10 9.387480e-05\n[150,]    0    0    0    0    0     0 6.196650e-20 1.742515e-10 6.571236e-05\n[151,]    0    0    0    0    0     0 4.337655e-20 1.219760e-10 4.599865e-05\n[152,]    0    0    0    0    0     0 3.036358e-20 8.538323e-11 3.219906e-05\n[153,]    0    0    0    0    0     0 2.125451e-20 5.976826e-11 2.253934e-05\n[154,]    0    0    0    0    0     0 1.487816e-20 4.183778e-11 1.577754e-05\n[155,]    0    0    0    0    0     0 1.041471e-20 2.928645e-11 1.104428e-05\n[156,]    0    0    0    0    0     0 7.290297e-21 2.050051e-11 7.730994e-06\n[157,]    0    0    0    0    0     0 5.103208e-21 1.435036e-11 5.411696e-06\n[158,]    0    0    0    0    0     0 3.572245e-21 1.004525e-11 3.788187e-06\n[159,]    0    0    0    0    0     0 2.500572e-21 7.031676e-12 2.651731e-06\n[160,]    0    0    0    0    0     0 1.750400e-21 4.922174e-12 1.856212e-06\n[161,]    0    0    0    0    0     0 1.225280e-21 3.445521e-12 1.299348e-06\n[162,]    0    0    0    0    0     0 8.576961e-22 2.411865e-12 9.095437e-07\n[163,]    0    0    0    0    0     0 6.003873e-22 1.688306e-12 6.366806e-07\n[164,]    0    0    0    0    0     0 4.202711e-22 1.181814e-12 4.456764e-07\n[165,]    0    0    0    0    0     0 2.941898e-22 8.272697e-13 3.119735e-07\n[166,]    0    0    0    0    0     0 2.059328e-22 5.790888e-13 2.183814e-07\n[167,]    0    0    0    0    0     0 1.441530e-22 4.053622e-13 1.528670e-07\n[168,]    0    0    0    0    0     0 1.009071e-22 2.837535e-13 1.070069e-07\n[169,]    0    0    0    0    0     0 7.063496e-23 1.986275e-13 7.490483e-08\n[170,]    0    0    0    0    0     0 4.944447e-23 1.390392e-13 5.243338e-08\n[171,]    0    0    0    0    0     0 3.461113e-23 9.732745e-14 3.670337e-08\n[172,]    0    0    0    0    0     0 2.422779e-23 6.812922e-14 2.569236e-08\n[173,]    0    0    0    0    0     0 1.695945e-23 4.769045e-14 1.798465e-08\n[174,]    0    0    0    0    0     0 1.187162e-23 3.338332e-14 1.258926e-08\n[175,]    0    0    0    0    0     0 8.310133e-24 2.336832e-14 8.812479e-09\n[176,]    0    0    0    0    0     0 5.817093e-24 1.635783e-14 6.168735e-09\n[177,]    0    0    0    0    0     0 4.071965e-24 1.145048e-14 4.318115e-09\n[178,]    0    0    0    0    0     0 2.850376e-24 8.015334e-15 3.022680e-09\n[179,]    0    0    0    0    0     0 1.995263e-24 5.610734e-15 2.115876e-09\n[180,]    0    0    0    0    0     0 1.396684e-24 3.927514e-15 1.481113e-09\n[181,]    0    0    0    0    0     0 9.776788e-25 2.749260e-15 1.036779e-09\n[182,]    0    0    0    0    0     0 6.843752e-25 1.924482e-15 7.257455e-10\n[183,]    0    0    0    0    0     0 4.790626e-25 1.347137e-15 5.080219e-10\n[184,]    0    0    0    0    0     0 3.353438e-25 9.429961e-16 3.556153e-10\n[185,]    0    0    0    0    0     0 2.347407e-25 6.600972e-16 2.489307e-10\n[186,]    0    0    0    0    0     0 1.643185e-25 4.620681e-16 1.742515e-10\n[187,]    0    0    0    0    0     0 1.150229e-25 3.234477e-16 1.219760e-10\n[188,]    0    0    0    0    0     0 8.051605e-26 2.264134e-16 8.538323e-11\n[189,]    0    0    0    0    0     0 5.636124e-26 1.584893e-16 5.976826e-11\n[190,]    0    0    0    0    0     0 3.945287e-26 1.109425e-16 4.183778e-11\n[191,]    0    0    0    0    0     0 2.761701e-26 7.765978e-17 2.928645e-11\n[192,]    0    0    0    0    0     0 1.933190e-26 5.436185e-17 2.050051e-11\n[193,]    0    0    0    0    0     0 1.353233e-26 3.805329e-17 1.435036e-11\n[194,]    0    0    0    0    0     0 9.472633e-27 2.663730e-17 1.004525e-11\n[195,]    0    0    0    0    0     0 6.630843e-27 1.864611e-17 7.031676e-12\n[196,]    0    0    0    0    0     0 4.641590e-27 1.305228e-17 4.922174e-12\n[197,]    0    0    0    0    0     0 3.249113e-27 9.136596e-18 3.445521e-12\n[198,]    0    0    0    0    0     0 2.274379e-27 6.395617e-18 2.411865e-12\n[199,]    0    0    0    0    0     0 1.592065e-27 4.476932e-18 1.688306e-12\n[200,]    0    0    0    0    0     0 1.114446e-27 3.133852e-18 1.181814e-12\n[201,]    0    0    0    0    0     0 7.801121e-28 2.193697e-18 8.272697e-13\n[202,]    0    0    0    0    0     0 5.460785e-28 1.535588e-18 5.790888e-13\n[203,]    0    0    0    0    0     0 3.822549e-28 1.074911e-18 4.053622e-13\n[204,]    0    0    0    0    0     0 2.675784e-28 7.524379e-19 2.837535e-13\n[205,]    0    0    0    0    0     0 1.873049e-28 5.267066e-19 1.986275e-13\n[206,]    0    0    0    0    0     0 1.311134e-28 3.686946e-19 1.390392e-13\n[207,]    0    0    0    0    0     0 9.177941e-29 2.580862e-19 9.732745e-14\n[208,]    0    0    0    0    0     0 6.424558e-29 1.806603e-19 6.812922e-14\n[209,]    0    0    0    0    0     0 4.497191e-29 1.264622e-19 4.769045e-14\n[210,]    0    0    0    0    0     0 3.148034e-29 8.852357e-20 3.338332e-14\n[211,]    0    0    0    0    0     0 2.203624e-29 6.196650e-20 2.336832e-14\n[212,]    0    0    0    0    0     0 1.542536e-29 4.337655e-20 1.635783e-14\n[213,]    0    0    0    0    0     0 1.079776e-29 3.036358e-20 1.145048e-14\n[214,]    0    0    0    0    0     0 7.558429e-30 2.125451e-20 8.015334e-15\n[215,]    0    0    0    0    0     0 5.290900e-30 1.487816e-20 5.610734e-15\n[216,]    0    0    0    0    0     0 3.703630e-30 1.041471e-20 3.927514e-15\n[217,]    0    0    0    0    0     0 2.592541e-30 7.290297e-21 2.749260e-15\n[218,]    0    0    0    0    0     0 1.814779e-30 5.103208e-21 1.924482e-15\n[219,]    0    0    0    0    0     0 1.270345e-30 3.572245e-21 1.347137e-15\n[220,]    0    0    0    0    0     0 8.892416e-31 2.500572e-21 9.429961e-16\n[221,]    0    0    0    0    0     0 6.224691e-31 1.750400e-21 6.600972e-16\n[222,]    0    0    0    0    0     0 4.357284e-31 1.225280e-21 4.620681e-16\n[223,]    0    0    0    0    0     0 3.050099e-31 8.576961e-22 3.234477e-16\n[224,]    0    0    0    0    0     0 2.135069e-31 6.003873e-22 2.264134e-16\n[225,]    0    0    0    0    0     0 1.494548e-31 4.202711e-22 1.584893e-16\n              TC124        TC125\n  [1,] 0.000000e+00 0.000000e+00\n  [2,] 0.000000e+00 0.000000e+00\n  [3,] 0.000000e+00 0.000000e+00\n  [4,] 0.000000e+00 0.000000e+00\n  [5,] 0.000000e+00 0.000000e+00\n  [6,] 0.000000e+00 0.000000e+00\n  [7,] 0.000000e+00 0.000000e+00\n  [8,] 0.000000e+00 0.000000e+00\n  [9,] 0.000000e+00 0.000000e+00\n [10,] 0.000000e+00 0.000000e+00\n [11,] 0.000000e+00 0.000000e+00\n [12,] 0.000000e+00 0.000000e+00\n [13,] 0.000000e+00 0.000000e+00\n [14,] 0.000000e+00 0.000000e+00\n [15,] 0.000000e+00 0.000000e+00\n [16,] 0.000000e+00 0.000000e+00\n [17,] 0.000000e+00 0.000000e+00\n [18,] 0.000000e+00 0.000000e+00\n [19,] 0.000000e+00 0.000000e+00\n [20,] 0.000000e+00 0.000000e+00\n [21,] 0.000000e+00 0.000000e+00\n [22,] 0.000000e+00 0.000000e+00\n [23,] 0.000000e+00 0.000000e+00\n [24,] 0.000000e+00 0.000000e+00\n [25,] 0.000000e+00 0.000000e+00\n [26,] 0.000000e+00 0.000000e+00\n [27,] 0.000000e+00 0.000000e+00\n [28,] 0.000000e+00 0.000000e+00\n [29,] 0.000000e+00 0.000000e+00\n [30,] 0.000000e+00 0.000000e+00\n [31,] 0.000000e+00 0.000000e+00\n [32,] 0.000000e+00 0.000000e+00\n [33,] 0.000000e+00 0.000000e+00\n [34,] 0.000000e+00 0.000000e+00\n [35,] 0.000000e+00 0.000000e+00\n [36,] 0.000000e+00 0.000000e+00\n [37,] 0.000000e+00 0.000000e+00\n [38,] 0.000000e+00 0.000000e+00\n [39,] 0.000000e+00 0.000000e+00\n [40,] 0.000000e+00 0.000000e+00\n [41,] 0.000000e+00 0.000000e+00\n [42,] 0.000000e+00 0.000000e+00\n [43,] 0.000000e+00 0.000000e+00\n [44,] 0.000000e+00 0.000000e+00\n [45,] 0.000000e+00 0.000000e+00\n [46,] 0.000000e+00 0.000000e+00\n [47,] 0.000000e+00 0.000000e+00\n [48,] 0.000000e+00 0.000000e+00\n [49,] 0.000000e+00 0.000000e+00\n [50,] 0.000000e+00 0.000000e+00\n [51,] 0.000000e+00 0.000000e+00\n [52,] 0.000000e+00 0.000000e+00\n [53,] 0.000000e+00 0.000000e+00\n [54,] 0.000000e+00 0.000000e+00\n [55,] 0.000000e+00 0.000000e+00\n [56,] 0.000000e+00 0.000000e+00\n [57,] 0.000000e+00 0.000000e+00\n [58,] 0.000000e+00 0.000000e+00\n [59,] 0.000000e+00 0.000000e+00\n [60,] 0.000000e+00 0.000000e+00\n [61,] 0.000000e+00 0.000000e+00\n [62,] 0.000000e+00 0.000000e+00\n [63,] 0.000000e+00 0.000000e+00\n [64,] 0.000000e+00 0.000000e+00\n [65,] 0.000000e+00 0.000000e+00\n [66,] 0.000000e+00 0.000000e+00\n [67,] 0.000000e+00 0.000000e+00\n [68,] 0.000000e+00 0.000000e+00\n [69,] 0.000000e+00 0.000000e+00\n [70,] 0.000000e+00 0.000000e+00\n [71,] 0.000000e+00 0.000000e+00\n [72,] 0.000000e+00 0.000000e+00\n [73,] 0.000000e+00 0.000000e+00\n [74,] 0.000000e+00 0.000000e+00\n [75,] 0.000000e+00 0.000000e+00\n [76,] 0.000000e+00 0.000000e+00\n [77,] 0.000000e+00 0.000000e+00\n [78,] 0.000000e+00 0.000000e+00\n [79,] 0.000000e+00 0.000000e+00\n [80,] 0.000000e+00 0.000000e+00\n [81,] 0.000000e+00 0.000000e+00\n [82,] 0.000000e+00 0.000000e+00\n [83,] 0.000000e+00 0.000000e+00\n [84,] 0.000000e+00 0.000000e+00\n [85,] 0.000000e+00 0.000000e+00\n [86,] 0.000000e+00 0.000000e+00\n [87,] 0.000000e+00 0.000000e+00\n [88,] 0.000000e+00 0.000000e+00\n [89,] 0.000000e+00 0.000000e+00\n [90,] 0.000000e+00 0.000000e+00\n [91,] 0.000000e+00 0.000000e+00\n [92,] 0.000000e+00 0.000000e+00\n [93,] 0.000000e+00 0.000000e+00\n [94,] 0.000000e+00 0.000000e+00\n [95,] 0.000000e+00 0.000000e+00\n [96,] 0.000000e+00 0.000000e+00\n [97,] 0.000000e+00 0.000000e+00\n [98,] 0.000000e+00 0.000000e+00\n [99,] 0.000000e+00 0.000000e+00\n[100,] 0.000000e+00 0.000000e+00\n[101,] 0.000000e+00 0.000000e+00\n[102,] 0.000000e+00 0.000000e+00\n[103,] 0.000000e+00 0.000000e+00\n[104,] 0.000000e+00 0.000000e+00\n[105,] 0.000000e+00 0.000000e+00\n[106,] 0.000000e+00 0.000000e+00\n[107,] 0.000000e+00 0.000000e+00\n[108,] 0.000000e+00 0.000000e+00\n[109,] 0.000000e+00 0.000000e+00\n[110,] 0.000000e+00 0.000000e+00\n[111,] 0.000000e+00 0.000000e+00\n[112,] 0.000000e+00 0.000000e+00\n[113,] 0.000000e+00 0.000000e+00\n[114,] 0.000000e+00 0.000000e+00\n[115,] 0.000000e+00 0.000000e+00\n[116,] 0.000000e+00 0.000000e+00\n[117,] 0.000000e+00 0.000000e+00\n[118,] 0.000000e+00 0.000000e+00\n[119,] 0.000000e+00 0.000000e+00\n[120,] 0.000000e+00 0.000000e+00\n[121,] 0.000000e+00 0.000000e+00\n[122,] 0.000000e+00 0.000000e+00\n[123,] 0.000000e+00 0.000000e+00\n[124,] 1.000000e+00 0.000000e+00\n[125,] 7.000000e-01 1.000000e+00\n[126,] 4.900000e-01 7.000000e-01\n[127,] 3.430000e-01 4.900000e-01\n[128,] 2.401000e-01 3.430000e-01\n[129,] 1.680700e-01 2.401000e-01\n[130,] 1.176490e-01 1.680700e-01\n[131,] 8.235430e-02 1.176490e-01\n[132,] 5.764801e-02 8.235430e-02\n[133,] 4.035361e-02 5.764801e-02\n[134,] 2.824752e-02 4.035361e-02\n[135,] 1.977327e-02 2.824752e-02\n[136,] 1.384129e-02 1.977327e-02\n[137,] 9.688901e-03 1.384129e-02\n[138,] 6.782231e-03 9.688901e-03\n[139,] 4.747562e-03 6.782231e-03\n[140,] 3.323293e-03 4.747562e-03\n[141,] 2.326305e-03 3.323293e-03\n[142,] 1.628414e-03 2.326305e-03\n[143,] 1.139890e-03 1.628414e-03\n[144,] 7.979227e-04 1.139890e-03\n[145,] 5.585459e-04 7.979227e-04\n[146,] 3.909821e-04 5.585459e-04\n[147,] 2.736875e-04 3.909821e-04\n[148,] 1.915812e-04 2.736875e-04\n[149,] 1.341069e-04 1.915812e-04\n[150,] 9.387480e-05 1.341069e-04\n[151,] 6.571236e-05 9.387480e-05\n[152,] 4.599865e-05 6.571236e-05\n[153,] 3.219906e-05 4.599865e-05\n[154,] 2.253934e-05 3.219906e-05\n[155,] 1.577754e-05 2.253934e-05\n[156,] 1.104428e-05 1.577754e-05\n[157,] 7.730994e-06 1.104428e-05\n[158,] 5.411696e-06 7.730994e-06\n[159,] 3.788187e-06 5.411696e-06\n[160,] 2.651731e-06 3.788187e-06\n[161,] 1.856212e-06 2.651731e-06\n[162,] 1.299348e-06 1.856212e-06\n[163,] 9.095437e-07 1.299348e-06\n[164,] 6.366806e-07 9.095437e-07\n[165,] 4.456764e-07 6.366806e-07\n[166,] 3.119735e-07 4.456764e-07\n[167,] 2.183814e-07 3.119735e-07\n[168,] 1.528670e-07 2.183814e-07\n[169,] 1.070069e-07 1.528670e-07\n[170,] 7.490483e-08 1.070069e-07\n[171,] 5.243338e-08 7.490483e-08\n[172,] 3.670337e-08 5.243338e-08\n[173,] 2.569236e-08 3.670337e-08\n[174,] 1.798465e-08 2.569236e-08\n[175,] 1.258926e-08 1.798465e-08\n[176,] 8.812479e-09 1.258926e-08\n[177,] 6.168735e-09 8.812479e-09\n[178,] 4.318115e-09 6.168735e-09\n[179,] 3.022680e-09 4.318115e-09\n[180,] 2.115876e-09 3.022680e-09\n[181,] 1.481113e-09 2.115876e-09\n[182,] 1.036779e-09 1.481113e-09\n[183,] 7.257455e-10 1.036779e-09\n[184,] 5.080219e-10 7.257455e-10\n[185,] 3.556153e-10 5.080219e-10\n[186,] 2.489307e-10 3.556153e-10\n[187,] 1.742515e-10 2.489307e-10\n[188,] 1.219760e-10 1.742515e-10\n[189,] 8.538323e-11 1.219760e-10\n[190,] 5.976826e-11 8.538323e-11\n[191,] 4.183778e-11 5.976826e-11\n[192,] 2.928645e-11 4.183778e-11\n[193,] 2.050051e-11 2.928645e-11\n[194,] 1.435036e-11 2.050051e-11\n[195,] 1.004525e-11 1.435036e-11\n[196,] 7.031676e-12 1.004525e-11\n[197,] 4.922174e-12 7.031676e-12\n[198,] 3.445521e-12 4.922174e-12\n[199,] 2.411865e-12 3.445521e-12\n[200,] 1.688306e-12 2.411865e-12\n[201,] 1.181814e-12 1.688306e-12\n[202,] 8.272697e-13 1.181814e-12\n[203,] 5.790888e-13 8.272697e-13\n[204,] 4.053622e-13 5.790888e-13\n[205,] 2.837535e-13 4.053622e-13\n[206,] 1.986275e-13 2.837535e-13\n[207,] 1.390392e-13 1.986275e-13\n[208,] 9.732745e-14 1.390392e-13\n[209,] 6.812922e-14 9.732745e-14\n[210,] 4.769045e-14 6.812922e-14\n[211,] 3.338332e-14 4.769045e-14\n[212,] 2.336832e-14 3.338332e-14\n[213,] 1.635783e-14 2.336832e-14\n[214,] 1.145048e-14 1.635783e-14\n[215,] 8.015334e-15 1.145048e-14\n[216,] 5.610734e-15 8.015334e-15\n[217,] 3.927514e-15 5.610734e-15\n[218,] 2.749260e-15 3.927514e-15\n[219,] 1.924482e-15 2.749260e-15\n[220,] 1.347137e-15 1.924482e-15\n[221,] 9.429961e-16 1.347137e-15\n[222,] 6.600972e-16 9.429961e-16\n[223,] 4.620681e-16 6.600972e-16\n[224,] 3.234477e-16 4.620681e-16\n[225,] 2.264134e-16 3.234477e-16\nNotese que se obtuvieron 26 outliers, lo cual nos puede indicar que el modelo ajustado no es muy bueno para este modelo, por dicha raz√≥n no seria lo mejor ajustar outliers a este modelo.\nmodelo_SARIMA_ref_outliers = Arima(df_train4, c(5, 1, 1),seasonal = list(order = c(3, 1, 2), period = 12),lambda = 0,fixed=c(0,NA,0,0,0,NA,NA,NA,0,0,0,NA,NA,0,NA,NA,NA,NA,0,0,NA,0),xreg =xregSARIMA )\ncoeftest(modelo_SARIMA_ref_outliers)\n\n\nz test of coefficients:\n\n        Estimate Std. Error  z value  Pr(&gt;|z|)    \nar2    0.2341858  0.0728046   3.2166 0.0012970 ** \nma1   -0.9298058  0.0266686 -34.8652 &lt; 2.2e-16 ***\nsar1  -0.2095066  0.0700866  -2.9893 0.0027966 ** \nsar2  -0.2817612  0.0737322  -3.8214 0.0001327 ***\nAO50  -0.0130544  0.0049514  -2.6365 0.0083764 ** \nAO52   0.0106068  0.0050200   2.1129 0.0346092 *  \nAO88  -0.0479514  0.0050262  -9.5403 &lt; 2.2e-16 ***\nAO89   0.0300805  0.0048134   6.2493 4.124e-10 ***\nAO126 -0.0146734  0.0050002  -2.9346 0.0033400 ** \nTC26  -0.0145443  0.0041481  -3.5062 0.0004545 ***\nTC124 -0.0203414  0.0041051  -4.9551 7.228e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## Revisando que no hay m√°s outliers\nresiO2= residuals(modelo_SARIMA_ref_outliers)\ncoefO2= coefs2poly(modelo_SARIMA_ref_outliers)\noutliersSARIMA2= locate.outliers(resiO2,coefO2,cval=4.5)\noutliersSARIMA2\n\n  type ind     coefhat     tstat\n2   TC  33  0.01302646  5.000072\n3   TC 152 -0.01184981 -4.548306\n\nn=length(df_train4)\nxregSARIMA2 = outliers.effects(outliersSARIMA2,n )\nxregSARIMA2\n\n               TC33        TC152\n  [1,] 0.000000e+00 0.000000e+00\n  [2,] 0.000000e+00 0.000000e+00\n  [3,] 0.000000e+00 0.000000e+00\n  [4,] 0.000000e+00 0.000000e+00\n  [5,] 0.000000e+00 0.000000e+00\n  [6,] 0.000000e+00 0.000000e+00\n  [7,] 0.000000e+00 0.000000e+00\n  [8,] 0.000000e+00 0.000000e+00\n  [9,] 0.000000e+00 0.000000e+00\n [10,] 0.000000e+00 0.000000e+00\n [11,] 0.000000e+00 0.000000e+00\n [12,] 0.000000e+00 0.000000e+00\n [13,] 0.000000e+00 0.000000e+00\n [14,] 0.000000e+00 0.000000e+00\n [15,] 0.000000e+00 0.000000e+00\n [16,] 0.000000e+00 0.000000e+00\n [17,] 0.000000e+00 0.000000e+00\n [18,] 0.000000e+00 0.000000e+00\n [19,] 0.000000e+00 0.000000e+00\n [20,] 0.000000e+00 0.000000e+00\n [21,] 0.000000e+00 0.000000e+00\n [22,] 0.000000e+00 0.000000e+00\n [23,] 0.000000e+00 0.000000e+00\n [24,] 0.000000e+00 0.000000e+00\n [25,] 0.000000e+00 0.000000e+00\n [26,] 0.000000e+00 0.000000e+00\n [27,] 0.000000e+00 0.000000e+00\n [28,] 0.000000e+00 0.000000e+00\n [29,] 0.000000e+00 0.000000e+00\n [30,] 0.000000e+00 0.000000e+00\n [31,] 0.000000e+00 0.000000e+00\n [32,] 0.000000e+00 0.000000e+00\n [33,] 1.000000e+00 0.000000e+00\n [34,] 7.000000e-01 0.000000e+00\n [35,] 4.900000e-01 0.000000e+00\n [36,] 3.430000e-01 0.000000e+00\n [37,] 2.401000e-01 0.000000e+00\n [38,] 1.680700e-01 0.000000e+00\n [39,] 1.176490e-01 0.000000e+00\n [40,] 8.235430e-02 0.000000e+00\n [41,] 5.764801e-02 0.000000e+00\n [42,] 4.035361e-02 0.000000e+00\n [43,] 2.824752e-02 0.000000e+00\n [44,] 1.977327e-02 0.000000e+00\n [45,] 1.384129e-02 0.000000e+00\n [46,] 9.688901e-03 0.000000e+00\n [47,] 6.782231e-03 0.000000e+00\n [48,] 4.747562e-03 0.000000e+00\n [49,] 3.323293e-03 0.000000e+00\n [50,] 2.326305e-03 0.000000e+00\n [51,] 1.628414e-03 0.000000e+00\n [52,] 1.139890e-03 0.000000e+00\n [53,] 7.979227e-04 0.000000e+00\n [54,] 5.585459e-04 0.000000e+00\n [55,] 3.909821e-04 0.000000e+00\n [56,] 2.736875e-04 0.000000e+00\n [57,] 1.915812e-04 0.000000e+00\n [58,] 1.341069e-04 0.000000e+00\n [59,] 9.387480e-05 0.000000e+00\n [60,] 6.571236e-05 0.000000e+00\n [61,] 4.599865e-05 0.000000e+00\n [62,] 3.219906e-05 0.000000e+00\n [63,] 2.253934e-05 0.000000e+00\n [64,] 1.577754e-05 0.000000e+00\n [65,] 1.104428e-05 0.000000e+00\n [66,] 7.730994e-06 0.000000e+00\n [67,] 5.411696e-06 0.000000e+00\n [68,] 3.788187e-06 0.000000e+00\n [69,] 2.651731e-06 0.000000e+00\n [70,] 1.856212e-06 0.000000e+00\n [71,] 1.299348e-06 0.000000e+00\n [72,] 9.095437e-07 0.000000e+00\n [73,] 6.366806e-07 0.000000e+00\n [74,] 4.456764e-07 0.000000e+00\n [75,] 3.119735e-07 0.000000e+00\n [76,] 2.183814e-07 0.000000e+00\n [77,] 1.528670e-07 0.000000e+00\n [78,] 1.070069e-07 0.000000e+00\n [79,] 7.490483e-08 0.000000e+00\n [80,] 5.243338e-08 0.000000e+00\n [81,] 3.670337e-08 0.000000e+00\n [82,] 2.569236e-08 0.000000e+00\n [83,] 1.798465e-08 0.000000e+00\n [84,] 1.258926e-08 0.000000e+00\n [85,] 8.812479e-09 0.000000e+00\n [86,] 6.168735e-09 0.000000e+00\n [87,] 4.318115e-09 0.000000e+00\n [88,] 3.022680e-09 0.000000e+00\n [89,] 2.115876e-09 0.000000e+00\n [90,] 1.481113e-09 0.000000e+00\n [91,] 1.036779e-09 0.000000e+00\n [92,] 7.257455e-10 0.000000e+00\n [93,] 5.080219e-10 0.000000e+00\n [94,] 3.556153e-10 0.000000e+00\n [95,] 2.489307e-10 0.000000e+00\n [96,] 1.742515e-10 0.000000e+00\n [97,] 1.219760e-10 0.000000e+00\n [98,] 8.538323e-11 0.000000e+00\n [99,] 5.976826e-11 0.000000e+00\n[100,] 4.183778e-11 0.000000e+00\n[101,] 2.928645e-11 0.000000e+00\n[102,] 2.050051e-11 0.000000e+00\n[103,] 1.435036e-11 0.000000e+00\n[104,] 1.004525e-11 0.000000e+00\n[105,] 7.031676e-12 0.000000e+00\n[106,] 4.922174e-12 0.000000e+00\n[107,] 3.445521e-12 0.000000e+00\n[108,] 2.411865e-12 0.000000e+00\n[109,] 1.688306e-12 0.000000e+00\n[110,] 1.181814e-12 0.000000e+00\n[111,] 8.272697e-13 0.000000e+00\n[112,] 5.790888e-13 0.000000e+00\n[113,] 4.053622e-13 0.000000e+00\n[114,] 2.837535e-13 0.000000e+00\n[115,] 1.986275e-13 0.000000e+00\n[116,] 1.390392e-13 0.000000e+00\n[117,] 9.732745e-14 0.000000e+00\n[118,] 6.812922e-14 0.000000e+00\n[119,] 4.769045e-14 0.000000e+00\n[120,] 3.338332e-14 0.000000e+00\n[121,] 2.336832e-14 0.000000e+00\n[122,] 1.635783e-14 0.000000e+00\n[123,] 1.145048e-14 0.000000e+00\n[124,] 8.015334e-15 0.000000e+00\n[125,] 5.610734e-15 0.000000e+00\n[126,] 3.927514e-15 0.000000e+00\n[127,] 2.749260e-15 0.000000e+00\n[128,] 1.924482e-15 0.000000e+00\n[129,] 1.347137e-15 0.000000e+00\n[130,] 9.429961e-16 0.000000e+00\n[131,] 6.600972e-16 0.000000e+00\n[132,] 4.620681e-16 0.000000e+00\n[133,] 3.234477e-16 0.000000e+00\n[134,] 2.264134e-16 0.000000e+00\n[135,] 1.584893e-16 0.000000e+00\n[136,] 1.109425e-16 0.000000e+00\n[137,] 7.765978e-17 0.000000e+00\n[138,] 5.436185e-17 0.000000e+00\n[139,] 3.805329e-17 0.000000e+00\n[140,] 2.663730e-17 0.000000e+00\n[141,] 1.864611e-17 0.000000e+00\n[142,] 1.305228e-17 0.000000e+00\n[143,] 9.136596e-18 0.000000e+00\n[144,] 6.395617e-18 0.000000e+00\n[145,] 4.476932e-18 0.000000e+00\n[146,] 3.133852e-18 0.000000e+00\n[147,] 2.193697e-18 0.000000e+00\n[148,] 1.535588e-18 0.000000e+00\n[149,] 1.074911e-18 0.000000e+00\n[150,] 7.524379e-19 0.000000e+00\n[151,] 5.267066e-19 0.000000e+00\n[152,] 3.686946e-19 1.000000e+00\n[153,] 2.580862e-19 7.000000e-01\n[154,] 1.806603e-19 4.900000e-01\n[155,] 1.264622e-19 3.430000e-01\n[156,] 8.852357e-20 2.401000e-01\n[157,] 6.196650e-20 1.680700e-01\n[158,] 4.337655e-20 1.176490e-01\n[159,] 3.036358e-20 8.235430e-02\n[160,] 2.125451e-20 5.764801e-02\n[161,] 1.487816e-20 4.035361e-02\n[162,] 1.041471e-20 2.824752e-02\n[163,] 7.290297e-21 1.977327e-02\n[164,] 5.103208e-21 1.384129e-02\n[165,] 3.572245e-21 9.688901e-03\n[166,] 2.500572e-21 6.782231e-03\n[167,] 1.750400e-21 4.747562e-03\n[168,] 1.225280e-21 3.323293e-03\n[169,] 8.576961e-22 2.326305e-03\n[170,] 6.003873e-22 1.628414e-03\n[171,] 4.202711e-22 1.139890e-03\n[172,] 2.941898e-22 7.979227e-04\n[173,] 2.059328e-22 5.585459e-04\n[174,] 1.441530e-22 3.909821e-04\n[175,] 1.009071e-22 2.736875e-04\n[176,] 7.063496e-23 1.915812e-04\n[177,] 4.944447e-23 1.341069e-04\n[178,] 3.461113e-23 9.387480e-05\n[179,] 2.422779e-23 6.571236e-05\n[180,] 1.695945e-23 4.599865e-05\n[181,] 1.187162e-23 3.219906e-05\n[182,] 8.310133e-24 2.253934e-05\n[183,] 5.817093e-24 1.577754e-05\n[184,] 4.071965e-24 1.104428e-05\n[185,] 2.850376e-24 7.730994e-06\n[186,] 1.995263e-24 5.411696e-06\n[187,] 1.396684e-24 3.788187e-06\n[188,] 9.776788e-25 2.651731e-06\n[189,] 6.843752e-25 1.856212e-06\n[190,] 4.790626e-25 1.299348e-06\n[191,] 3.353438e-25 9.095437e-07\n[192,] 2.347407e-25 6.366806e-07\n[193,] 1.643185e-25 4.456764e-07\n[194,] 1.150229e-25 3.119735e-07\n[195,] 8.051605e-26 2.183814e-07\n[196,] 5.636124e-26 1.528670e-07\n[197,] 3.945287e-26 1.070069e-07\n[198,] 2.761701e-26 7.490483e-08\n[199,] 1.933190e-26 5.243338e-08\n[200,] 1.353233e-26 3.670337e-08\n[201,] 9.472633e-27 2.569236e-08\n[202,] 6.630843e-27 1.798465e-08\n[203,] 4.641590e-27 1.258926e-08\n[204,] 3.249113e-27 8.812479e-09\n[205,] 2.274379e-27 6.168735e-09\n[206,] 1.592065e-27 4.318115e-09\n[207,] 1.114446e-27 3.022680e-09\n[208,] 7.801121e-28 2.115876e-09\n[209,] 5.460785e-28 1.481113e-09\n[210,] 3.822549e-28 1.036779e-09\n[211,] 2.675784e-28 7.257455e-10\n[212,] 1.873049e-28 5.080219e-10\n[213,] 1.311134e-28 3.556153e-10\n[214,] 9.177941e-29 2.489307e-10\n[215,] 6.424558e-29 1.742515e-10\n[216,] 4.497191e-29 1.219760e-10\n[217,] 3.148034e-29 8.538323e-11\n[218,] 2.203624e-29 5.976826e-11\n[219,] 1.542536e-29 4.183778e-11\n[220,] 1.079776e-29 2.928645e-11\n[221,] 7.558429e-30 2.050051e-11\n[222,] 5.290900e-30 1.435036e-11\n[223,] 3.703630e-30 1.004525e-11\n[224,] 2.592541e-30 7.031676e-12\n[225,] 1.814779e-30 4.922174e-12\n\n##No hay m√°s outliers\ntotal_outliers2&lt;-cbind(xregSARIMA,xregSARIMA2)\nmodelo_SARIMA_ref_outliers2 = Arima(df_train4, c(5, 1, 1),seasonal = list(order = c(3, 1, 2), period = 12),lambda = 0,fixed=c(0,NA,0,0,0,NA,NA,NA,0,0,0,NA,0,0,NA,0,0,0,0,0,NA,0,NA,NA),xreg =total_outliers2 )\ncoeftest(modelo_SARIMA_ref_outliers2)\n\n\nz test of coefficients:\n\n        Estimate Std. Error  z value  Pr(&gt;|z|)    \nar2    0.2067029  0.0760131   2.7193  0.006542 ** \nma1   -0.9200445  0.0315473 -29.1640 &lt; 2.2e-16 ***\nsar1  -0.3471718  0.0684348  -5.0730 3.915e-07 ***\nsar2  -0.3588121  0.0653484  -5.4908 4.002e-08 ***\nAO50  -0.0168670  0.0055266  -3.0520  0.002273 ** \nAO88  -0.0524776  0.0056220  -9.3343 &lt; 2.2e-16 ***\nTC124 -0.0251921  0.0046302  -5.4408 5.304e-08 ***\nTC33   0.0142141  0.0046955   3.0272  0.002468 ** \nTC152 -0.0131171  0.0046450  -2.8239  0.004744 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nresiO= residuals(ARPURO_ref_prueba)\ncoefO= coefs2poly(ARPURO_ref_prueba)\noutliersSARIMA= locate.outliers(resiO,coefO,cval=4.5)\noutliersSARIMA\n\n  type ind    coefhat     tstat\n1   AO  88 -0.6796103 -8.871384\n3   AO 150  0.3644965  4.758003\n4   TC 124 -0.2226187 -4.580497\n5   TC 147  0.2434923  5.009983\n6   TC 148  0.2795131  5.751130\n\nn=length(df_train4)\nxregAR = outliers.effects(outliersSARIMA,n )\nxregAR\n\n       AO88 AO150        TC124        TC147        TC148\n  [1,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n  [2,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n  [3,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n  [4,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n  [5,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n  [6,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n  [7,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n  [8,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n  [9,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [10,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [11,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [12,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [13,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [14,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [15,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [16,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [17,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [18,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [19,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [20,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [21,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [22,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [23,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [24,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [25,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [26,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [27,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [28,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [29,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [30,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [31,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [32,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [33,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [34,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [35,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [36,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [37,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [38,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [39,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [40,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [41,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [42,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [43,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [44,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [45,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [46,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [47,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [48,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [49,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [50,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [51,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [52,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [53,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [54,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [55,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [56,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [57,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [58,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [59,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [60,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [61,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [62,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [63,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [64,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [65,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [66,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [67,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [68,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [69,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [70,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [71,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [72,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [73,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [74,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [75,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [76,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [77,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [78,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [79,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [80,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [81,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [82,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [83,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [84,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [85,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [86,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [87,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [88,]    1     0 0.000000e+00 0.000000e+00 0.000000e+00\n [89,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [90,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [91,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [92,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [93,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [94,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [95,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [96,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [97,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [98,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n [99,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n[100,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n[101,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n[102,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n[103,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n[104,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n[105,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n[106,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n[107,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n[108,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n[109,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n[110,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n[111,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n[112,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n[113,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n[114,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n[115,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n[116,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n[117,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n[118,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n[119,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n[120,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n[121,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n[122,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n[123,]    0     0 0.000000e+00 0.000000e+00 0.000000e+00\n[124,]    0     0 1.000000e+00 0.000000e+00 0.000000e+00\n[125,]    0     0 7.000000e-01 0.000000e+00 0.000000e+00\n[126,]    0     0 4.900000e-01 0.000000e+00 0.000000e+00\n[127,]    0     0 3.430000e-01 0.000000e+00 0.000000e+00\n[128,]    0     0 2.401000e-01 0.000000e+00 0.000000e+00\n[129,]    0     0 1.680700e-01 0.000000e+00 0.000000e+00\n[130,]    0     0 1.176490e-01 0.000000e+00 0.000000e+00\n[131,]    0     0 8.235430e-02 0.000000e+00 0.000000e+00\n[132,]    0     0 5.764801e-02 0.000000e+00 0.000000e+00\n[133,]    0     0 4.035361e-02 0.000000e+00 0.000000e+00\n[134,]    0     0 2.824752e-02 0.000000e+00 0.000000e+00\n[135,]    0     0 1.977327e-02 0.000000e+00 0.000000e+00\n[136,]    0     0 1.384129e-02 0.000000e+00 0.000000e+00\n[137,]    0     0 9.688901e-03 0.000000e+00 0.000000e+00\n[138,]    0     0 6.782231e-03 0.000000e+00 0.000000e+00\n[139,]    0     0 4.747562e-03 0.000000e+00 0.000000e+00\n[140,]    0     0 3.323293e-03 0.000000e+00 0.000000e+00\n[141,]    0     0 2.326305e-03 0.000000e+00 0.000000e+00\n[142,]    0     0 1.628414e-03 0.000000e+00 0.000000e+00\n[143,]    0     0 1.139890e-03 0.000000e+00 0.000000e+00\n[144,]    0     0 7.979227e-04 0.000000e+00 0.000000e+00\n[145,]    0     0 5.585459e-04 0.000000e+00 0.000000e+00\n[146,]    0     0 3.909821e-04 0.000000e+00 0.000000e+00\n[147,]    0     0 2.736875e-04 1.000000e+00 0.000000e+00\n[148,]    0     0 1.915812e-04 7.000000e-01 1.000000e+00\n[149,]    0     0 1.341069e-04 4.900000e-01 7.000000e-01\n[150,]    0     1 9.387480e-05 3.430000e-01 4.900000e-01\n[151,]    0     0 6.571236e-05 2.401000e-01 3.430000e-01\n[152,]    0     0 4.599865e-05 1.680700e-01 2.401000e-01\n[153,]    0     0 3.219906e-05 1.176490e-01 1.680700e-01\n[154,]    0     0 2.253934e-05 8.235430e-02 1.176490e-01\n[155,]    0     0 1.577754e-05 5.764801e-02 8.235430e-02\n[156,]    0     0 1.104428e-05 4.035361e-02 5.764801e-02\n[157,]    0     0 7.730994e-06 2.824752e-02 4.035361e-02\n[158,]    0     0 5.411696e-06 1.977327e-02 2.824752e-02\n[159,]    0     0 3.788187e-06 1.384129e-02 1.977327e-02\n[160,]    0     0 2.651731e-06 9.688901e-03 1.384129e-02\n[161,]    0     0 1.856212e-06 6.782231e-03 9.688901e-03\n[162,]    0     0 1.299348e-06 4.747562e-03 6.782231e-03\n[163,]    0     0 9.095437e-07 3.323293e-03 4.747562e-03\n[164,]    0     0 6.366806e-07 2.326305e-03 3.323293e-03\n[165,]    0     0 4.456764e-07 1.628414e-03 2.326305e-03\n[166,]    0     0 3.119735e-07 1.139890e-03 1.628414e-03\n[167,]    0     0 2.183814e-07 7.979227e-04 1.139890e-03\n[168,]    0     0 1.528670e-07 5.585459e-04 7.979227e-04\n[169,]    0     0 1.070069e-07 3.909821e-04 5.585459e-04\n[170,]    0     0 7.490483e-08 2.736875e-04 3.909821e-04\n[171,]    0     0 5.243338e-08 1.915812e-04 2.736875e-04\n[172,]    0     0 3.670337e-08 1.341069e-04 1.915812e-04\n[173,]    0     0 2.569236e-08 9.387480e-05 1.341069e-04\n[174,]    0     0 1.798465e-08 6.571236e-05 9.387480e-05\n[175,]    0     0 1.258926e-08 4.599865e-05 6.571236e-05\n[176,]    0     0 8.812479e-09 3.219906e-05 4.599865e-05\n[177,]    0     0 6.168735e-09 2.253934e-05 3.219906e-05\n[178,]    0     0 4.318115e-09 1.577754e-05 2.253934e-05\n[179,]    0     0 3.022680e-09 1.104428e-05 1.577754e-05\n[180,]    0     0 2.115876e-09 7.730994e-06 1.104428e-05\n[181,]    0     0 1.481113e-09 5.411696e-06 7.730994e-06\n[182,]    0     0 1.036779e-09 3.788187e-06 5.411696e-06\n[183,]    0     0 7.257455e-10 2.651731e-06 3.788187e-06\n[184,]    0     0 5.080219e-10 1.856212e-06 2.651731e-06\n[185,]    0     0 3.556153e-10 1.299348e-06 1.856212e-06\n[186,]    0     0 2.489307e-10 9.095437e-07 1.299348e-06\n[187,]    0     0 1.742515e-10 6.366806e-07 9.095437e-07\n[188,]    0     0 1.219760e-10 4.456764e-07 6.366806e-07\n[189,]    0     0 8.538323e-11 3.119735e-07 4.456764e-07\n[190,]    0     0 5.976826e-11 2.183814e-07 3.119735e-07\n[191,]    0     0 4.183778e-11 1.528670e-07 2.183814e-07\n[192,]    0     0 2.928645e-11 1.070069e-07 1.528670e-07\n[193,]    0     0 2.050051e-11 7.490483e-08 1.070069e-07\n[194,]    0     0 1.435036e-11 5.243338e-08 7.490483e-08\n[195,]    0     0 1.004525e-11 3.670337e-08 5.243338e-08\n[196,]    0     0 7.031676e-12 2.569236e-08 3.670337e-08\n[197,]    0     0 4.922174e-12 1.798465e-08 2.569236e-08\n[198,]    0     0 3.445521e-12 1.258926e-08 1.798465e-08\n[199,]    0     0 2.411865e-12 8.812479e-09 1.258926e-08\n[200,]    0     0 1.688306e-12 6.168735e-09 8.812479e-09\n[201,]    0     0 1.181814e-12 4.318115e-09 6.168735e-09\n[202,]    0     0 8.272697e-13 3.022680e-09 4.318115e-09\n[203,]    0     0 5.790888e-13 2.115876e-09 3.022680e-09\n[204,]    0     0 4.053622e-13 1.481113e-09 2.115876e-09\n[205,]    0     0 2.837535e-13 1.036779e-09 1.481113e-09\n[206,]    0     0 1.986275e-13 7.257455e-10 1.036779e-09\n[207,]    0     0 1.390392e-13 5.080219e-10 7.257455e-10\n[208,]    0     0 9.732745e-14 3.556153e-10 5.080219e-10\n[209,]    0     0 6.812922e-14 2.489307e-10 3.556153e-10\n[210,]    0     0 4.769045e-14 1.742515e-10 2.489307e-10\n[211,]    0     0 3.338332e-14 1.219760e-10 1.742515e-10\n[212,]    0     0 2.336832e-14 8.538323e-11 1.219760e-10\n[213,]    0     0 1.635783e-14 5.976826e-11 8.538323e-11\n[214,]    0     0 1.145048e-14 4.183778e-11 5.976826e-11\n[215,]    0     0 8.015334e-15 2.928645e-11 4.183778e-11\n[216,]    0     0 5.610734e-15 2.050051e-11 2.928645e-11\n[217,]    0     0 3.927514e-15 1.435036e-11 2.050051e-11\n[218,]    0     0 2.749260e-15 1.004525e-11 1.435036e-11\n[219,]    0     0 1.924482e-15 7.031676e-12 1.004525e-11\n[220,]    0     0 1.347137e-15 4.922174e-12 7.031676e-12\n[221,]    0     0 9.429961e-16 3.445521e-12 4.922174e-12\n[222,]    0     0 6.600972e-16 2.411865e-12 3.445521e-12\n[223,]    0     0 4.620681e-16 1.688306e-12 2.411865e-12\n[224,]    0     0 3.234477e-16 1.181814e-12 1.688306e-12\n[225,]    0     0 2.264134e-16 8.272697e-13 1.181814e-12\nARPURO_ref_prueba_outliers=Arima(ElimiTenddian_STL_dummy,order=c(1,0,0),seasonal = c(1,0,0),include.mean = F,xreg=xregAR,fixed=c(NA,NA,NA,NA,NA,NA,0))\n#coeftest(modelo_AR_ref_outliers)\nresiO= residuals( ARPURO_ref_prueba_outliers)\ncoefO= coefs2poly( ARPURO_ref_prueba_outliers)\noutliersSARIMA= locate.outliers(resiO,coefO,cval=4.5)\noutliersSARIMA\n\n  type ind   coefhat    tstat\n1   AO  89 0.4699829 7.420944\n\nn=length(df_train4)\nxregAR2 = outliers.effects(outliersSARIMA,n )\nxregAR2\n\n       AO89\n  [1,]    0\n  [2,]    0\n  [3,]    0\n  [4,]    0\n  [5,]    0\n  [6,]    0\n  [7,]    0\n  [8,]    0\n  [9,]    0\n [10,]    0\n [11,]    0\n [12,]    0\n [13,]    0\n [14,]    0\n [15,]    0\n [16,]    0\n [17,]    0\n [18,]    0\n [19,]    0\n [20,]    0\n [21,]    0\n [22,]    0\n [23,]    0\n [24,]    0\n [25,]    0\n [26,]    0\n [27,]    0\n [28,]    0\n [29,]    0\n [30,]    0\n [31,]    0\n [32,]    0\n [33,]    0\n [34,]    0\n [35,]    0\n [36,]    0\n [37,]    0\n [38,]    0\n [39,]    0\n [40,]    0\n [41,]    0\n [42,]    0\n [43,]    0\n [44,]    0\n [45,]    0\n [46,]    0\n [47,]    0\n [48,]    0\n [49,]    0\n [50,]    0\n [51,]    0\n [52,]    0\n [53,]    0\n [54,]    0\n [55,]    0\n [56,]    0\n [57,]    0\n [58,]    0\n [59,]    0\n [60,]    0\n [61,]    0\n [62,]    0\n [63,]    0\n [64,]    0\n [65,]    0\n [66,]    0\n [67,]    0\n [68,]    0\n [69,]    0\n [70,]    0\n [71,]    0\n [72,]    0\n [73,]    0\n [74,]    0\n [75,]    0\n [76,]    0\n [77,]    0\n [78,]    0\n [79,]    0\n [80,]    0\n [81,]    0\n [82,]    0\n [83,]    0\n [84,]    0\n [85,]    0\n [86,]    0\n [87,]    0\n [88,]    0\n [89,]    1\n [90,]    0\n [91,]    0\n [92,]    0\n [93,]    0\n [94,]    0\n [95,]    0\n [96,]    0\n [97,]    0\n [98,]    0\n [99,]    0\n[100,]    0\n[101,]    0\n[102,]    0\n[103,]    0\n[104,]    0\n[105,]    0\n[106,]    0\n[107,]    0\n[108,]    0\n[109,]    0\n[110,]    0\n[111,]    0\n[112,]    0\n[113,]    0\n[114,]    0\n[115,]    0\n[116,]    0\n[117,]    0\n[118,]    0\n[119,]    0\n[120,]    0\n[121,]    0\n[122,]    0\n[123,]    0\n[124,]    0\n[125,]    0\n[126,]    0\n[127,]    0\n[128,]    0\n[129,]    0\n[130,]    0\n[131,]    0\n[132,]    0\n[133,]    0\n[134,]    0\n[135,]    0\n[136,]    0\n[137,]    0\n[138,]    0\n[139,]    0\n[140,]    0\n[141,]    0\n[142,]    0\n[143,]    0\n[144,]    0\n[145,]    0\n[146,]    0\n[147,]    0\n[148,]    0\n[149,]    0\n[150,]    0\n[151,]    0\n[152,]    0\n[153,]    0\n[154,]    0\n[155,]    0\n[156,]    0\n[157,]    0\n[158,]    0\n[159,]    0\n[160,]    0\n[161,]    0\n[162,]    0\n[163,]    0\n[164,]    0\n[165,]    0\n[166,]    0\n[167,]    0\n[168,]    0\n[169,]    0\n[170,]    0\n[171,]    0\n[172,]    0\n[173,]    0\n[174,]    0\n[175,]    0\n[176,]    0\n[177,]    0\n[178,]    0\n[179,]    0\n[180,]    0\n[181,]    0\n[182,]    0\n[183,]    0\n[184,]    0\n[185,]    0\n[186,]    0\n[187,]    0\n[188,]    0\n[189,]    0\n[190,]    0\n[191,]    0\n[192,]    0\n[193,]    0\n[194,]    0\n[195,]    0\n[196,]    0\n[197,]    0\n[198,]    0\n[199,]    0\n[200,]    0\n[201,]    0\n[202,]    0\n[203,]    0\n[204,]    0\n[205,]    0\n[206,]    0\n[207,]    0\n[208,]    0\n[209,]    0\n[210,]    0\n[211,]    0\n[212,]    0\n[213,]    0\n[214,]    0\n[215,]    0\n[216,]    0\n[217,]    0\n[218,]    0\n[219,]    0\n[220,]    0\n[221,]    0\n[222,]    0\n[223,]    0\n[224,]    0\n[225,]    0\ntotal_outliers=cbind(xregAR,xregAR2)\n ARPURO_ref_prueba_outliers2=Arima(ElimiTenddian_STL_dummy,order=c(1,0,0),seasonal = c(1,0,0),include.mean = F,xreg=total_outliers,fixed=c(NA,NA,NA,NA,NA,NA,0,NA))\ncoeftest( ARPURO_ref_prueba_outliers2)\n\n\nz test of coefficients:\n\n       Estimate Std. Error z value  Pr(&gt;|z|)    \nar1   -0.160468   0.066645 -2.4078 0.0160491 *  \nsar1   0.628647   0.051024 12.3206 &lt; 2.2e-16 ***\nAO88  -0.778931   0.078773 -9.8883 &lt; 2.2e-16 ***\nAO150  0.252164   0.082155  3.0694 0.0021452 ** \nTC124 -0.236201   0.050844 -4.6456 3.391e-06 ***\nTC147  0.178754   0.053271  3.3556 0.0007921 ***\nAO89   0.494072   0.079127  6.2441 4.263e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "Descriptivo Dian (2).html#eliminaci√≥n-de-la-estacionalidad-utilizando-variables-dummy",
    "href": "Descriptivo Dian (2).html#eliminaci√≥n-de-la-estacionalidad-utilizando-variables-dummy",
    "title": "1¬† An√°lisis descriptivo del recaudo de impuestos internos por la DIAN",
    "section": "1.5 Eliminaci√≥n de la estacionalidad utilizando variables dummy",
    "text": "1.5 Eliminaci√≥n de la estacionalidad utilizando variables dummy\n\n## Prueba de crear las variables dummy \nlibrary(stats)\nlibrary(forecast)\nlibrary(ggplot2)\n\n# Carga tus datos o crea una serie de tiempo similar\n# Puedes cargar tus datos desde un archivo o crearlos manualmente\n# Aqu√≠ se asume que tienes una serie de tiempo en un objeto llamado 'dian_detrend_STL'\n\n# Crea un objeto de variable dummy estacional\ndummy &lt;- seasonaldummy(ElimiTenddian_STL)\n\n# Ajusta un modelo de regresi√≥n lineal\nmodelo &lt;- lm(ElimiTenddian_STL ~ dummy)\n\n# Obtiene un resumen del modelo\nsummary(modelo)\n\n\nCall:\nlm(formula = ElimiTenddian_STL ~ dummy)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.73461 -0.07125 -0.00763  0.07523  0.54817 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -0.43056    0.03010 -14.304  &lt; 2e-16 ***\ndummyJan     0.77121    0.04212  18.308  &lt; 2e-16 ***\ndummyFeb     0.21961    0.04212   5.213 3.69e-07 ***\ndummyMar     0.40270    0.04212   9.560  &lt; 2e-16 ***\ndummyApr     0.68980    0.04212  16.375  &lt; 2e-16 ***\ndummyMay     0.63959    0.04212  15.183  &lt; 2e-16 ***\ndummyJun     0.64048    0.04212  15.205  &lt; 2e-16 ***\ndummyJul     0.47789    0.04257  11.226  &lt; 2e-16 ***\ndummyAug     0.21469    0.04257   5.043 8.40e-07 ***\ndummySep     0.68424    0.04257  16.073  &lt; 2e-16 ***\ndummyOct     0.05631    0.04257   1.323    0.187    \ndummyNov     0.50827    0.04257  11.940  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1444 on 270 degrees of freedom\nMultiple R-squared:  0.7594,    Adjusted R-squared:  0.7496 \nF-statistic: 77.49 on 11 and 270 DF,  p-value: &lt; 2.2e-16\n\n# Realiza predicciones con el modelo\nnuevas_obs &lt;- length(ElimiTenddian_STL)  # N√∫mero de observaciones en la serie de tiempo\npredicciones &lt;- predict(modelo, newdata = data.frame(dummy = dummy))\n\n# Crea un nuevo objeto de serie de tiempo con las predicciones\ndian_pred &lt;- ts(predicciones, start = start(ElimiTenddian_STL), frequency = frequency(ElimiTenddian_STL))\n\n# Grafica los resultados\nplot(ElimiTenddian_STL, col = \"blue\", type = \"l\", xlab = \"Fecha\", ylab = \"Valor Original\")\nlines(dian_pred, col = \"red\")\nlegend(\"topleft\", legend = c(\"Impuestos\", \"Predicciones\"), col = c(\"blue\", \"red\"))\n\n\n\n\n\nplot(ElimiTenddian_STL-dian_pred, col = \"blue\", type = \"l\", xlab = \"Fecha\", ylab = \"Impuestos\",main=\"Series sin tendencia (STL) y sin estacionalidad (dummy)\")\n\n\n\n\n\nacf(as.numeric(ElimiTenddian_STL-dian_pred))"
  },
  {
    "objectID": "Descriptivo Dian (2).html#division-de-los-datos-en-entrenamiento-y-prueba.",
    "href": "Descriptivo Dian (2).html#division-de-los-datos-en-entrenamiento-y-prueba.",
    "title": "1¬† An√°lisis descriptivo del recaudo de impuestos internos por la DIAN",
    "section": "2.1 Division de los datos en entrenamiento y prueba.",
    "text": "2.1 Division de los datos en entrenamiento y prueba.\nEn primer lugar se realizar√° la divisi√≥n de los datos en el conjunto de entrenamiento y de prueba.\n\nlserie=length(ldian2)\nntrain=trunc(length(ldian2)*0.80) ##% del datos en el conjunto de entrenamiento es del 85%.\nntrain\n\n[1] 225\n\ntime(ldian2)\n\n          Jan      Feb      Mar      Apr      May      Jun      Jul      Aug\n2000 2000.000 2000.083 2000.167 2000.250 2000.333 2000.417 2000.500 2000.583\n2001 2001.000 2001.083 2001.167 2001.250 2001.333 2001.417 2001.500 2001.583\n2002 2002.000 2002.083 2002.167 2002.250 2002.333 2002.417 2002.500 2002.583\n2003 2003.000 2003.083 2003.167 2003.250 2003.333 2003.417 2003.500 2003.583\n2004 2004.000 2004.083 2004.167 2004.250 2004.333 2004.417 2004.500 2004.583\n2005 2005.000 2005.083 2005.167 2005.250 2005.333 2005.417 2005.500 2005.583\n2006 2006.000 2006.083 2006.167 2006.250 2006.333 2006.417 2006.500 2006.583\n2007 2007.000 2007.083 2007.167 2007.250 2007.333 2007.417 2007.500 2007.583\n2008 2008.000 2008.083 2008.167 2008.250 2008.333 2008.417 2008.500 2008.583\n2009 2009.000 2009.083 2009.167 2009.250 2009.333 2009.417 2009.500 2009.583\n2010 2010.000 2010.083 2010.167 2010.250 2010.333 2010.417 2010.500 2010.583\n2011 2011.000 2011.083 2011.167 2011.250 2011.333 2011.417 2011.500 2011.583\n2012 2012.000 2012.083 2012.167 2012.250 2012.333 2012.417 2012.500 2012.583\n2013 2013.000 2013.083 2013.167 2013.250 2013.333 2013.417 2013.500 2013.583\n2014 2014.000 2014.083 2014.167 2014.250 2014.333 2014.417 2014.500 2014.583\n2015 2015.000 2015.083 2015.167 2015.250 2015.333 2015.417 2015.500 2015.583\n2016 2016.000 2016.083 2016.167 2016.250 2016.333 2016.417 2016.500 2016.583\n2017 2017.000 2017.083 2017.167 2017.250 2017.333 2017.417 2017.500 2017.583\n2018 2018.000 2018.083 2018.167 2018.250 2018.333 2018.417 2018.500 2018.583\n2019 2019.000 2019.083 2019.167 2019.250 2019.333 2019.417 2019.500 2019.583\n2020 2020.000 2020.083 2020.167 2020.250 2020.333 2020.417 2020.500 2020.583\n2021 2021.000 2021.083 2021.167 2021.250 2021.333 2021.417 2021.500 2021.583\n2022 2022.000 2022.083 2022.167 2022.250 2022.333 2022.417 2022.500 2022.583\n2023 2023.000 2023.083 2023.167 2023.250 2023.333 2023.417                  \n          Sep      Oct      Nov      Dec\n2000 2000.667 2000.750 2000.833 2000.917\n2001 2001.667 2001.750 2001.833 2001.917\n2002 2002.667 2002.750 2002.833 2002.917\n2003 2003.667 2003.750 2003.833 2003.917\n2004 2004.667 2004.750 2004.833 2004.917\n2005 2005.667 2005.750 2005.833 2005.917\n2006 2006.667 2006.750 2006.833 2006.917\n2007 2007.667 2007.750 2007.833 2007.917\n2008 2008.667 2008.750 2008.833 2008.917\n2009 2009.667 2009.750 2009.833 2009.917\n2010 2010.667 2010.750 2010.833 2010.917\n2011 2011.667 2011.750 2011.833 2011.917\n2012 2012.667 2012.750 2012.833 2012.917\n2013 2013.667 2013.750 2013.833 2013.917\n2014 2014.667 2014.750 2014.833 2014.917\n2015 2015.667 2015.750 2015.833 2015.917\n2016 2016.667 2016.750 2016.833 2016.917\n2017 2017.667 2017.750 2017.833 2017.917\n2018 2018.667 2018.750 2018.833 2018.917\n2019 2019.667 2019.750 2019.833 2019.917\n2020 2020.667 2020.750 2020.833 2020.917\n2021 2021.667 2021.750 2021.833 2021.917\n2022 2022.667 2022.750 2022.833 2022.917\n2023                                    \n\ntime(ldian2)[ntrain]###Me entrega la ultima fecha de la posici√≥n ntrain\n\n[1] 2018.667\n\ntrain=window(ldian2,end=time(ldian2)[ntrain])\ntest=window(ldian2,start=time(ldian2)[ntrain]+1/12)##1/12 porque es la fracci√≥n que corresponde a un mes\nlength(train)\n\n[1] 225\n\nntest=length(test)\nntest ##Me define el valor de origins, o de ventanas de rolling.\n\n[1] 57\n\nlserie ### Comparar los valores\n\n[1] 282\n\n\nLuego de dividir los datos procedemos a crear algunos vectores necesarios para realizar el rolling y posteriormente realizaremos el modelo sobre los datos de entrenamiento. ## Modelamiento SE.\n\nh=1\nfchstepahe=matrix(0,nrow=ntest,ncol=h) ##Crea una Columna para los h-pasos adelante\n### verval contiene los verdaderos valores de la serie en el conjunto de prueba con los que se comparar√°n los pron√≥sticos.\nverval=cbind(test[1:ntest])\nfor(j in 2:h){\n  verval=cbind(verval,c(test[j:ntest],rep(NA,j-1)))\n}\n\nverval=cbind(test[1:ntest],c(test[2:ntest],NA),c(test[3:ntest],NA,NA))\n####Ajuste del modelo con los datos de entrenamiento\nHWAP_train=stats::HoltWinters(train,seasonal=\"additive\")\nHWAP_train$alpha\n\n     alpha \n0.09446078 \n\nHWAP_train$beta\n\n      beta \n0.06537417 \n\nHWAP_train$gamma\n\n    gamma \n0.4091491 \n\n\n\n2.1.1 An√°lisis de reisulaes\nEl an√°lisis de los residuales se hace sobre el conjunto de entrenamiento del siguiente modo.\n\nlibrary(stats)\n# Obtener residuales del modelo Holt-Winters\nresiduales_hw &lt;- residuals(HWAP_train)\n# Visualizar los residuales en un gr√°fico\nplot(residuales_hw, type = \"l\", col = \"blue\", ylab = \"Residuales\", main = \"Residuales del modelo Holt-Winters\")\n\n\n\nacf(as.numeric(residuales_hw))\n\n\n\npacf(as.numeric(residuales_hw))\n\n\n\n#Test de Ljung-Box\n# Longitud de los residuos dividida por 4\nlongitud_dividida &lt;- length(residuales_hw) / 4\ncat(\"Longitud de los residuos dividida por 4:\", longitud_dividida, \"\\n\")\n\nLongitud de los residuos dividida por 4: 53.25 \n\n# Ra√≠z cuadrada de la longitud de los residuos\nraiz_cuadrada &lt;- sqrt(length(residuales_hw))\ncat(\"Ra√≠z cuadrada de la longitud de los residuos:\", raiz_cuadrada, \"\\n\")\n\nRa√≠z cuadrada de la longitud de los residuos: 14.59452 \n\n# Test de Ljung-Box para autocorrelaci√≥n\nlibrary(stats)\n# Lags a considerar (24 en este caso)\nlags &lt;- 24\n# Realizar el test de Ljung-Box\nljung_box_test &lt;- Box.test(residuales_hw, lag = lags, type = \"Ljung-Box\", fitdf = 0)\ncat(\"Estad√≠stica de Ljung-Box:\", ljung_box_test$statistic, \"\\n\")\n\nEstad√≠stica de Ljung-Box: 28.16708 \n\ncat(\"P-valor:\", ljung_box_test$p.value, \"\\n\")\n\nP-valor: 0.2530558 \n\n\nEn este caso es posible observar que al revisar las graficas del ACf y PACF no se evidencian que se tengan cosas por explicar, adem√°s la prueba de Ljung-Box, nos da un p valor de 0.2530558 el cual es m√°s grande que un valor \\(\\alpha=0.05\\), es decir que existe evidencia estadisticamente significativa para rechazar la hipotesis de correlaci√≥n, es decir que los residuales no parecen estar correlacionados. Luego de esto procederemos a realizar Rolling para conocer la capacidad predictiva del modelo. ### Rolling SE\n\n##Rolling\nfor(i in 1:(ntest))\n{\n  x=window(ldian2,end=time(ldian2)[ntrain]+(i-1)/12)\n  print(length(x))\n  refit=stats::HoltWinters(x,alpha=0.09446078,beta=0.06537417 ,gamma=0.4091491 ,seasonal=\"additive\")\n    fchstepahe[i,]=as.numeric(forecast::forecast(refit,h=h)$mean)\n}\n\n[1] 225\n[1] 226\n[1] 227\n[1] 228\n[1] 229\n[1] 230\n[1] 231\n[1] 232\n[1] 233\n[1] 234\n[1] 235\n[1] 236\n[1] 237\n[1] 238\n[1] 239\n[1] 240\n[1] 241\n[1] 242\n[1] 243\n[1] 244\n[1] 245\n[1] 246\n[1] 247\n[1] 248\n[1] 249\n[1] 250\n[1] 251\n[1] 252\n[1] 253\n[1] 254\n[1] 255\n[1] 256\n[1] 257\n[1] 258\n[1] 259\n[1] 260\n[1] 261\n[1] 262\n[1] 263\n[1] 264\n[1] 265\n[1] 266\n[1] 267\n[1] 268\n[1] 269\n[1] 270\n[1] 271\n[1] 272\n[1] 273\n[1] 274\n[1] 275\n[1] 276\n[1] 277\n[1] 278\n[1] 279\n[1] 280\n[1] 281\n\nfchstepahe\n\n          [,1]\n [1,] 15.59525\n [2,] 16.14393\n [3,] 15.60399\n [4,] 16.55152\n [5,] 15.75755\n [6,] 16.11598\n [7,] 16.46955\n [8,] 16.44372\n [9,] 16.41609\n[10,] 16.21793\n[11,] 15.77656\n[12,] 16.53835\n[13,] 15.75931\n[14,] 16.27512\n[15,] 15.88808\n[16,] 16.61020\n[17,] 15.82943\n[18,] 16.19280\n[19,] 16.46533\n[20,] 16.46223\n[21,] 16.38716\n[22,] 16.24423\n[23,] 15.75905\n[24,] 16.49863\n[25,] 15.71893\n[26,] 16.21610\n[27,] 15.79271\n[28,] 16.56674\n[29,] 15.77398\n[30,] 16.10388\n[31,] 16.20957\n[32,] 16.35066\n[33,] 16.31956\n[34,] 16.18904\n[35,] 15.78278\n[36,] 16.53065\n[37,] 15.83829\n[38,] 16.36082\n[39,] 15.89946\n[40,] 16.70520\n[41,] 15.91163\n[42,] 16.29069\n[43,] 16.37797\n[44,] 16.57237\n[45,] 16.47571\n[46,] 16.45082\n[47,] 16.07613\n[48,] 16.80589\n[49,] 16.12452\n[50,] 16.67698\n[51,] 16.21919\n[52,] 16.98076\n[53,] 16.19589\n[54,] 16.59437\n[55,] 16.73014\n[56,] 16.86376\n[57,] 16.74383\n\nerrores_pred=exp(verval[,1]) -exp(fchstepahe) ##Observaci√≥n: debo devolver los pron√≥sticos y los verdaderos valores a la escala original si es necesario.\nECM=apply(errores_pred^2,MARGIN = 2,mean,na.rm=TRUE) ##Ac√° se computa la medida de precisi√≥n del pron√≥stico(en este caso ECM).\nRECM=sqrt(ECM) ##Se le saca ra√≠z \nRECM ##se lee: Primera fila RECM 1-paso adelante y as√≠ sucesivamente.\n\n[1] 2143759\n\n\nDe este modo se obtuvo un valor ECM de 4.595703e+12 (Billones) y un valor RECM de 2143759 (Millones) ### Predicci√≥n usando el modelo SE.\n\nverval_ts&lt;-ts(exp(verval[,1]),start=time(ldian2)[ntrain]+1/12,frequency=12)\nfchstepahe_ts&lt;-ts(exp(fchstepahe),start=time(ldian2)[ntrain]+1/12,frequency=12)\n\nplot(verval_ts, col = \"blue\", ylab = \"Impuestos\", xlab = \"Tiempo\")\nlines(fchstepahe_ts, col = \"red\")\nlegend(\"topright\", legend = c(\"Reales\", \"Predicciones\"), col = c(\"blue\", \"red\"), lty = 1)"
  },
  {
    "objectID": "Descriptivo Dian (2).html#modelamiento-arma-con-componentes-de-fourier.",
    "href": "Descriptivo Dian (2).html#modelamiento-arma-con-componentes-de-fourier.",
    "title": "1¬† An√°lisis descriptivo del recaudo de impuestos internos por la DIAN",
    "section": "3.1 Modelamiento ARMA con componentes de fourier.",
    "text": "3.1 Modelamiento ARMA con componentes de fourier.\nEn primer lugar iniciamos utilizando la serie sin tendencia (via STL), con varianza estable y con estacionalidad eliminada (via componentes de fourier), se observaran su gr√°ficos acf y su gr√°fico pacf para encontrar los posibles ordens p y q, para realizar los modelamientos.\n\nElimiTenddian_STL_fourier&lt;-ElimiTenddian_STL-results_ciclo_ts\n\nacf(as.numeric(ElimiTenddian_STL_fourier),main=\"Series estacionaria (STL-Fourier)\",lag.max = length(dian2)/4)\n\n\n\nacf(as.numeric(ElimiTenddian_STL_fourier),main=\"Series estacionaria (STL-Fourier)\",lag.max = length(dian2)/4,ci.type='ma')## Para el MA\n\n\n\npacf(as.numeric(ElimiTenddian_STL_fourier),main=\"Series estacionaria (STL-Fourier)\",lag.max = length(dian2)/4)\n\n\n\n\n\nrequire(feasts)\ndian2_tsbl_notend=as_tsibble(ElimiTenddian_STL_fourier)\ndian2_tsbl_notend%&gt;%gg_subseries(value)\n\n\n\n\nEste gr√°fico nos indica que la series sin tendencia via STL y sin estacionalidad via componentes de fourier no hace que nuestra series de tiempo sea estacionaria, esto puede deberse a que las componentes de fourier no ayudaron a estimar de modo correcto la estacionalidad de este proceso. ## Modelamiento ARMA con dummy. Teniendo en cuenta que el metodo que mejor estim√≥ la estacionalidad fue el metodo de variables dummy, se proceder√° a realizar el modelado de 3 modelos, AR,MA y ARMA, luego procederemos a compararlos en terminos de su capacidad predictiva (ECM). ## Divisi√≥n de la base de datos en entrenamiento, validaci√≥n y prueba.\n\ntrain_weight2 &lt;- 0.8\nsplit2 &lt;- as.integer(length(ElimiTenddian_STL) * train_weight2)\n#window(ldian2,end=time(ldian2)[ntrain])\ndf_train2 &lt;- window(ElimiTenddian_STL, end = time(ElimiTenddian_STL)[split2])#80%\ndf_test2 &lt;- window(ElimiTenddian_STL, start = time(ElimiTenddian_STL)[split2] + 1/12,)#20%"
  },
  {
    "objectID": "Descriptivo Dian (2).html#modelo-ar",
    "href": "Descriptivo Dian (2).html#modelo-ar",
    "title": "1¬† An√°lisis descriptivo del recaudo de impuestos internos por la DIAN",
    "section": "3.2 Modelo AR",
    "text": "3.2 Modelo AR\nEn primer lugar es necesario realizar la estimaci√≥n de las variables dummy sobre el conjunto de prueba lo cual se va a hacer a continuaci√≥n. ### Variables dummy\n\n## Prueba de crear las variables dummy \nlibrary(stats)\nlibrary(forecast)\nlibrary(ggplot2)\n\n# Carga tus datos o crea una serie de tiempo similar\n# Puedes cargar tus datos desde un archivo o crearlos manualmente\n# Aqu√≠ se asume que tienes una serie de tiempo en un objeto llamado 'dian_detrend_STL'\n# Crea un objeto de variable dummy estacional\ndummy &lt;- seasonaldummy(df_train2)\n# Ajusta un modelo de regresi√≥n lineal\nmodelo &lt;- lm(df_train2 ~ dummy)\n# Obtiene un resumen del modelo\nsummary(modelo)\n\n\nCall:\nlm(formula = df_train2 ~ dummy)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.76802 -0.05968 -0.00249  0.08298  0.51336 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -0.46507    0.03431 -13.556  &lt; 2e-16 ***\ndummyJan     0.78175    0.04788  16.329  &lt; 2e-16 ***\ndummyFeb     0.29694    0.04788   6.202 2.85e-09 ***\ndummyMar     0.43254    0.04788   9.035  &lt; 2e-16 ***\ndummyApr     0.75773    0.04788  15.827  &lt; 2e-16 ***\ndummyMay     0.68003    0.04788  14.204  &lt; 2e-16 ***\ndummyJun     0.70980    0.04788  14.826  &lt; 2e-16 ***\ndummyJul     0.50649    0.04788  10.579  &lt; 2e-16 ***\ndummyAug     0.28110    0.04788   5.872 1.64e-08 ***\ndummySep     0.71053    0.04788  14.841  &lt; 2e-16 ***\ndummyOct     0.09436    0.04852   1.945   0.0531 .  \ndummyNov     0.53051    0.04852  10.934  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1456 on 213 degrees of freedom\nMultiple R-squared:  0.7598,    Adjusted R-squared:  0.7474 \nF-statistic: 61.26 on 11 and 213 DF,  p-value: &lt; 2.2e-16\n\n# Realiza predicciones con el modelo\nnuevas_obs &lt;- length(df_train2)  # N√∫mero de observaciones en la serie de tiempo\npredicciones &lt;- predict(modelo, newdata = data.frame(dummy = dummy))\n# Crea un nuevo objeto de serie de tiempo con las predicciones\ndian_pred_train &lt;- ts(predicciones, start = start(df_train2), frequency = frequency(df_train2))\n\n# Grafica los resultados\nplot(df_train2, col = \"blue\", type = \"l\", xlab = \"Fecha\", ylab = \"Valor Original\")\nlines(dian_pred_train, col = \"red\")\nlegend(\"topleft\", legend = c(\"Impuestos\", \"Predicciones\"), col = c(\"blue\", \"red\"))\n\n\n\n\n\n#Eliminando la estacionalidad.\nElimiTenddian_STL_dummy&lt;-df_train2-dian_pred_train\nplot(ElimiTenddian_STL_dummy,main=\"Datos estacionarios\")\n\n\n\nacf(as.numeric(ElimiTenddian_STL_dummy),main=\"ACF datos estacionarios\",lag.max = length(ElimiTenddian_STL_dummy)/4)\n\n\n\nacf(as.numeric(ElimiTenddian_STL_dummy),main=\"ACF datos estacionarios\",lag.max = length(ElimiTenddian_STL_dummy)/4,ci.type='ma')\n\n\n\npacf(as.numeric(ElimiTenddian_STL_dummy),main=\"PACF datos estacionarios\",lag.max = length(ElimiTenddian_STL_dummy)/4)\n\n\n\nrequire(feasts)\ndian2_tsbl_notend=as_tsibble(ElimiTenddian_STL_dummy)\ndian2_tsbl_notend%&gt;%gg_subseries(value)\n\n\n\n\n\n3.2.1 Ajustando el modelo AR(12)\nAl observar los graficos del acf y el pacf es posible observar que el ACF desciende lentamente hacia 0, mientras que en el PACF se observa que el rezago 12 es significativamente diferente de 0 y rezagos m√°s grandes no parecen ser significativamente distintos de 0, por esta razon nos decantamos por construir un modelo de tipo AR(12)\n\nlibrary(lmtest)\nARPURO=Arima(ElimiTenddian_STL_dummy,order=c(12,0,0),include.mean = TRUE)\ncoeftest(ARPURO)\n\n\nz test of coefficients:\n\n             Estimate  Std. Error z value  Pr(&gt;|z|)    \nar1       -0.17658703  0.05979452 -2.9532  0.003145 ** \nar2        0.01322007  0.06117696  0.2161  0.828913    \nar3       -0.09495073  0.06104447 -1.5554  0.119842    \nar4       -0.10611084  0.06137399 -1.7289  0.083823 .  \nar5       -0.06870130  0.06198604 -1.1083  0.267717    \nar6       -0.04956787  0.06153850 -0.8055  0.420544    \nar7       -0.06398874  0.06218240 -1.0290  0.303457    \nar8       -0.02486263  0.06232279 -0.3989  0.689942    \nar9       -0.05688534  0.06197595 -0.9179  0.358691    \nar10      -0.02991973  0.06168740 -0.4850  0.627661    \nar11      -0.00779959  0.06162111 -0.1266  0.899278    \nar12       0.42095115  0.05995852  7.0207 2.208e-12 ***\nintercept -0.00056137  0.00645641 -0.0869  0.930713    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n##Refinamiento del modelo \nARPURO_ref=Arima(ElimiTenddian_STL_dummy,order=c(12,0,0),include.mean = TRUE,\n                 fixed=c(NA,0,0,0,0,0,0,0,0,0,0,NA,0))\n### Modelo m√°s parsimonioso que el anterior.\nARPURO_ref_prueba=Arima(ElimiTenddian_STL_dummy,order=c(1,0,0),seasonal = c(1,0,0),include.mean = F)\ncoeftest(ARPURO_ref)\n\n\nz test of coefficients:\n\n      Estimate Std. Error z value  Pr(&gt;|z|)    \nar1  -0.162738   0.057542 -2.8282  0.004681 ** \nar12  0.446109   0.057620  7.7423 9.764e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ncoeftest(ARPURO_ref_prueba)\n\n\nz test of coefficients:\n\n      Estimate Std. Error z value Pr(&gt;|z|)    \nar1  -0.210490   0.065031 -3.2368 0.001209 ** \nsar1  0.463263   0.058270  7.9503 1.86e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nAl realizar el refinamiento es posible observar que unicamente se encontraron como significativos los parametros asociados con los retardos 1 y 12. Posteriormente se va a realizar el an√°lisis de residuales del modelo AR(12). ### Verificaci√≥n de supusetos modelo AR\n\n# An√°lisis de residuales\nresiduales=ARPURO_ref_prueba$residuals\nplot(residuales)\n\n\n\nacf(residuales)\n\n\n\nacf(residuales^2)\n\n\n\npacf(residuales)\n\n\n\n\nEs posible observar con los graficos para el ACf y el PACF que no parece que quede algo por explicar dentro de los residuales de este modelo ajustado, lo cual es un buen indicio.\n\n#Test de normalidad\ntseries::jarque.bera.test(residuales)\n\n\n    Jarque Bera Test\n\ndata:  residuales\nX-squared = 973.46, df = 2, p-value &lt; 2.2e-16\n\n#Test de autocorrelaci√≥n\nlength(residuales)/4\n\n[1] 56.25\n\nsqrt(length(residuales))\n\n[1] 15\n\nBox.test(residuales, lag =17 , type = \"Ljung-Box\", fitdf = 2)#No puedo Rechazar la hip√≥tesis de no autocorrelaci√≥n!\n\n\n    Box-Ljung test\n\ndata:  residuales\nX-squared = 9.6551, df = 15, p-value = 0.8409\n\n\nEn este caso se tiene que el test de normalidad dado por el test de jarque bera, tiene un p valor de 2.2e-16, el cual es menor que un valor alpha del 0.05, por lo tanto existe suficiente evidencia estadistica para rechazar la hipotesis de normalidad. En el caso de la prueba de autocorrelaci√≥n se obtiene un p valor de 0.8409, lo cual indica que no hay suficiente evidencia para afirmar que hay autocorrelaci√≥n significativa en los residuos.\n\n###Estad?sticas CUSUM\nres=residuales\ncum=cumsum(res)/sd(res)\nN=length(res)\ncumq=cumsum(res^2)/sum(res^2)\nAf=0.948 ###Cuantil del 95% para la estad?stica cusum\nco=0.10997####Valor del cuantil aproximado para cusumsq para n/2\nLS=Af*sqrt(N)+2*Af*c(1:length(res))/sqrt(N)\nLI=-LS\nLQS=co+(1:length(res))/N\nLQI=-co+(1:length(res))/N\nplot(cum,type=\"l\",ylim=c(min(LI),max(LS)),xlab=\"t\",ylab=\"\",main=\"CUSUM\")\nlines(LS,type=\"S\",col=\"red\")\nlines(LI,type=\"S\",col=\"red\")\n\n\n\n#CUSUMSQ\nplot(cumq,type=\"l\",xlab=\"t\",ylab=\"\",main=\"CUSUMSQ\")                      \nlines(LQS,type=\"S\",col=\"red\")                                                                           \nlines(LQI,type=\"S\",col=\"red\")\n\n\n\n\nEste gr√°fico mide la variabilidad de los residuales, en este caso se tiene que se sale un poco la variabilidad de las bandas de confianza, pero esto no ocurre por un largo periodo de tiempo.\n\n\n3.2.2 Rolling AR()\n\n# rolling \n#ElimiTenddian_STL-dian_pred\nh=1\nfcmat=matrix(0,nrow=ntest,ncol=h)\nfor(i in 1:ntest){\n  x=window((ElimiTenddian_STL-dian_pred),end=time(ElimiTenddian_STL-dian_pred)[ntrain]+(i-1)/12)\n  #print(length(x))\n  refit=Arima(x,model=ARPURO_ref_prueba)\n  fcmat[i,]=as.numeric(forecast::forecast(refit,h=h)$mean)\n}\n\n# para volver a la escala original\nestacionalidad&lt;-as.vector(dian_pred)\ntendencia&lt;-as.vector(modelo_stl$trend)\nfchstepahe&lt;-(fcmat+estacionalidad[226:282])+tendencia[226:282] # primero sumamos la estacionalidad y luego la tendencia\n\nerrores_pred=exp(verval[,1]) -exp(fchstepahe) ##Observaci√≥n: debo devolver los pron√≥sticos y los verdaderos valores a la escala original si es necesario.\nECM=apply(errores_pred^2,MARGIN = 2,mean,na.rm=TRUE) ##Ac√° se computa la medida de precisi√≥n del pron√≥stico(en este caso ECM).\nRECM=sqrt(ECM) ##Se le saca ra√≠z \nRECM # 1308387\n\n[1] 1308387\n\n\nCon el Rolling sobre el modelo AR(12) se obutov un valor ECM de 1.711875e+12 (Billones) y un valor RECM de 1308387 (Millones) ### Predicci√≥n usando el modelo AR(12)\n\nverval_ts&lt;-ts(exp(verval[,1]),start=time(ldian2)[ntrain]+1/12,frequency=12)\nfchstepahe_ts&lt;-ts(exp(fchstepahe),start=time(ldian2)[ntrain]+1/12,frequency=12)\n\nplot(verval_ts, col = \"blue\", ylab = \"Impuestos\", xlab = \"Tiempo\")\nlines(fchstepahe_ts, col = \"red\")\nlegend(\"topright\", legend = c(\"Reales\", \"Predicciones\"), col = c(\"blue\", \"red\"), lty = 1)"
  },
  {
    "objectID": "Descriptivo Dian (2).html#ajustando-el-modelo-arima",
    "href": "Descriptivo Dian (2).html#ajustando-el-modelo-arima",
    "title": "1¬† An√°lisis descriptivo del recaudo de impuestos internos por la DIAN",
    "section": "5.1 Ajustando el modelo ARIMA",
    "text": "5.1 Ajustando el modelo ARIMA\nEn primer lugar es necesario diviir los datos en conjunto de entrenamiento y de prueba.\n\n## Divison de los datos Utilizando los datos con varianza estable por boxcox.\n\ntrain_weight2 &lt;- 0.8\nsplit2 &lt;- as.integer(length(dldian2) * train_weight2)\n#window(ldian2,end=time(ldian2)[ntrain])\ndf_train3 &lt;- window(ldian2, end = time(ldian2)[split2])#80%\ndf_test3 &lt;- window(ldian2, start = time(ldian2)[split2] + 1/12)#20%\n\nPor lo observado en los graficos de acf, tiene snetido realizar un ajuste de un modelo ARIMA(12,1,0), puesto que el grafico del ACF baja lentamente y luego del rezago 12, la autocorrelaci√≥n parcial se hace significativamente igual a 0 (observando el grafico PACF).\n\ndummy_ARIMA&lt;-forecast::seasonaldummy(df_train3)\n###Variables Dummy\nARIMA&lt;-Arima(df_train3,order=c(12,1,0),include.mean = TRUE,xreg = dummy_ARIMA)\ncoeftest(ARIMA)\n\n\nz test of coefficients:\n\n      Estimate Std. Error  z value  Pr(&gt;|z|)    \nar1  -0.836525   0.066167 -12.6426 &lt; 2.2e-16 ***\nar2  -0.540680   0.085515  -6.3226 2.571e-10 ***\nar3  -0.425229   0.092021  -4.6210 3.819e-06 ***\nar4  -0.349554   0.095551  -3.6583 0.0002539 ***\nar5  -0.261111   0.098094  -2.6619 0.0077712 ** \nar6  -0.194296   0.099366  -1.9554 0.0505413 .  \nar7  -0.178789   0.099580  -1.7954 0.0725864 .  \nar8  -0.143400   0.098785  -1.4516 0.1466018    \nar9  -0.176200   0.096527  -1.8254 0.0679407 .  \nar10 -0.191734   0.093073  -2.0600 0.0393940 *  \nar11 -0.215715   0.086273  -2.5004 0.0124063 *  \nar12  0.151694   0.066951   2.2657 0.0234669 *  \nJan   0.782990   0.082581   9.4814 &lt; 2.2e-16 ***\nFeb   0.286359   0.060197   4.7570 1.965e-06 ***\nMar   0.443788   0.077788   5.7051 1.163e-08 ***\nApr   0.747220   0.066226  11.2829 &lt; 2.2e-16 ***\nMay   0.688016   0.073975   9.3006 &lt; 2.2e-16 ***\nJun   0.703536   0.067092  10.4861 &lt; 2.2e-16 ***\nJul   0.517541   0.073977   6.9960 2.634e-12 ***\nAug   0.283447   0.066218   4.2805 1.864e-05 ***\nSep   0.716101   0.078597   9.1111 &lt; 2.2e-16 ***\nOct   0.085955   0.060702   1.4160 0.1567695    \nNov   0.534292   0.083475   6.4006 1.548e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n## Refinamiento \nARIMA_ref&lt;-Arima(df_train3,order=c(12,1,0),include.mean = TRUE,xreg = dummy_ARIMA,fixed=c(NA,NA,NA,NA,0,0,0,0,0,0,0,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,0,NA))\ncoeftest(ARIMA_ref)\n\n\nz test of coefficients:\n\n      Estimate Std. Error  z value  Pr(&gt;|z|)    \nar1  -0.763976   0.064788 -11.7919 &lt; 2.2e-16 ***\nar2  -0.435002   0.081169  -5.3592 8.359e-08 ***\nar3  -0.283567   0.081087  -3.4971 0.0004704 ***\nar4  -0.143521   0.062208  -2.3071 0.0210484 *  \nar12  0.282710   0.048061   5.8823 4.045e-09 ***\nJan   0.722194   0.065612  11.0071 &lt; 2.2e-16 ***\nFeb   0.255665   0.053402   4.7876 1.688e-06 ***\nMar   0.390215   0.058617   6.6570 2.795e-11 ***\nApr   0.716330   0.059918  11.9552 &lt; 2.2e-16 ***\nMay   0.644563   0.055073  11.7039 &lt; 2.2e-16 ***\nJun   0.653079   0.059922  10.8988 &lt; 2.2e-16 ***\nJul   0.478100   0.058291   8.2020 2.364e-16 ***\nAug   0.228513   0.053555   4.2669 1.983e-05 ***\nSep   0.685207   0.066132  10.3613 &lt; 2.2e-16 ***\nNov   0.489457   0.070777   6.9155 4.663e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nAhora procedemos a observar si se cumplen los supuestos de este modelo. ## Verificaci√≥n de los supuestos.\n\n## Validaci√≥n de los supuestos.\n# An√°lisis de residuales\nresiduales &lt;-ARIMA_ref$residuals \n\nplot(residuales)\n\n\n\nacf(as.numeric(residuales))\n\n\n\nacf(as.numeric(residuales^2))\n\n\n\npacf(as.numeric(residuales))\n\n\n\n\n\n#Test de normalidad\ntseries::jarque.bera.test(residuales)\n\n\n    Jarque Bera Test\n\ndata:  residuales\nX-squared = 275.72, df = 2, p-value &lt; 2.2e-16\n\n#Test de autocorrelaci√≥n\nlength(residuales)/4\n\n[1] 56\n\nsqrt(length(residuales))\n\n[1] 14.96663\n\nBox.test(residuales, lag =17 , type = \"Ljung-Box\", fitdf = 2)#No puedo Rechazar la hip√≥tesis de no autocorrelaci√≥n!\n\n\n    Box-Ljung test\n\ndata:  residuales\nX-squared = 34.765, df = 15, p-value = 0.002655\n\n\nEn este caso se tiene que se rechaza el supuesto de normalidad ya que 2.2e-16 (p-value) es menor que un valor alpha de 0.05,en este caso el p-valor de la prueba Box-Ljung es 0.002655, que es menor que 0.05, por lo tanto hay suficiente evidencia para no rechazar que hay autocorrelaci√≥n significativa en los residuos.\n\n###Estad?sticas CUSUM\nres=residuales\ncum=cumsum(res)/sd(res)\nN=length(res)\ncumq=cumsum(res^2)/sum(res^2)\nAf=0.948 ###Cuantil del 95% para la estad?stica cusum\nco=0.10997####Valor del cuantil aproximado para cusumsq para n/2\nLS=Af*sqrt(N)+2*Af*c(1:length(res))/sqrt(N)\nLI=-LS\nLQS=co+(1:length(res))/N\nLQI=-co+(1:length(res))/N\nplot(cum,type=\"l\",ylim=c(min(LI),max(LS)),xlab=\"t\",ylab=\"\",main=\"CUSUM\")\nlines(LS,type=\"S\",col=\"red\")\nlines(LI,type=\"S\",col=\"red\")\n\n\n\n#CUSUMSQ\nplot(cumq,type=\"l\",xlab=\"t\",ylab=\"\",main=\"CUSUMSQ\")                      \nlines(LQS,type=\"S\",col=\"red\")                                                                           \nlines(LQI,type=\"S\",col=\"red\")"
  },
  {
    "objectID": "Descriptivo Dian (2).html#divisi√≥n-de-los-datos",
    "href": "Descriptivo Dian (2).html#divisi√≥n-de-los-datos",
    "title": "1¬† An√°lisis descriptivo del recaudo de impuestos internos por la DIAN",
    "section": "6.1 Divisi√≥n de los datos",
    "text": "6.1 Divisi√≥n de los datos\n\ntrain_weight2 &lt;- 0.8\nsplit2 &lt;- as.integer(length(ldian2) * train_weight2)\n#window(ldian2,end=time(ldian2)[ntrain])\ndf_train4 &lt;- window(ldian2, end = time(ldian2)[split2])#80%\ndf_test4 &lt;- window(ldian2, start = time(ldian2)[split2] + 1/12)#20%\n\nTeniendo en cuenta la prueba de raices unitarias realizada anteriormente se conoce que hay presencia de una ra√≠z unitaria, por lo cual se deberia realizar una diferenciaci√≥n ordinaria, por otro lado se sabe de la secci√≥n del an√°lisis descriptivo que se tiene estacionalidad de periodo 12, por dicha raz√≥n procederemos a realizar diferenciacion estacional, posteriormente observaremos los posibles ordenes para el modelamiento SARIMA.\n\n##Diferencia estacional.\ndldian2&lt;-diff(df_train4)\nmonthplot(dldian2)\n\n\n\nacf(as.numeric(dldian2),lag.max = length(dian2)/4)\n\n\n\nspectrum(dldian2)\n\n\n\nnsdiffs(dldian2)\n\n[1] 1\n\nnsdiffs(ldian2)\n\n[1] 1\n\n\nLa funci√≥n ‚Äúnsdiffs‚Äù, no indica la cantidad de diferencias estacionales que se deben hacer, en este caso se nos indica que es 1, a su ves se conovia gracias a la secci√≥n descriptiva que se tenia presencia de una componente estacional de periodo \\(s=12\\).\n\n##Diferenciacion estacional\nDdldian2=diff(dldian2,lag=12)###lag=s\n\n\nplot(dldian2)\n\n\n\nplot(Ddldian2)\n\n\n\nmonthplot(Ddldian2)\n\n\n\nacf(as.numeric(Ddldian2),lag.max = length(dian2)/4)\n\n\n\nspectrum(Ddldian2)\n\n\n\nnsdiffs(Ddldian2)\n\n[1] 0\n\n\nNotese que ya es posible observar una serie estacionaria luego de realizar la diferenciaci√≥n ordinaria y la diferenciaci√≥n estacionaria, adem√°s no parece ser necesario realizar m√°s diferenciaciones. Ahora si procedemos a encontrar los ordenes para los modelos de la familia SARIMA.\n\nacf(as.numeric(Ddldian2))\n\n\n\nacf(as.numeric(Ddldian2),lag.max = length(dian2)/4, ci.type='ma')# q=0,1,2 Q=0,1\n\n\n\npacf(as.numeric(Ddldian2),lag.max = length(dian2)/4)#p=0,1,2,...,5, P=0,1,2,3\n\n\n\n\nLuego de analizar los gr√°ficos del ACF y PACF se procede a ajustar el modelo SARIMA. ## Ajuste del modelo\n\n##Ajuste del modelo SARIMA\nmodelo_SARIMA = Arima(df_train4, c(5, 1, 1),seasonal = list(order = c(3, 1, 2), period = 12),lambda = 0)\ncoeftest(modelo_SARIMA)\n\n\nz test of coefficients:\n\n      Estimate Std. Error  z value  Pr(&gt;|z|)    \nar1  -0.068782   0.079788  -0.8621  0.388655    \nar2   0.215094   0.077028   2.7924  0.005232 ** \nar3   0.013880   0.074776   0.1856  0.852740    \nar4  -0.077461   0.074281  -1.0428  0.297038    \nar5   0.035963   0.073834   0.4871  0.626202    \nma1  -0.922809   0.037890 -24.3550 &lt; 2.2e-16 ***\nsar1 -0.816776   0.456869  -1.7878  0.073813 .  \nsar2 -0.460331   0.292090  -1.5760  0.115028    \nsar3 -0.249335   0.126857  -1.9655  0.049359 *  \nsma1  0.355469   0.458807   0.7748  0.438476    \nsma2 -0.099372   0.400739  -0.2480  0.804156    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n##Refinando el modelo SARIMA.\nmodelo_SARIMA_ref = Arima(df_train4, c(5, 1, 1),seasonal = list(order = c(3, 1, 2), period = 12),lambda = 0,fixed=c(0,NA,0,0,0,NA,NA,NA,NA,0,0))\ncoeftest(modelo_SARIMA_ref)\n\n\nz test of coefficients:\n\n      Estimate Std. Error  z value  Pr(&gt;|z|)    \nar2   0.211420   0.071878   2.9414  0.003267 ** \nma1  -0.935944   0.024303 -38.5119 &lt; 2.2e-16 ***\nsar1 -0.459411   0.070200  -6.5443 5.978e-11 ***\nsar2 -0.391257   0.069138  -5.6591 1.522e-08 ***\nsar3 -0.131092   0.068258  -1.9205  0.054791 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "Descriptivo Dian (2).html#verificaci√≥n-de-los-supusetos.",
    "href": "Descriptivo Dian (2).html#verificaci√≥n-de-los-supusetos.",
    "title": "1¬† An√°lisis descriptivo del recaudo de impuestos internos por la DIAN",
    "section": "6.2 Verificaci√≥n de los supusetos.",
    "text": "6.2 Verificaci√≥n de los supusetos.\nAhora procederemos a revisar los supusetos de este modelo.\n\n# An√°lisis de residuales\nresiduales=modelo_SARIMA_ref$residuals\nplot(residuales)\n\n\n\nacf(as.numeric(residuales))\n\n\n\nacf(as.numeric(residuales^2))\n\n\n\npacf(as.numeric(residuales))\n\n\n\n\nNotese que los acf y pacf parecen indicar que no queda nada por ser explicado en los residuales del modelo, lo cual es un buen indicio.\n\n#Test de normalidad\ntseries::jarque.bera.test(residuales)\n\n\n    Jarque Bera Test\n\ndata:  residuales\nX-squared = 1057, df = 2, p-value &lt; 2.2e-16\n\n#Test de autocorrelaci√≥n\nlength(residuales)/4\n\n[1] 56.25\n\nsqrt(length(residuales))\n\n[1] 15\n\nBox.test(residuales, lag =17 , type = \"Ljung-Box\", fitdf = 2)#No puedo Rechazar la hip√≥tesis de no autocorrelaci√≥n!\n\n\n    Box-Ljung test\n\ndata:  residuales\nX-squared = 6.9188, df = 15, p-value = 0.9599\n\n\nEn este caso se tiene que se rechaza el supuesto de normalidad ya que 2.2e-16 (p-value) es menor que un valor alpha de 0.05,en este caso el p-valor de la prueba Box-Ljung es 0.9599, que es mayor que 0.05, por lo tanto hay suficiente evidencia para rechazar que hay autocorrelaci√≥n significativa en los residuos.\n\n###Estad?sticas CUSUM\nres=residuales\ncum=cumsum(res)/sd(res)\nN=length(res)\ncumq=cumsum(res^2)/sum(res^2)\nAf=0.948 ###Cuantil del 95% para la estad?stica cusum\nco=0.10997####Valor del cuantil aproximado para cusumsq para n/2\nLS=Af*sqrt(N)+2*Af*c(1:length(res))/sqrt(N)\nLI=-LS\nLQS=co+(1:length(res))/N\nLQI=-co+(1:length(res))/N\nplot(cum,type=\"l\",ylim=c(min(LI),max(LS)),xlab=\"t\",ylab=\"\",main=\"CUSUM\")\nlines(LS,type=\"S\",col=\"red\")\nlines(LI,type=\"S\",col=\"red\")\n\n\n\n#CUSUMSQ\nplot(cumq,type=\"l\",xlab=\"t\",ylab=\"\",main=\"CUSUMSQ\")                      \nlines(LQS,type=\"S\",col=\"red\")                                                                           \nlines(LQI,type=\"S\",col=\"red\")"
  },
  {
    "objectID": "Descriptivo Dian (2).html#rolling-modelo-sarima",
    "href": "Descriptivo Dian (2).html#rolling-modelo-sarima",
    "title": "1¬† An√°lisis descriptivo del recaudo de impuestos internos por la DIAN",
    "section": "6.3 Rolling modelo SARIMA",
    "text": "6.3 Rolling modelo SARIMA\nLuesto de observar los supuestos sobre los residuales del modelo SARIMA ajustado procedemos a observar la capacidad predictiva del modelo haciendo rolling sobre el conjunto de prueba y obteniendo su ECM.\n\nh=1\nlserie=length(df_train4)##datos de entrenamiento\nntrain=length(df_train4)\nntrain\n\n[1] 225\n\ntime(df_train4)\n\n          Jan      Feb      Mar      Apr      May      Jun      Jul      Aug\n2000 2000.000 2000.083 2000.167 2000.250 2000.333 2000.417 2000.500 2000.583\n2001 2001.000 2001.083 2001.167 2001.250 2001.333 2001.417 2001.500 2001.583\n2002 2002.000 2002.083 2002.167 2002.250 2002.333 2002.417 2002.500 2002.583\n2003 2003.000 2003.083 2003.167 2003.250 2003.333 2003.417 2003.500 2003.583\n2004 2004.000 2004.083 2004.167 2004.250 2004.333 2004.417 2004.500 2004.583\n2005 2005.000 2005.083 2005.167 2005.250 2005.333 2005.417 2005.500 2005.583\n2006 2006.000 2006.083 2006.167 2006.250 2006.333 2006.417 2006.500 2006.583\n2007 2007.000 2007.083 2007.167 2007.250 2007.333 2007.417 2007.500 2007.583\n2008 2008.000 2008.083 2008.167 2008.250 2008.333 2008.417 2008.500 2008.583\n2009 2009.000 2009.083 2009.167 2009.250 2009.333 2009.417 2009.500 2009.583\n2010 2010.000 2010.083 2010.167 2010.250 2010.333 2010.417 2010.500 2010.583\n2011 2011.000 2011.083 2011.167 2011.250 2011.333 2011.417 2011.500 2011.583\n2012 2012.000 2012.083 2012.167 2012.250 2012.333 2012.417 2012.500 2012.583\n2013 2013.000 2013.083 2013.167 2013.250 2013.333 2013.417 2013.500 2013.583\n2014 2014.000 2014.083 2014.167 2014.250 2014.333 2014.417 2014.500 2014.583\n2015 2015.000 2015.083 2015.167 2015.250 2015.333 2015.417 2015.500 2015.583\n2016 2016.000 2016.083 2016.167 2016.250 2016.333 2016.417 2016.500 2016.583\n2017 2017.000 2017.083 2017.167 2017.250 2017.333 2017.417 2017.500 2017.583\n2018 2018.000 2018.083 2018.167 2018.250 2018.333 2018.417 2018.500 2018.583\n          Sep      Oct      Nov      Dec\n2000 2000.667 2000.750 2000.833 2000.917\n2001 2001.667 2001.750 2001.833 2001.917\n2002 2002.667 2002.750 2002.833 2002.917\n2003 2003.667 2003.750 2003.833 2003.917\n2004 2004.667 2004.750 2004.833 2004.917\n2005 2005.667 2005.750 2005.833 2005.917\n2006 2006.667 2006.750 2006.833 2006.917\n2007 2007.667 2007.750 2007.833 2007.917\n2008 2008.667 2008.750 2008.833 2008.917\n2009 2009.667 2009.750 2009.833 2009.917\n2010 2010.667 2010.750 2010.833 2010.917\n2011 2011.667 2011.750 2011.833 2011.917\n2012 2012.667 2012.750 2012.833 2012.917\n2013 2013.667 2013.750 2013.833 2013.917\n2014 2014.667 2014.750 2014.833 2014.917\n2015 2015.667 2015.750 2015.833 2015.917\n2016 2016.667 2016.750 2016.833 2016.917\n2017 2017.667 2017.750 2017.833 2017.917\n2018 2018.667                           \n\ntime(df_train4)[ntrain]###Me entrega la ultima fecha de la posici√≥n ntrain\n\n[1] 2018.667\n\ntrain=window(ldian2,end=c(2018,8))\ntest=window(ldian2, start = time(df_train4)[split2] + 1/12)\n#length(train)\nntest=length(df_test4)\nntest\n\n[1] 57\n\nfcmat=matrix(0,nrow=ntest,ncol=h)\nfor(i in 1:ntest)\n{\n  x=window(ldian2,end=time(ldian2)[ntrain]+(i-1)/12)\n  #print(length(x))\n  refit=Arima(x, model=modelo_SARIMA_ref)\n  fcmat[i,]=as.numeric(forecast::forecast(refit,h=h)$mean)\n}\nfcmat_menos_reales&lt;-exp(verval[,1])-exp(fcmat)\nECM=apply(fcmat_menos_reales^2,MARGIN = 2,mean,na.rm=TRUE)\nRECM=sqrt(ECM) \nRECM # 4953741\n\n[1] 2197225\n\n\nSe obtuvo un valor de ECM de 4.827798e+12 (Billones) y un RECM de 2197225 (Millones). ## Predicci√≥n usando el modelo SARIMA.\n\nverval_ts&lt;-ts(exp(test),start=time(ldian2)[ntrain]+1/12,frequency=12)\nfchstepahe_ts&lt;-ts(exp(fcmat),start=time(ldian2)[ntrain]+1/12,frequency=12)\n\nplot(verval_ts, col = \"blue\", ylab = \"Impuestos\", xlab = \"Tiempo\")\nlines(fchstepahe_ts, col = \"red\")\nlegend(\"topright\", legend = c(\"Reales\", \"Predicciones\"), col = c(\"blue\", \"red\"), lty = 1)"
  },
  {
    "objectID": "Descriptivo Dian (2).html#verificaci√≥n-de-los-supusetos.-1",
    "href": "Descriptivo Dian (2).html#verificaci√≥n-de-los-supusetos.-1",
    "title": "1¬† An√°lisis descriptivo del recaudo de impuestos internos por la DIAN",
    "section": "7.1 Verificaci√≥n de los supusetos.",
    "text": "7.1 Verificaci√≥n de los supusetos.\nAhora procederemos a revisar los supusetos de este modelo.\n\n# An√°lisis de residuales\nresiduales=modelo_SARIMA_ref_outliers2$residuals\nplot(residuales)\n\n\n\nacf(as.numeric(residuales))\n\n\n\nacf(as.numeric(residuales^2))\n\n\n\npacf(as.numeric(residuales))\n\n\n\n\n\n#Test de normalidad\ntseries::jarque.bera.test(residuales)\n\n\n    Jarque Bera Test\n\ndata:  residuales\nX-squared = 233.76, df = 2, p-value &lt; 2.2e-16\n\n#Test de autocorrelaci√≥n\nlength(residuales)/4\n\n[1] 56.25\n\nsqrt(length(residuales))\n\n[1] 15\n\nBox.test(residuales, lag =17 , type = \"Ljung-Box\", fitdf = 2)#No puedo Rechazar la hip√≥tesis de no autocorrelaci√≥n!\n\n\n    Box-Ljung test\n\ndata:  residuales\nX-squared = 8.0528, df = 15, p-value = 0.9216\n\n\nPor el p value encontrado en el test de Jarque bera (1.059e-08&lt;0.05) se tiene suficiente evidencia estadistica para rechazar la hipotesis de normalidad, es decir que lso residuales no siguen una distribuci√≥n normal, por otro lado se tiene un p valor de 0.9216 en la prueba de Box-Ljung, lo cual nos indica que hay suficiente evidencia estadistica para rechazar la hip√≥tesis de Autocorrelaci√≥n dentro de los residuales.\n\n### Estadisticas CUSUM\nres=residuales\ncum=cumsum(res)/sd(res)\nN=length(res)\ncumq=cumsum(res^2)/sum(res^2)\nAf=0.948 ###Cuantil del 95% para la estad?stica cusum\nco=0.10997####Valor del cuantil aproximado para cusumsq para n/2\nLS=Af*sqrt(N)+2*Af*c(1:length(res))/sqrt(N)\nLI=-LS\nLQS=co+(1:length(res))/N\nLQI=-co+(1:length(res))/N\nplot(cum,type=\"l\",ylim=c(min(LI),max(LS)),xlab=\"t\",ylab=\"\",main=\"CUSUM\")\nlines(LS,type=\"S\",col=\"red\")\nlines(LI,type=\"S\",col=\"red\")\n\n\n\n#CUSUMSQ\nplot(cumq,type=\"l\",xlab=\"t\",ylab=\"\",main=\"CUSUMSQ\")                      \nlines(LQS,type=\"S\",col=\"red\")                                                                           \nlines(LQI,type=\"S\",col=\"red\")"
  },
  {
    "objectID": "Descriptivo Dian (2).html#rolling-sobre-el-modelo-sarima-con-outliers.",
    "href": "Descriptivo Dian (2).html#rolling-sobre-el-modelo-sarima-con-outliers.",
    "title": "1¬† An√°lisis descriptivo del recaudo de impuestos internos por la DIAN",
    "section": "7.2 Rolling sobre el modelo SARIMA con outliers.",
    "text": "7.2 Rolling sobre el modelo SARIMA con outliers.\n\nh=1\nnum_outliers=dim(total_outliers2)[2]\nregresoras_aditivos1=matrix(c(rep(0,h*(num_outliers-7))),h,num_outliers-7)\n#regresoras_LS=matrix(c(rep(1,h)),h,1)\n#regresoras_aditivos2=matrix(c(rep(0,h)),h,1)\nregresoras_TC=matrix(c(rep(0,h)),h,7)\nregresoras=cbind(regresoras_aditivos1,regresoras_TC)\ncolnames(regresoras)=colnames(total_outliers2)\n\n\nprediccSARIMAo &lt;- matrix(0, nrow=ntest, ncol=h) \nverval &lt;- cbind(test[1:ntest])\nfor(i in 1:(ntest)){\n  x&lt;-window(ldian2,end=time(ldian2)[ntrain]+(i-1)/12)\n  refit &lt;- Arima(x, model=modelo_SARIMA_ref_outliers2,xreg = total_outliers2)\n  prediccSARIMAo[i,] &lt;- forecast::forecast(refit, xreg=regresoras,h=h)$mean\n  total_outliers2&lt;-rbind(total_outliers2,regresoras)\n}\nerrores_predSARIMAo &lt;- exp(verval) -exp(prediccSARIMAo)\nECM_SARIMAo &lt;- mean(errores_predSARIMAo^2) # Medida de precisi√≥n del pron√≥stico (ECM).\nRECM_SARIMAo &lt;- sqrt(ECM_SARIMAo) # Se le saca ra√≠z \nRECM_SARIMAo\n\n[1] 2129751\n\n\nSe obtuvo un valor ECM de 4.827798e+12 y un valor RECM de 2129751. ## Prediccion utilizando el modelo SARIMA con outliers.\n\nverval_ts&lt;-ts(exp(verval),start=time(ldian2)[ntrain]+1/12,frequency=12)\nfchstepahe_ts&lt;-ts(exp(prediccSARIMAo),start=time(ldian2)[ntrain]+1/12,frequency=12)\n\nplot(verval_ts, col = \"blue\", ylab = \"Impuestos\", xlab = \"Tiempo\")\nlines(fchstepahe_ts, col = \"red\")\nlegend(\"topright\", legend = c(\"Reales\", \"Predicciones\"), col = c(\"blue\", \"red\"), lty = 1)"
  },
  {
    "objectID": "Descriptivo Dian (2).html#verificaci√≥n-de-los-supuestos-modelo-ar12-con-outliers.",
    "href": "Descriptivo Dian (2).html#verificaci√≥n-de-los-supuestos-modelo-ar12-con-outliers.",
    "title": "1¬† An√°lisis descriptivo del recaudo de impuestos internos por la DIAN",
    "section": "8.1 Verificaci√≥n de los supuestos modelo AR(12) con Outliers.",
    "text": "8.1 Verificaci√≥n de los supuestos modelo AR(12) con Outliers.\n\n# An√°lisis de residuales\nresiduales= ARPURO_ref_prueba_outliers2$residuals\nplot(residuales)\n\n\n\nacf(as.numeric(residuales))\n\n\n\nacf(as.numeric(residuales^2))\n\n\n\npacf(as.numeric(residuales))\n\n\n\n\n\n#Test de normalidad\ntseries::jarque.bera.test(residuales)\n\n\n    Jarque Bera Test\n\ndata:  residuales\nX-squared = 44.24, df = 2, p-value = 2.474e-10\n\n#Test de autocorrelaci√≥n\nlength(residuales)/4\n\n[1] 56.25\n\nsqrt(length(residuales))\n\n[1] 15\n\nBox.test(residuales, lag =17 , type = \"Ljung-Box\", fitdf = 2)#No puedo Rechazar la hip√≥tesis de no autocorrelaci√≥n!\n\n\n    Box-Ljung test\n\ndata:  residuales\nX-squared = 11.715, df = 15, p-value = 0.7005\n\n\n\n###Estad?sticas CUSUM\nres=residuales\ncum=cumsum(res)/sd(res)\nN=length(res)\ncumq=cumsum(res^2)/sum(res^2)\nAf=0.948 ###Cuantil del 95% para la estad?stica cusum\nco=0.10997####Valor del cuantil aproximado para cusumsq para n/2\nLS=Af*sqrt(N)+2*Af*c(1:length(res))/sqrt(N)\nLI=-LS\nLQS=co+(1:length(res))/N\nLQI=-co+(1:length(res))/N\nplot(cum,type=\"l\",ylim=c(min(LI),max(LS)),xlab=\"t\",ylab=\"\",main=\"CUSUM\")\nlines(LS,type=\"S\",col=\"red\")\nlines(LI,type=\"S\",col=\"red\")\n\n\n\n#CUSUMSQ\nplot(cumq,type=\"l\",xlab=\"t\",ylab=\"\",main=\"CUSUMSQ\")                      \nlines(LQS,type=\"S\",col=\"red\")                                                                           \nlines(LQI,type=\"S\",col=\"red\")"
  },
  {
    "objectID": "Descriptivo Dian (2).html#rolling-sobre-el-modelo-ar-con-outliers.",
    "href": "Descriptivo Dian (2).html#rolling-sobre-el-modelo-ar-con-outliers.",
    "title": "1¬† An√°lisis descriptivo del recaudo de impuestos internos por la DIAN",
    "section": "8.2 Rolling sobre el modelo AR con outliers.",
    "text": "8.2 Rolling sobre el modelo AR con outliers.\n\nh=1\nnum_outliers=dim(total_outliers)[2]\nregresoras_aditivos1=matrix(c(rep(0,h*(num_outliers-4))),h,num_outliers-4)\n#regresoras_LS=matrix(c(rep(1,h)),h,1)\nregresoras_aditivos2=matrix(c(rep(0,h)),h,1)\nregresoras_TC=matrix(c(rep(0,h)),h,3)\nregresoras=cbind(regresoras_aditivos1,regresoras_TC,regresoras_aditivos2)\ncolnames(regresoras)=colnames(total_outliers)\n\n\nprediccARo &lt;- matrix(0, nrow=ntest, ncol=h) \nverval &lt;- cbind(test[1:ntest])\nfor(i in 1:(ntest)){\n  x &lt;- window((ElimiTenddian_STL-dian_pred), end = time(ElimiTenddian_STL-dian_pred)[ntrain]+(i-1)/12)\n  refit &lt;- Arima(x, model=ARPURO_ref_prueba_outliers2,xreg = total_outliers)\n  prediccARo[i,] &lt;- forecast::forecast(refit, xreg=regresoras,h=h)$mean\n  total_outliers&lt;-rbind(total_outliers,regresoras)\n}\nprediccARo1&lt;-(prediccARo+estacionalidad[226:282])+tendencia[226:282]\nerrores_predARo &lt;- exp(verval) -exp(prediccARo1)\nECM_ARo &lt;- mean(errores_predARo^2) # Medida de precisi√≥n del pron√≥stico (ECM).\nRECM_ARo &lt;- sqrt(ECM_ARo) # Se le saca ra√≠z \nRECM_ARo\n\n[1] 1302753\n\n\nNotese que se obtuvo un valor ECM de 1.697165e+12 y un valor de RECM de 1302753. ## Prediccion utilizando el modelo AR con outliers\n\nverval_ts&lt;-ts(exp(verval[,1]),start=time(ldian2)[ntrain]+1/12,frequency=12)\nfchstepahe_ts&lt;-ts(exp(prediccARo1),start=time(ldian2)[ntrain]+1/12,frequency=12)\n\nplot(verval_ts, col = \"blue\", ylab = \"Impuestos\", xlab = \"Tiempo\")\nlines(fchstepahe_ts, col = \"red\")\nlegend(\"topright\", legend = c(\"Reales\", \"Predicciones\"), col = c(\"blue\", \"red\"), lty = 1)"
  }
]